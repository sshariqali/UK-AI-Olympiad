{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d360eb",
   "metadata": {},
   "source": [
    "### P2_P1 (5 points, non-coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b7cc2",
   "metadata": {},
   "source": [
    "The high level idea of affine transformation in math is that for each column vector $x \\in \\mathbb{R}^N$, an affine transformation maps it to another column vector $y \\in \\mathbb{R}^M$ via\n",
    "\n",
    "$$y = Wx + b$$\n",
    "\n",
    "where $W \\in \\mathbb{R}^{M \\times N}$ and $b \\in \\mathbb{R}^M$.\n",
    "\n",
    "Let $W = \\begin{bmatrix} 2 & -3 & 1 & 3 & -2 \\\\ 0 & 1 & 2 & 5 & -1 \\\\ 7 & -1 & -3 & 7 & 0 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix}$, and $x = \\begin{bmatrix} 1 \\\\ 2 \\\\ -3 \\\\ 1 \\\\ -2 \\end{bmatrix}$.\n",
    "\n",
    "#### Answers:\n",
    "\n",
    "1. **What is the value of $N$?**\n",
    "   $W$ has 5 columns, so $N = 5$.\n",
    "\n",
    "2. **What is the value of $M$?**\n",
    "   $W$ has 3 rows, so $M = 3$.\n",
    "\n",
    "3. **What is the value of $y$?**\n",
    "   **Reasoning:**\n",
    "   First, compute $Wx$:\n",
    "   $$Wx = \\begin{bmatrix} 2 & -3 & 1 & 3 & -2 \\\\ 0 & 1 & 2 & 5 & -1 \\\\ 7 & -1 & -3 & 7 & 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\\\ -3 \\\\ 1 \\\\ -2 \\end{bmatrix} = \\begin{bmatrix} (2 \\cdot 1) + (-3 \\cdot 2) + (1 \\cdot -3) + (3 \\cdot 1) + (-2 \\cdot -2) \\\\ (0 \\cdot 1) + (1 \\cdot 2) + (2 \\cdot -3) + (5 \\cdot 1) + (-1 \\cdot -2) \\\\ (7 \\cdot 1) + (-1 \\cdot 2) + (-3 \\cdot -3) + (7 \\cdot 1) + (0 \\cdot -2) \\end{bmatrix}$$\n",
    "   $$Wx = \\begin{bmatrix} 2 - 6 - 3 + 3 + 4 \\\\ 0 + 2 - 6 + 5 + 2 \\\\ 7 - 2 + 9 + 7 + 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 3 \\\\ 21 \\end{bmatrix}$$\n",
    "   Then, add $b$:\n",
    "   $$y = Wx + b = \\begin{bmatrix} 0 \\\\ 3 \\\\ 21 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 20 \\end{bmatrix}$$\n",
    "   So, $y = \\begin{bmatrix} 1 \\\\ 3 \\\\ 20 \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94643f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = \n",
      "tensor([[ 1],\n",
      "        [ 3],\n",
      "        [20]])\n"
     ]
    }
   ],
   "source": [
    "# Verification of P2_P1\n",
    "W = torch.tensor([[2, -3, 1, 3, -2],\n",
    "                  [0, 1, 2, 5, -1],\n",
    "                  [7, -1, -3, 7, 0]])\n",
    "\n",
    "b = torch.tensor([[1], \n",
    "                  [0], \n",
    "                  [-1]])\n",
    "\n",
    "x = torch.tensor([[1], \n",
    "                  [2], \n",
    "                  [-3], \n",
    "                  [1], \n",
    "                  [-2]])\n",
    "\n",
    "y = torch.matmul(W, x) + b\n",
    "print(f\"y = \\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5804331",
   "metadata": {},
   "source": [
    "### P2_P3 (10 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e5c4f",
   "metadata": {},
   "source": [
    "In this part, you are asked to build an affine transformation module from scratch by using **NumPy**, NOT PyTorch or TensorFlow.\n",
    "\n",
    "Define such a class as `My_Linear_NumPy`.\n",
    "\n",
    "- **Attributes**\n",
    "    - `in_features`: Number of input features\n",
    "    - `out_features`: Number of output features\n",
    "    - `weight`: This refers to matrix $W$ in Part 1. The shape is `(out_features, in_features)`.\n",
    "    - `bias`: This refers to vector $b$ in Part 1. The shape is `(out_features,)`.\n",
    "    - `random_seed`: The NumPy random seed number used to generate initial values of weight and bias.\n",
    "- **Method `__init__`**:\n",
    "    - To initialize an object in this class, you need to specify `in_features` and `out_features`.\n",
    "    - You may initialize the object by specifying a value for `random_seed`. If it is not specified, then its default value is 42.\n",
    "    - The initial values of weight and bias are random that follow standard normal distributions generated with the seed number attribute `random_seed`.\n",
    "- **Method `forward`**:\n",
    "    - Input `x`: numpy array with shape $(n_0, n_1, \\dots, n_{d-1}, \\text{in\\_features})$ with an arbitrary dimension $d=1, 2, \\dots$.\n",
    "    - Output `y`: numpy array with shape $(n_0, n_1, \\dots, n_{d-1}, \\text{out\\_features})$.\n",
    "    - The affine transformation works in a way that given the first $d$ indices in `x` and `y`, it does affine transformation along the last axis of `x` and `y`.\n",
    "    - **Do not use any loop in your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873c55c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (NumPy) = [ 1  3 20]\n"
     ]
    }
   ],
   "source": [
    "class My_Linear_NumPy:\n",
    "    def __init__(self, in_features, out_features, random_seed=42):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # Initialize weight and bias\n",
    "        np.random.seed(self.random_seed)\n",
    "        self.weight = np.random.randn(self.out_features, self.in_features)\n",
    "        self.bias = np.random.randn(self.out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (..., in_features)\n",
    "        weight shape: (out_features, in_features)\n",
    "        bias shape: (out_features,)\n",
    "        \"\"\"\n",
    "        # Using broadcasting to perform matrix multiplication without loops\n",
    "        # x[..., np.newaxis] shape: (..., in_features, 1)\n",
    "        # self.weight.T shape: (in_features, out_features)\n",
    "        # result shape: (..., in_features, out_features)\n",
    "        # np.sum along axis -2 results in (..., out_features)\n",
    "        return np.sum(x[..., np.newaxis] * self.weight.T, axis=-2) + self.bias\n",
    "\n",
    "# Verification with example from Part 1\n",
    "model = My_Linear_NumPy(in_features=5, out_features=3, random_seed=None)\n",
    "model.weight = np.array([[2, -3, 1, 3, -2],\n",
    "                         [0, 1, 2, 5, -1],\n",
    "                         [7, -1, -3, 7, 0]])\n",
    "model.bias = np.array([1, 0, -1])\n",
    "\n",
    "x_np = np.array([1, 2, -3, 1, -2])\n",
    "y_np = model.forward(x_np)\n",
    "print(f\"y (NumPy) = {y_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92794c",
   "metadata": {},
   "source": [
    "### P2_P4 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b670c",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1.  Construct an object in the class `My_Linear_NumPy` called `linear_model_np`.\n",
    "2.  Set `in_features = 3` and `out_features = 5`.\n",
    "3.  Create multiple $X$ with the following different shapes, but common numpy random seed number 2025 and the same standard normal distribution.\n",
    "    *   `(in_features,)`\n",
    "    *   `(10, in_features)`\n",
    "    *   `(10, 20, in_features)`\n",
    "    *   `(10, 20, 30, in_features)`\n",
    "    After generating $X$, reset the numpy random seed number to its default value.\n",
    "4.  We call our constructed function with each of the above $X$ as the input. Print the shape of each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be639dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(10, 5)\n",
      "(10, 20, 5)\n",
      "(10, 20, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "in_features = 3\n",
    "out_features = 5\n",
    "\n",
    "linear_model_np = My_Linear_NumPy(in_features, out_features)\n",
    "\n",
    "np.random.seed(2025)\n",
    "X_list = [\n",
    "    np.random.randn(in_features),\n",
    "    np.random.randn(10, in_features),\n",
    "    np.random.randn(10, 20, in_features),\n",
    "    np.random.randn(10, 20, 30, in_features)\n",
    "]\n",
    "np.random.seed() # Reset to default value\n",
    "\n",
    "for X in X_list:\n",
    "    print(linear_model_np.forward(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bc73a",
   "metadata": {},
   "source": [
    "### P2_P5 (10 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d757b",
   "metadata": {},
   "source": [
    "In this part, you are asked to program with **PyTorch, NOT NumPy**.\n",
    "\n",
    "**Define a deep neural network module (class) named `Linear_Model`.**\n",
    "\n",
    "It has the following architecture:\n",
    "\n",
    "*   2 layers: 1 hidden layer and 1 output layer.\n",
    "*   No activation function. That is, the connection between two consecutive layers is only an affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "        self.linear0 = nn.Linear(in_features, hidden_features)\n",
    "        self.linear1 = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49aab4",
   "metadata": {},
   "source": [
    "### P2_P6 (5 points, non-coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d47ed",
   "metadata": {},
   "source": [
    "We make the following modifications on the previous part.\n",
    "\n",
    "*   We consider a special symmetric neural network that `out_features = in_features`.\n",
    "*   No bias in all affine transformations.\n",
    "*   The transformation matrix from the hidden layer to the output layer is binded to be the transpose of the transformation matrix from the input layer to the hidden layer.\n",
    "\n",
    "**What is the total number of learnable parameters in this model?**\n",
    "\n",
    "*   Reasoning is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b7016",
   "metadata": {},
   "source": [
    "The total number of learnable parameters is:\n",
    "**`in_features * hidden_features`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c57c3",
   "metadata": {},
   "source": [
    "### P2_P9 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60efeac6",
   "metadata": {},
   "source": [
    "This question follows Part 6.\n",
    "\n",
    "In this part, you are asked to program with **PyTorch, not NumPy**.\n",
    "\n",
    "**Build a deep neural network class named as `Symmetric_Linear_Model` that meets the modifications imposed in Part 6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetric_Linear_Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.linear0 = nn.Linear(in_features, hidden_features, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        # Multiply by the transpose of the first layer's weight\n",
    "        x = torch.sum(self.linear0.weight * x.reshape(*x.shape, 1), dim=-2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73805758",
   "metadata": {},
   "source": [
    "### P2_P10 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d04c7",
   "metadata": {},
   "source": [
    "Rectified Linear Unit, or the \"ReLU\", is one of the most common used function in deep learning. It is defined as\n",
    "\n",
    "$$\\text{ReLU}(x) = \\max \\{0, x\\}.$$\n",
    "\n",
    "In this part, you are asked to use **PyTorch** to build a ReLU class named `My_ReLU` that subclasses `nn.Module`.\n",
    "\n",
    "A successful class works in the following ways:\n",
    "\n",
    "*   The initialization of an object in `My_ReLU` does not take any input.\n",
    "*   Suppose we have a `My_ReLU` object called `activation0`. When we call `activation0(x)` with input `x` that is a tensor `x` with an arbitrary dimension and shape, we get an output `y` from the element-wise ReLU activation on `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38780a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.max(torch.zeros_like(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca3374",
   "metadata": {},
   "source": [
    "### P2_P11 (10 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8593f37",
   "metadata": {},
   "source": [
    "It is known by math that the combination of several linear layers can still be seen as an linear layer, so we can add some non-linear activation functions, such as ReLU, in between to get better effect.\n",
    "\n",
    "Multi-Layer Perceptron (MLP), is such a neural network composed of multiple fully connected layers with non-linear activations, commonly used in deep learning.\n",
    "\n",
    "**Please define a class called `My_MLP_Model` that subclasses `nn.Module` and works in the following ways:**\n",
    "\n",
    "*   The architecture consists of two hidden layers and one output layer.\n",
    "*   Each hidden layer consists of an affine transformation module and a ReLU activation module.\n",
    "*   Each affine transformation module shall be initialized with the build-in class `nn.Linear`.\n",
    "*   Each ReLU activation module shall be initialized with your self-defined class `My_ReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_MLP_Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features1, hidden_features2, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features1 = hidden_features1\n",
    "        self.hidden_features2 = hidden_features2\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features1),\n",
    "            My_ReLU(),\n",
    "            nn.Linear(hidden_features1, hidden_features2),\n",
    "            My_ReLU(),\n",
    "            nn.Linear(hidden_features2, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd0c11",
   "metadata": {},
   "source": [
    "### P2_P12 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a94a8",
   "metadata": {},
   "source": [
    "After building our deep neural network architecture in Part 11 and before using it to train our model, we need to prepare our training dataset.\n",
    "\n",
    "Let us look at a simple application of deep neural network in studying harmonic motion in physics.\n",
    "\n",
    "**Write code to construct the following training dataset:**\n",
    "\n",
    "*   Use `sample_size` to store the number of samples. Set the value as 1000.\n",
    "*   Define `x_train` as a tensor whose shape is `(sample_size,)` and the value on each entry is uniformly drawn between 0 and 1.\n",
    "*   Define `y_train` as a tensor whose values are obtained from the following element-wise mapping from `x_train`:\n",
    "\n",
    "    $$y = \\sin(2\\pi x) + 0.1 \\cdot \\mathcal{N}(0, 1),$$\n",
    "\n",
    "    where $\\mathcal{N}(0, 1)$ is a standard normal random variable.\n",
    "*   Print the dimensions of `x_train` and `y_train`.\n",
    "*   Print the shapes of `x_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf82df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "x_train = torch.rand(sample_size)\n",
    "y_train = torch.sin(2 * np.pi * x_train) + 0.1 * torch.randn_like(x_train)\n",
    "\n",
    "print(x_train.ndim)\n",
    "print(y_train.ndim)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c632cfa",
   "metadata": {},
   "source": [
    "### P2_P13 (15 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b44e83",
   "metadata": {},
   "source": [
    "In this part, we use the training dataset constructed in Part 12 to train a model defined in Part 11.\n",
    "\n",
    "- Use mean-squared error (MSE) as the loss function.\n",
    "- Use Adam as the optimization algorithm.\n",
    "- Do whole-batch training in each epoch.\n",
    "- After every 10 epochs, print the following sentence:\n",
    "  `Epoch: XXX. Loss: XXX.`\n",
    "  The loss value should be with 4 decimal places.\n",
    "- Generate an epoch-MSE loss plot after completing the training. Set the x-label as `epoch` and the y-label as `MSE loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "''' DO NOT CHANGE ANYTHING IN THIS CODE CELL '''\n",
    "\n",
    "hidden_features1 = 32\n",
    "hidden_features2 = 16\n",
    "\n",
    "num_epochs = 500\n",
    "learning_rate = 1e-3\n",
    "\n",
    "### WRITE YOUR SOLUTION HERE ###\n",
    "\n",
    "my_mlp_model = My_MLP_Model(1, hidden_features1, hidden_features2, 1)\n",
    "optimizer = torch.optim.Adam(my_mlp_model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "loss_list_plot = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass: whole-batch training\n",
    "    y_pred = my_mlp_model(x_train.reshape(-1, 1))\n",
    "    loss = loss_fn(y_pred, y_train.reshape(-1, 1))\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    loss_list_plot.append(loss.item())\n",
    "\n",
    "# Plotting the loss\n",
    "plt.plot(loss_list_plot)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb43c1",
   "metadata": {},
   "source": [
    "### P3_P1 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193eb922",
   "metadata": {},
   "source": [
    "We study the dataset `USAAIO_2025_round1_prob3_train.csv` provided in this contest.\n",
    "\n",
    "The dataset can be found here:\n",
    "\n",
    "url = \"https://drive.google.com/file/d/125YsFPS2nCNRvYyy1tgnD8RhYIUglLX9/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351a58e",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1. Load `USAAIO_2025_round1_prob3_train.csv` into a pandas DataFrame object called `df_1`.\n",
    "\n",
    "2. Print the first 10 rows.\n",
    "\n",
    "3. Define a function called `data_summary` that\n",
    "\n",
    "    - Takes a DataFrame object as an input.\n",
    "\n",
    "    - Prints the shape of the DataFrame.\n",
    "\n",
    "    - Prints the data type for each column.\n",
    "\n",
    "    - Prints the count of missing values for each column.\n",
    "\n",
    "    - Delivers no output.\n",
    "\n",
    "4. After defining the above function, call it by feeding `df_1` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d67044",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "\n",
    "df_1 = pd.read_csv('USAAIO_2025_round1_prob3_train.csv')\n",
    "print(df_1.head(10))\n",
    "\n",
    "def data_summary(df):\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Data Types: {df.dtypes}\")\n",
    "    print(f\"Missing Values per Column: {df.isnull().sum()}\")\n",
    "\n",
    "data_summary(df_1)\n",
    "\n",
    "\"\"\" END OF THIS PART \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7051ab2",
   "metadata": {},
   "source": [
    "### P3_P2 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67218c4",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1. Create a DataFrame object called `df_2` that keeps the following columns in `df_1` (all other columns in `df_1` shall not appear in `df_2`):\n",
    "    - `Survived`\n",
    "    - `Sex`\n",
    "    - `Age`\n",
    "    - `SibSp`\n",
    "    - `Parch`\n",
    "    - `Fare`\n",
    "    - `Embarked`\n",
    "2. Print the first 5 rows of `df_2`.\n",
    "3. Print the shape of `df_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "\n",
    "print(df_2.head())\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a786827",
   "metadata": {},
   "source": [
    "### P3_P3 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03400a19",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1. In `df_2`, remove all rows that contain null (missing) values.\n",
    "2. Save the updated DataFrame object as `df_3` (that is, the change of `df_2` should not be inplace).\n",
    "3. For `df_3`, print the count of missing values per column.\n",
    "4. Print the shape of `df_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.dropna()\n",
    "\n",
    "print(df_3.isnull().sum())\n",
    "print(df_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e0d00",
   "metadata": {},
   "source": [
    "### P3_P4 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71006aaf",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1. Create a deep copy of `df_3`, named `df_4`.\n",
    "2. In `df_4`, create a new column called `GroupSize`. Its value is equal to `SibSp + Parch + 1`.\n",
    "3. Print the first five rows of `df_3` and `df_4`.\n",
    "4. Print the shapes of `df_3` and `df_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = copy.deepcopy(df_3)\n",
    "df_4['GroupSize'] = df_4['SibSp'] + df_4['Parch'] + 1\n",
    "\n",
    "print(df_3.head())\n",
    "print(df_4.head())\n",
    "\n",
    "print(df_3.shape)\n",
    "print(df_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c3a8f",
   "metadata": {},
   "source": [
    "### P3_P5 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045f34e",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1. Remove columns `SibSp` and `Parch` in `df_4` , and save this new DataFrame object as `df_5` (changes on `df_4` should not be inplace).\n",
    "\n",
    "2. Print the first five rows of `df_4` and `df_5`.\n",
    "\n",
    "3. Print the shapes of `df_4` and `df_5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "df_5 = df_4.drop(columns=['SibSp', 'Parch'])\n",
    "\n",
    "print(df_4.head())\n",
    "print(df_5.head())\n",
    "\n",
    "print(df_4.shape)\n",
    "print(df_5.shape)\n",
    "\n",
    "\"\"\" END OF THIS PART \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018a716",
   "metadata": {},
   "source": [
    "### P3_P6 (5 points, coding and conceptual reasoning task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887970eb",
   "metadata": {},
   "source": [
    "In `df_5`, columns `Sex` and `Embarked` are categorical data.\n",
    "\n",
    "**Do the following tasks to process these categorical data.**\n",
    "\n",
    "1. To do logistic regression on this dataset, we need to do one hot encoding on these two columns. Explain why?\n",
    "\n",
    "2. Do one hot encoding on these two columns. Set `drop_first = True` and `dtype = np.int8`. Save the new dataframe object as `df_6`.\n",
    "\n",
    "3. Explain what `drop_first = True` means and why we do so.\n",
    "\n",
    "4. Print the first five rows of `df_5` and `df_6`.\n",
    "\n",
    "5. Print the shapes of `df_5` and `df_6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e91d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "\n",
    "# Question 1\n",
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "Logistic regression requires numerical data, not categorical data.\n",
    "\"\"\"\n",
    "\n",
    "# Question 2\n",
    "# Answer: (put your code here)\n",
    "\n",
    "df_6 = pd.get_dummies(df_5, columns=['Sex', 'Embarked'], drop_first=True, dtype=np.int8)\n",
    "\n",
    "# Question 3\n",
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "Suppose a categorical variable takes value k chosen from K categories, indexed as 0, 1, ..., K-1.\n",
    "By setting drop_first = True, it is replaced by a vector with shape K-1.\n",
    "If k = 0, then in this vector, all entries are 0.\n",
    "If k is not 0, then in this vector, the (k-1)th entry (entry indices starts from 0) is 1.\n",
    "\n",
    "Setting drop_first = True avoids multicollinearity.\n",
    "\"\"\"\n",
    "\n",
    "# Question 4\n",
    "# Answer: (put your code here)\n",
    "\n",
    "print(df_5.head())\n",
    "print(df_6.head())\n",
    "\n",
    "# Question 5\n",
    "# Answer: (put your code here)\n",
    "\n",
    "print(df_5.shape)\n",
    "print(df_6.shape)\n",
    "\n",
    "\"\"\" END OF THIS PART \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc1976",
   "metadata": {},
   "source": [
    "### P3_P7 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a756d20",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1. Define `X` that keeps all features in `df_6` and drops the label column `Survived`.\n",
    "\n",
    "2. Define `y` that keeps the label column `Survived` in `df_6` only.\n",
    "\n",
    "3. Print the types of objects `X` and `y`.\n",
    "\n",
    "4. Print the first five rows of `X` and the first five elements in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "X = df_6.drop(columns=['Survived'])\n",
    "y = df_6['Survived']\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "\"\"\" END OF THIS PART \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6902d",
   "metadata": {},
   "source": [
    "### P3_P8 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d39f89",
   "metadata": {},
   "source": [
    "Do the following tasks in this part.\n",
    "\n",
    "1.  Define a function called `my_train_test_split` that splits the whole dataset into the training component and the test/validation component.\n",
    "    *   The split is random\n",
    "    *   **Inputs**\n",
    "        *   `X`: A DataFrame object of features of all sample data.\n",
    "        *   `y`: A Series object of labels of all sample data.\n",
    "        *   `test_size`: It takes a value between 0 and 1 that denotes the fraction of samples used for testing. That is, the number of samples used for testing is `int(total number of samples * test_size)`.\n",
    "    *   **Outputs**\n",
    "        *   `X_train`: It keeps samples in `X` for training.\n",
    "        *   `X_test`: It keeps samples in `X` for testing.\n",
    "        *   `y_train`: It keeps samples in `y` for training.\n",
    "        *   `y_test`: It keeps samples in `y` for testing.\n",
    "\n",
    "2.  Call this function with inputs\n",
    "    *   `X = X`\n",
    "    *   `y = y`\n",
    "    *   `test_size = 0.2`\n",
    "\n",
    "3.  Print object types and shapes of `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "def my_train_test_split(X, y, test_size):\n",
    "    num_samples = X.shape[0]\n",
    "    num_test_samples = int(num_samples * test_size)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    test_indices = indices[:num_test_samples]\n",
    "    train_indices = indices[num_test_samples:]\n",
    "\n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y, 0.2)\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b079ea",
   "metadata": {},
   "source": [
    "### P3_P9 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51eb2f",
   "metadata": {},
   "source": [
    "Use `StandardScaler` that has been imported from `sklearn.preprocessing` (DO NOT IMPORT IT AGAIN) to do the following tasks.\n",
    "\n",
    "1.  Create an object called `scaler`.\n",
    "\n",
    "2.  Use `scaler.fit_transform` to scale each column in `X_train` to standard normal. Save the scaled training dataset as `X_train_scaled`.\n",
    "\n",
    "3.  Use `scaler.transform` to scale `X_test`. Save the scaled test dataset as `X_test_scaled`.\n",
    "\n",
    "4.  Add a column to `X_train_scaled` with all 1s. Do the same thing for `X_test_scaled`.\n",
    "\n",
    "5.  Print the types of objects `X_train_scaled` and `X_test_scaled`.\n",
    "\n",
    "6.  Print the shapes of objects `X_train_scaled` and `X_test_scaled`.\n",
    "\n",
    "7.  Print the first five rows of `X_train_scaled` and `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.concat([X_train_scaled, np.ones(X_train_scaled.shape[0], 1)])\n",
    "X_test_scaled = np.concat([X_test_scaled, np.ones((X_test_scaled.shape[0], 1))])\n",
    "\n",
    "print(type(X_train_scaled))\n",
    "print(type(X_test_scaled))\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "\n",
    "print(X_train_scaled[:5])\n",
    "print(X_test_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3_P16 (5 points, coding task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718040c",
   "metadata": {},
   "source": [
    "Define a function called `my_sigmoid`:\n",
    "\n",
    "*   Input: A numpy array with any shape.\n",
    "\n",
    "*   Output: Elementwise sigmoid functional values.\n",
    "\n",
    "*   No loop in the body of your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18167402",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR SOLUTION HERE ###\n",
    "def my_sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\"\"\" END OF THIS PART \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
