{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24f447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4db04",
   "metadata": {},
   "source": [
    "### Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1f2418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a36140",
   "metadata": {},
   "source": [
    "Language Modelling Principal (Token Communication):\n",
    "\n",
    "Token in 5th Location for example should not be able to communicate with token in 6th, 7th or 8th token as they are future tokens. \n",
    "\n",
    "It should only be able to communicate with tokens before it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d131b90",
   "metadata": {},
   "source": [
    "We can do this using Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1668e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "b=\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "c=\n",
      "tensor([[ 5.,  7.],\n",
      "        [ 7.,  7.],\n",
      "        [12., 10.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3, 3)) # torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3,2), dtype = torch.float)\n",
    "c = a @ b\n",
    "\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=')\n",
    "print(b)\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e453dcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 1\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True) # normalize the rows\n",
    "out_1 = wei @ x # (T,T) @ (B,T,C) ---> (B,T,T) @ (B,T,C) ---> (B,T,C)\n",
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0921fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 2\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = torch.softmax(wei, dim=-1)\n",
    "out_2 = wei @ x\n",
    "out_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf971d",
   "metadata": {},
   "source": [
    "- Every single token at every position will now emit three vectors, a Query and a Key and a Value\n",
    "- Query means What am I looking for?\n",
    "- Key means What do I contain?\n",
    "- Value means What will I communicate?\n",
    "- Their dot product of Q and K will then basically give us attention scores meaning which token has a higher affinity to which other tokens.\n",
    "- Finally we will take the dot product of the attention scores with the values to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f8b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now Implement a Single Head of Self Attention\n",
    "\n",
    "head_size = 16\n",
    "key = torch.nn.Linear(C, head_size, bias = False)\n",
    "query = torch.nn.Linear(C, head_size, bias = False)\n",
    "value = torch.nn.Linear(C, head_size, bias = False)\n",
    "\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "v = value(x)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) / head_size**0.5  # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = torch.softmax(wei, dim=-1)\n",
    "out = wei @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e909ce77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [7.1821e-01, 2.8179e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [6.2292e-01, 2.6785e-01, 1.0923e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.7394e-02, 3.5937e-02, 8.8566e-02, 8.4810e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [9.2227e-01, 1.0381e-02, 4.4360e-02, 7.6919e-04, 2.2219e-02, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [7.4951e-02, 1.1837e-01, 2.4863e-01, 3.7787e-01, 6.3060e-03, 1.7387e-01,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.8730e-01, 5.8106e-02, 6.1382e-02, 3.6453e-03, 6.4791e-01, 1.8433e-02,\n",
       "         2.3230e-02, 0.0000e+00],\n",
       "        [4.1080e-01, 6.0570e-02, 2.1063e-02, 1.6063e-03, 1.6883e-01, 1.5380e-02,\n",
       "         4.0297e-03, 3.1772e-01]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
