{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7051b501",
   "metadata": {},
   "source": [
    "# **Day 8 (Part 2 - Step 2): Position-wise Feed-Forward Network**\n",
    "\n",
    "## The Non-Linear Powerhouse of the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca38c4",
   "metadata": {},
   "source": [
    "### **1. Recap: What We've Built So Far**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3721037a",
   "metadata": {},
   "source": [
    "**Our Encoder Layer Building Progress:**\n",
    "\n",
    "| Component | Status | Purpose |\n",
    "|-----------|--------|--------|\n",
    "| Multi-Head Attention | ‚úÖ Day 7 | Relate words to each other |\n",
    "| Positional Encoding | ‚úÖ Step 1 | Add position information |\n",
    "| **Feed-Forward Network** | üîß **Today** | **Add non-linear transformations** |\n",
    "| Layer Normalization | ‚è≥ Step 3 | Stabilize training |\n",
    "| Residual Connections | ‚è≥ Step 3 | Enable gradient flow |\n",
    "| Complete Encoder Layer | ‚è≥ Step 3 | Assemble everything |\n",
    "\n",
    "**Today's Goal:** Build the Position-wise Feed-Forward Network (FFN) ‚Äì a simple but crucial component that adds **non-linear transformation power** to the Transformer!\n",
    "\n",
    "Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828d01a",
   "metadata": {},
   "source": [
    "### **2. What is the Position-wise Feed-Forward Network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d251a3",
   "metadata": {},
   "source": [
    "#### **The Problem: Attention is Linear!**\n",
    "\n",
    "Remember the attention formula?\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "While softmax adds some non-linearity to the attention weights, the overall operation is mostly **linear**:\n",
    "- Matrix multiplications (Q, K, V projections)\n",
    "- Weighted sum of values\n",
    "\n",
    "**Why is this a problem?**\n",
    "\n",
    "Linear transformations have limited expressiveness:\n",
    "- Multiple linear layers = equivalent to a single linear layer\n",
    "- Can't learn complex, non-linear patterns\n",
    "- Limited representational power\n",
    "\n",
    "$$\\text{Linear}_2(\\text{Linear}_1(x)) = \\text{Linear}_3(x)$$\n",
    "\n",
    "We need **non-linearity** to learn complex functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9c281",
   "metadata": {},
   "source": [
    "#### **The Solution: Feed-Forward Network**\n",
    "\n",
    "The Feed-Forward Network (FFN) is a simple **two-layer MLP** with a non-linear activation:\n",
    "\n",
    "$$\\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2$$\n",
    "\n",
    "Or using ReLU notation:\n",
    "\n",
    "$$\\text{FFN}(x) = \\text{ReLU}(xW_1 + b_1)W_2 + b_2$$\n",
    "\n",
    "**In Modern Transformers (GELU):**\n",
    "\n",
    "$$\\text{FFN}(x) = \\text{GELU}(xW_1 + b_1)W_2 + b_2$$\n",
    "\n",
    "**Architecture Diagram:**\n",
    "\n",
    "```\n",
    "Input (d_model=512)\n",
    "        ‚Üì\n",
    "  [Linear Layer 1]\n",
    "  (512 ‚Üí 2048)\n",
    "        ‚Üì\n",
    "  [ReLU / GELU]\n",
    "        ‚Üì\n",
    "  [Dropout]\n",
    "        ‚Üì\n",
    "  [Linear Layer 2]\n",
    "  (2048 ‚Üí 512)\n",
    "        ‚Üì\n",
    "Output (d_model=512)\n",
    "```\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/0*l-kF0t8dFKSUFrXx.png\" width=\"400\"/>\n",
    "  <p><i>Position-wise Feed-Forward Network</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0b8ec",
   "metadata": {},
   "source": [
    "### **3. Why \"Position-wise\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8062741",
   "metadata": {},
   "source": [
    "The key insight is that the FFN is applied **independently to each position**:\n",
    "\n",
    "```\n",
    "Sequence: [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "              ‚Üì       ‚Üì      ‚Üì     ‚Üì      ‚Üì      ‚Üì\n",
    "            FFN     FFN    FFN   FFN    FFN    FFN\n",
    "              ‚Üì       ‚Üì      ‚Üì     ‚Üì      ‚Üì      ‚Üì\n",
    "          [out_1] [out_2] [out_3] [out_4] [out_5] [out_6]\n",
    "```\n",
    "\n",
    "**Important:** \n",
    "- Same weights for all positions (parameter sharing)\n",
    "- No interaction between positions (unlike attention)\n",
    "- Each position transformed independently\n",
    "\n",
    "**Analogy:**\n",
    "\n",
    "Think of attention as a **group discussion** where everyone talks to each other, and FFN as **individual thinking** where each person processes information on their own.\n",
    "\n",
    "| Component | What It Does | Analogy |\n",
    "|-----------|--------------|--------|\n",
    "| Attention | Positions interact with each other | Group discussion üë• |\n",
    "| FFN | Each position transformed independently | Individual thinking üß† |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36322f5",
   "metadata": {},
   "source": [
    "### **4. The Expand-Contract Pattern**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d266bac",
   "metadata": {},
   "source": [
    "A key design choice in the FFN is the **expand-then-contract** pattern:\n",
    "\n",
    "```\n",
    "d_model (512) ‚Üí d_ff (2048) ‚Üí d_model (512)\n",
    "     ‚Üì              ‚Üì              ‚Üì\n",
    "  Narrow        Expanded        Narrow\n",
    "```\n",
    "\n",
    "**Why Expand to 4√ó the Size?**\n",
    "\n",
    "1. **More Expressiveness**: The larger hidden dimension allows for more complex computations\n",
    "2. **Bottleneck Architecture**: Forces the model to learn compressed representations\n",
    "3. **Feature Detection**: Each hidden unit can detect different patterns\n",
    "\n",
    "**Analogy: The Thinking Process**\n",
    "\n",
    "Imagine solving a complex problem:\n",
    "\n",
    "1. **Input (512 dims)**: You receive information\n",
    "2. **Expand (2048 dims)**: You think about many aspects, consider various possibilities\n",
    "3. **Contract (512 dims)**: You summarize your thoughts into a conclusion\n",
    "\n",
    "The expansion allows for **richer intermediate representations**!\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://theaisummer.com/static/3e9d1a5498e65f15e019bb48e50f529c/ee604/feed-forward-layer.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6127b0c",
   "metadata": {},
   "source": [
    "### **5. Activation Functions: ReLU vs GELU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ca423",
   "metadata": {},
   "source": [
    "The original Transformer used **ReLU**, but modern transformers often use **GELU**.\n",
    "\n",
    "#### **ReLU (Rectified Linear Unit)**\n",
    "\n",
    "$$\\text{ReLU}(x) = \\max(0, x)$$\n",
    "\n",
    "- Simple and fast\n",
    "- \"Hard\" threshold at 0\n",
    "- Can cause \"dead neurons\" (always output 0)\n",
    "\n",
    "#### **GELU (Gaussian Error Linear Unit)**\n",
    "\n",
    "$$\\text{GELU}(x) = x \\cdot \\Phi(x) = x \\cdot \\frac{1}{2}\\left[1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]$$\n",
    "\n",
    "Approximation:\n",
    "$$\\text{GELU}(x) \\approx 0.5x\\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}}\\left(x + 0.044715x^3\\right)\\right]\\right)$$\n",
    "\n",
    "- Smooth activation\n",
    "- \"Soft\" threshold (probabilistic)\n",
    "- Used in GPT, BERT, and most modern transformers\n",
    "\n",
    "Let's visualize both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create input range\n",
    "x = torch.linspace(-4, 4, 200)\n",
    "\n",
    "# Compute activations\n",
    "relu = F.relu(x)\n",
    "gelu = F.gelu(x)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ReLU\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x.numpy(), relu.numpy(), 'b-', linewidth=2, label='ReLU')\n",
    "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.fill_between(x.numpy(), relu.numpy(), alpha=0.3)\n",
    "plt.xlabel('Input (x)')\n",
    "plt.ylabel('Output')\n",
    "plt.title('ReLU: max(0, x)\\n\"Hard\" threshold at 0', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# GELU\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x.numpy(), gelu.numpy(), 'r-', linewidth=2, label='GELU')\n",
    "plt.plot(x.numpy(), relu.numpy(), 'b--', linewidth=1, alpha=0.5, label='ReLU (reference)')\n",
    "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.fill_between(x.numpy(), gelu.numpy(), alpha=0.3, color='red')\n",
    "plt.xlabel('Input (x)')\n",
    "plt.ylabel('Output')\n",
    "plt.title('GELU: x ¬∑ Œ¶(x)\\n\"Soft\" probabilistic threshold', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Differences:\")\n",
    "print(\"‚Ä¢ ReLU: Hard cutoff at 0 - either fully on or fully off\")\n",
    "print(\"‚Ä¢ GELU: Smooth transition - allows small negative values through\")\n",
    "print(\"‚Ä¢ GELU is used in GPT, BERT, and most modern transformers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4c90a",
   "metadata": {},
   "source": [
    "### **6. Implementing the Position-wise Feed-Forward Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb4719",
   "metadata": {},
   "source": [
    "Now let's implement the FFN as a PyTorch module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network\n",
    "    \n",
    "    This is a simple two-layer MLP applied independently to each position.\n",
    "    \n",
    "    Architecture:\n",
    "        Input (d_model) ‚Üí Linear ‚Üí Activation ‚Üí Dropout ‚Üí Linear ‚Üí Output (d_model)\n",
    "    \n",
    "    Args:\n",
    "        d_model: Model dimension (e.g., 512)\n",
    "        d_ff: Feed-forward hidden dimension (typically 4 * d_model = 2048)\n",
    "        dropout: Dropout probability (default: 0.1)\n",
    "        activation: Activation function ('relu' or 'gelu')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, d_ff, dropout=0.1, activation='relu'):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        \n",
    "        # Store dimensions for inspection\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        # First linear layer: expand from d_model to d_ff\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        \n",
    "        # Second linear layer: contract from d_ff back to d_model\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation function\n",
    "        if activation == 'relu':\n",
    "            self.activation = F.relu\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = F.gelu\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation}. Use 'relu' or 'gelu'.\")\n",
    "        \n",
    "        self.activation_name = activation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the FFN.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model)\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Step 1: Expand dimensions (d_model ‚Üí d_ff)\n",
    "        x = self.linear1(x)  # (batch, seq_len, d_ff)\n",
    "        \n",
    "        # Step 2: Apply activation function\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Step 3: Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Step 4: Contract dimensions (d_ff ‚Üí d_model)\n",
    "        x = self.linear2(x)  # (batch, seq_len, d_model)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"PositionWiseFeedForward(\\n\"\n",
    "                f\"  d_model={self.d_model},\\n\"\n",
    "                f\"  d_ff={self.d_ff},\\n\"\n",
    "                f\"  activation={self.activation_name}\\n\"\n",
    "                f\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb67c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our implementation!\n",
    "\n",
    "# Configuration (matching the original Transformer paper)\n",
    "d_model = 512\n",
    "d_ff = 2048  # 4 * d_model\n",
    "dropout = 0.1\n",
    "\n",
    "# Create FFN with ReLU\n",
    "ffn_relu = PositionWiseFeedForward(d_model, d_ff, dropout, activation='relu')\n",
    "print(\"FFN with ReLU:\")\n",
    "print(ffn_relu)\n",
    "print()\n",
    "\n",
    "# Create FFN with GELU (modern transformers)\n",
    "ffn_gelu = PositionWiseFeedForward(d_model, d_ff, dropout, activation='gelu')\n",
    "print(\"FFN with GELU:\")\n",
    "print(ffn_gelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f054dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample input\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "\n",
    "# Create random input\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"  ‚Üí (batch_size={batch_size}, seq_len={seq_len}, d_model={d_model})\")\n",
    "print()\n",
    "\n",
    "# Forward pass\n",
    "ffn_relu.eval()  # Set to eval mode to disable dropout for testing\n",
    "with torch.no_grad():\n",
    "    output = ffn_relu(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"  ‚Üí (batch_size={batch_size}, seq_len={seq_len}, d_model={d_model})\")\n",
    "print()\n",
    "print(\"‚úÖ Input and output shapes match! (as expected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f316b05",
   "metadata": {},
   "source": [
    "### **7. Visualizing the Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81451666",
   "metadata": {},
   "source": [
    "Let's visualize what happens inside the FFN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88608b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small FFN for visualization\n",
    "d_model_small = 8\n",
    "d_ff_small = 32\n",
    "\n",
    "ffn_viz = PositionWiseFeedForward(d_model_small, d_ff_small, dropout=0.0, activation='relu')\n",
    "ffn_viz.eval()\n",
    "\n",
    "# Create a simple input (1 batch, 4 positions, 8 dims)\n",
    "x_viz = torch.randn(1, 4, d_model_small)\n",
    "\n",
    "# Get intermediate activations\n",
    "with torch.no_grad():\n",
    "    # Step 1: After first linear\n",
    "    after_linear1 = ffn_viz.linear1(x_viz)\n",
    "    \n",
    "    # Step 2: After activation\n",
    "    after_activation = F.relu(after_linear1)\n",
    "    \n",
    "    # Step 3: After second linear (final output)\n",
    "    output_viz = ffn_viz.linear2(after_activation)\n",
    "\n",
    "# Visualize the transformations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Input\n",
    "im1 = axes[0, 0].imshow(x_viz[0].numpy(), cmap='RdBu', aspect='auto', vmin=-2, vmax=2)\n",
    "axes[0, 0].set_title(f'1. Input\\nShape: (4 positions, {d_model_small} dims)', fontsize=11)\n",
    "axes[0, 0].set_xlabel('Dimension')\n",
    "axes[0, 0].set_ylabel('Position')\n",
    "plt.colorbar(im1, ax=axes[0, 0])\n",
    "\n",
    "# After first linear (expanded)\n",
    "im2 = axes[0, 1].imshow(after_linear1[0].numpy(), cmap='RdBu', aspect='auto', vmin=-2, vmax=2)\n",
    "axes[0, 1].set_title(f'2. After Linear1 (Expanded!)\\nShape: (4 positions, {d_ff_small} dims)', fontsize=11)\n",
    "axes[0, 1].set_xlabel('Dimension (expanded to 32)')\n",
    "axes[0, 1].set_ylabel('Position')\n",
    "plt.colorbar(im2, ax=axes[0, 1])\n",
    "\n",
    "# After ReLU\n",
    "im3 = axes[1, 0].imshow(after_activation[0].numpy(), cmap='RdBu', aspect='auto', vmin=-2, vmax=2)\n",
    "axes[1, 0].set_title(f'3. After ReLU\\nNegatives ‚Üí 0 (see the zeros!)', fontsize=11)\n",
    "axes[1, 0].set_xlabel('Dimension')\n",
    "axes[1, 0].set_ylabel('Position')\n",
    "plt.colorbar(im3, ax=axes[1, 0])\n",
    "\n",
    "# Output (contracted back)\n",
    "im4 = axes[1, 1].imshow(output_viz[0].numpy(), cmap='RdBu', aspect='auto', vmin=-2, vmax=2)\n",
    "axes[1, 1].set_title(f'4. After Linear2 (Contracted!)\\nShape: (4 positions, {d_model_small} dims)', fontsize=11)\n",
    "axes[1, 1].set_xlabel('Dimension (back to 8)')\n",
    "axes[1, 1].set_ylabel('Position')\n",
    "plt.colorbar(im4, ax=axes[1, 1])\n",
    "\n",
    "plt.suptitle('FFN Transformation: Expand ‚Üí Activate ‚Üí Contract', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(f\"‚Ä¢ Input:        {d_model_small} dimensions\")\n",
    "print(f\"‚Ä¢ Expanded to:  {d_ff_small} dimensions (4√ó larger!)\")\n",
    "print(f\"‚Ä¢ After ReLU:   Negative values become 0 (white areas)\")\n",
    "print(f\"‚Ä¢ Output:       Back to {d_model_small} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42c2ef",
   "metadata": {},
   "source": [
    "### **8. Parameter Count Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0a837",
   "metadata": {},
   "source": [
    "Let's understand how many parameters are in the FFN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in a model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def analyze_ffn_parameters(d_model, d_ff):\n",
    "    \"\"\"Analyze FFN parameter breakdown.\"\"\"\n",
    "    ffn = PositionWiseFeedForward(d_model, d_ff, dropout=0.1)\n",
    "    \n",
    "    # Linear 1: d_model ‚Üí d_ff\n",
    "    linear1_weights = d_model * d_ff\n",
    "    linear1_bias = d_ff\n",
    "    \n",
    "    # Linear 2: d_ff ‚Üí d_model\n",
    "    linear2_weights = d_ff * d_model\n",
    "    linear2_bias = d_model\n",
    "    \n",
    "    total = linear1_weights + linear1_bias + linear2_weights + linear2_bias\n",
    "    \n",
    "    print(f\"FFN Parameter Analysis (d_model={d_model}, d_ff={d_ff})\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Linear 1 (d_model ‚Üí d_ff):\")\n",
    "    print(f\"  ‚Ä¢ Weights: {d_model} √ó {d_ff} = {linear1_weights:,}\")\n",
    "    print(f\"  ‚Ä¢ Bias:    {d_ff:,}\")\n",
    "    print(f\"  ‚Ä¢ Subtotal: {linear1_weights + linear1_bias:,}\")\n",
    "    print()\n",
    "    print(f\"Linear 2 (d_ff ‚Üí d_model):\")\n",
    "    print(f\"  ‚Ä¢ Weights: {d_ff} √ó {d_model} = {linear2_weights:,}\")\n",
    "    print(f\"  ‚Ä¢ Bias:    {d_model:,}\")\n",
    "    print(f\"  ‚Ä¢ Subtotal: {linear2_weights + linear2_bias:,}\")\n",
    "    print()\n",
    "    print(f\"Total FFN Parameters: {total:,}\")\n",
    "    print()\n",
    "    \n",
    "    # Verify with actual model\n",
    "    actual_count = count_parameters(ffn)\n",
    "    print(f\"Verification (actual count): {actual_count:,}\")\n",
    "    print(f\"Match: {'‚úÖ Yes!' if actual_count == total else '‚ùå No'}\")\n",
    "    \n",
    "    return total\n",
    "\n",
    "# Analyze with original Transformer dimensions\n",
    "params = analyze_ffn_parameters(512, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FFN params to total Encoder Layer params\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FFN's Share of Encoder Layer Parameters\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "num_heads = 8\n",
    "\n",
    "# FFN parameters\n",
    "ffn_params = 2 * d_model * d_ff + d_ff + d_model\n",
    "\n",
    "# Multi-Head Attention parameters (W_q, W_k, W_v, W_o)\n",
    "mha_params = 4 * (d_model * d_model + d_model)  # 4 linear layers with biases\n",
    "\n",
    "# Layer Norm parameters (2 layer norms, each has gamma and beta)\n",
    "ln_params = 2 * 2 * d_model\n",
    "\n",
    "total_encoder_layer = ffn_params + mha_params + ln_params\n",
    "\n",
    "print(f\"Multi-Head Attention: {mha_params:,} params ({100*mha_params/total_encoder_layer:.1f}%)\")\n",
    "print(f\"Feed-Forward Network: {ffn_params:,} params ({100*ffn_params/total_encoder_layer:.1f}%)\")\n",
    "print(f\"Layer Normalization:  {ln_params:,} params ({100*ln_params/total_encoder_layer:.1f}%)\")\n",
    "print(f\"-\" * 40)\n",
    "print(f\"Total Encoder Layer:  {total_encoder_layer:,} params\")\n",
    "print()\n",
    "print(\"üí° Insight: FFN contains about 2/3 of the encoder layer's parameters!\")\n",
    "print(\"   This is because d_ff = 4 √ó d_model makes the FFN very large.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e080b6d",
   "metadata": {},
   "source": [
    "### **9. Position-wise Independence: Demonstration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459f101",
   "metadata": {},
   "source": [
    "Let's verify that the FFN processes each position **independently**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22735ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an FFN\n",
    "ffn = PositionWiseFeedForward(d_model=64, d_ff=256, dropout=0.0)\n",
    "ffn.eval()\n",
    "\n",
    "# Create two inputs that differ only at position 0\n",
    "x1 = torch.randn(1, 5, 64)  # 5 positions\n",
    "x2 = x1.clone()\n",
    "x2[0, 0, :] = torch.randn(64)  # Change only position 0\n",
    "\n",
    "print(\"Testing Position-wise Independence\")\n",
    "print(\"=\" * 50)\n",
    "print(\"x1 and x2 differ ONLY at position 0\")\n",
    "print()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = ffn(x1)\n",
    "    out2 = ffn(x2)\n",
    "\n",
    "# Check each position\n",
    "for pos in range(5):\n",
    "    diff = torch.abs(out1[0, pos] - out2[0, pos]).max().item()\n",
    "    is_same = diff < 1e-6\n",
    "    status = \"‚úÖ Same\" if is_same else \"‚ùå Different\"\n",
    "    print(f\"Position {pos}: {status} (max diff: {diff:.2e})\")\n",
    "\n",
    "print()\n",
    "print(\"Conclusion:\")\n",
    "print(\"‚Ä¢ Positions 1-4 are identical (not affected by change at position 0)\")\n",
    "print(\"‚Ä¢ Position 0 is different (as expected)\")\n",
    "print(\"‚Ä¢ This proves FFN is POSITION-WISE (no cross-position interaction)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871ac61",
   "metadata": {},
   "source": [
    "### **10. Comparing with Attention: Key Differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's contrast FFN with attention!\n",
    "\n",
    "print(\"FFN vs Attention: Key Differences\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "comparison = [\n",
    "    [\"Position Interaction\", \"No (independent)\", \"Yes (all-to-all)\"],\n",
    "    [\"Purpose\", \"Non-linear transformation\", \"Aggregate information\"],\n",
    "    [\"Computation Type\", \"Same weights, different inputs\", \"Content-dependent weights\"],\n",
    "    [\"Parallelism\", \"Fully parallel\", \"Fully parallel\"],\n",
    "    [\"Parameters\", \"~2/3 of layer\", \"~1/3 of layer\"],\n",
    "    [\"Complexity\", \"O(n √ó d¬≤)\", \"O(n¬≤ √ó d)\"],\n",
    "    [\"Role in Layer\", \"Feature transformation\", \"Context aggregation\"],\n",
    "]\n",
    "\n",
    "# Print as table\n",
    "print(f\"{'Aspect':<25} {'FFN':<25} {'Attention':<25}\")\n",
    "print(\"-\" * 75)\n",
    "for row in comparison:\n",
    "    print(f\"{row[0]:<25} {row[1]:<25} {row[2]:<25}\")\n",
    "\n",
    "print()\n",
    "print(\"üîë Key Insight:\")\n",
    "print(\"   Attention = 'What should I pay attention to?'\")\n",
    "print(\"   FFN = 'How should I transform what I've gathered?'\")\n",
    "print(\"   Together, they form a powerful processing unit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629a5f5",
   "metadata": {},
   "source": [
    "### **11. Modern Variations: SwiGLU and Other Alternatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359e4d8",
   "metadata": {},
   "source": [
    "Modern transformers (like LLaMA, PaLM) often use improved FFN variants:\n",
    "\n",
    "#### **SwiGLU (Used in LLaMA, PaLM)**\n",
    "\n",
    "$$\\text{SwiGLU}(x) = (xW_1) \\odot \\text{Swish}(xW_{gate})$$\n",
    "\n",
    "Where:\n",
    "- $\\text{Swish}(x) = x \\cdot \\sigma(x)$ (sigmoid-weighted)\n",
    "- $\\odot$ is element-wise multiplication\n",
    "- $W_1$ and $W_{gate}$ are separate linear projections\n",
    "\n",
    "**Benefits:**\n",
    "- Better gradient flow\n",
    "- Improved training dynamics\n",
    "- Slightly better performance\n",
    "\n",
    "For now, we'll stick with the **original ReLU/GELU FFN** ‚Äì it's simpler and works great for learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Let's implement a simple SwiGLU for the curious!\n",
    "\n",
    "class SwiGLUFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    SwiGLU Feed-Forward Network (used in LLaMA, PaLM)\n",
    "    \n",
    "    SwiGLU(x) = (x @ W1) * Swish(x @ W_gate) @ W2\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # SwiGLU uses 3 linear layers instead of 2\n",
    "        self.w1 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.w2 = nn.Linear(d_ff, d_model, bias=False)\n",
    "        self.w_gate = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Swish activation: x * sigmoid(x)\n",
    "        swish = lambda x: x * torch.sigmoid(x)\n",
    "        \n",
    "        # SwiGLU: (x @ W1) * Swish(x @ W_gate)\n",
    "        gate = swish(self.w_gate(x))\n",
    "        x = self.w1(x) * gate\n",
    "        x = self.dropout(x)\n",
    "        x = self.w2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Quick test\n",
    "swiglu = SwiGLUFeedForward(512, 2048)\n",
    "x_test = torch.randn(2, 10, 512)\n",
    "out_swiglu = swiglu(x_test)\n",
    "print(f\"SwiGLU input shape:  {x_test.shape}\")\n",
    "print(f\"SwiGLU output shape: {out_swiglu.shape}\")\n",
    "print(\"\\nüí° SwiGLU is what LLaMA and PaLM use instead of ReLU/GELU FFN!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbae892",
   "metadata": {},
   "source": [
    "### **12. Summary: What We Built**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd7a2c",
   "metadata": {},
   "source": [
    "Excellent work! You've built the Position-wise Feed-Forward Network! üéâ\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "‚úÖ **Purpose**: Add non-linear transformation power to the Transformer\n",
    "\n",
    "‚úÖ **Architecture**: Two-layer MLP with expand-contract pattern\n",
    "```\n",
    "d_model (512) ‚Üí d_ff (2048) ‚Üí d_model (512)\n",
    "```\n",
    "\n",
    "‚úÖ **Position-wise**: Applied independently to each position (no cross-position interaction)\n",
    "\n",
    "‚úÖ **Activation**: ReLU (original) or GELU (modern transformers)\n",
    "\n",
    "‚úÖ **Parameters**: Contains about 2/3 of the Encoder layer's parameters!\n",
    "\n",
    "‚úÖ **Complement to Attention**: \n",
    "- Attention = Context aggregation (gather information)\n",
    "- FFN = Feature transformation (process information)\n",
    "\n",
    "---\n",
    "\n",
    "**Our Progress:**\n",
    "\n",
    "| Component | Status |\n",
    "|-----------|--------|\n",
    "| Multi-Head Attention | ‚úÖ Day 7 |\n",
    "| Positional Encoding | ‚úÖ Step 1 |\n",
    "| **Feed-Forward Network** | ‚úÖ **Step 2 (Today!)** |\n",
    "| Layer Normalization | ‚è≥ Step 3 |\n",
    "| Residual Connections | ‚è≥ Step 3 |\n",
    "| Complete Encoder Layer | ‚è≥ Step 3 |\n",
    "\n",
    "**Next Up:** In Step 3, we'll combine everything to build the complete Encoder Layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ed896",
   "metadata": {},
   "source": [
    "### **13. Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4765b87",
   "metadata": {},
   "source": [
    "Try these exercises to deepen your understanding!\n",
    "\n",
    "**Exercise 1:** What happens if we set `d_ff = d_model` (no expansion)? Try it and compare outputs.\n",
    "\n",
    "**Exercise 2:** Add a third linear layer to the FFN. Does this improve expressiveness?\n",
    "\n",
    "**Exercise 3:** Implement the SwiGLU variant and compare parameter counts with the standard FFN.\n",
    "\n",
    "**Exercise 4:** Visualize what happens with GELU vs ReLU ‚Äì how do the intermediate activations differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your exercises!\n",
    "\n",
    "# Exercise 1: FFN with no expansion\n",
    "# ffn_no_expand = PositionWiseFeedForward(d_model=512, d_ff=512)  # d_ff = d_model\n",
    "# Compare with standard FFN...\n",
    "\n",
    "# Your code here!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
