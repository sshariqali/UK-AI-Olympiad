{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85428c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<script>\n",
    "const firstCell = document.querySelector('.cell.code_cell');\n",
    "if (firstCell) {\n",
    "  firstCell.querySelector('.input').style.pointerEvents = 'none';\n",
    "  firstCell.querySelector('.input').style.opacity = '0.5';\n",
    "}\n",
    "</script>\n",
    "\"\"\"))\n",
    "\n",
    "html = \"\"\"\n",
    "<div style=\"display:flex; flex-direction:column; align-items:center; text-align:center; gap:12px; padding:8px;\">\n",
    "  <h1 style=\"margin:0;\">ðŸ‘‹ Welcome to <span style=\"color:#1E88E5;\">Algopath Coding Academy</span>!</h1>\n",
    "\n",
    "  <img src=\"https://raw.githubusercontent.com/sshariqali/mnist_pretrained_model/main/algopath_logo.jpg\"\n",
    "       alt=\"Algopath Coding Academy Logo\"\n",
    "       width=\"400\"\n",
    "       style=\"border-radius:15px; box-shadow:0 4px 12px rgba(0,0,0,0.2); max-width:100%; height:auto;\" />\n",
    "\n",
    "  <p style=\"font-size:16px; margin:0;\">\n",
    "    <em>Empowering young minds to think creatively, code intelligently, and build the future with AI.</em>\n",
    "  </p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d865e26",
   "metadata": {},
   "source": [
    "## **1. Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d8dc2",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "The goal is to develop a neural network model that can accurately classify images of clothing items into their respective categories. Given a grayscale image of a clothing item, our model should predict which category it belongs to among 10 different classes.\n",
    "\n",
    "**Dataset: Fashion MNIST**\n",
    "\n",
    "Fashion MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**The 10 Classes:**\n",
    "\n",
    "| Label | Description |\n",
    "|-------|-------------|\n",
    "| 0     | T-shirt/top |\n",
    "| 1     | Trouser     |\n",
    "| 2     | Pullover    |\n",
    "| 3     | Dress       |\n",
    "| 4     | Coat        |\n",
    "| 5     | Sandal      |\n",
    "| 6     | Shirt       |\n",
    "| 7     | Sneaker     |\n",
    "| 8     | Bag         |\n",
    "| 9     | Ankle boot  |\n",
    "\n",
    "**Dataset Properties:**\n",
    "- **Training images:** 60,000\n",
    "- **Test images:** 10,000\n",
    "- **Image size:** 28x28 pixels\n",
    "- **Color:** Grayscale (1 channel)\n",
    "- **Pixel values:** 0-255 (0 = black, 255 = white)\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "To address this problem, we will create a `Multi-Layer Neural Network model` using `PyTorch` to implement `Image Classification` - a Machine Learning task.\n",
    "\n",
    "**Tools**\n",
    "- **NumPy:** A library for scientific computing, mainly involving linear algebra operations.\n",
    "- **Matplotlib:** A library for plotting and visualizing data.\n",
    "- **PyTorch:** A library for flexibility and speed when building deep learning models.\n",
    "- **torchvision:** PyTorch's computer vision library for datasets and transformations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48823c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e39932",
   "metadata": {},
   "source": [
    "## **2. Loading and Exploring the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion-MNIST Train dataset\n",
    "\n",
    "train_data = pd.read_csv('fashion-mnist_train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71877f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Train Labels\n",
    "\n",
    "labels_train = torch.tensor(train_data['label'].to_list(), dtype = torch.long)\n",
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11da91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Train Images\n",
    "\n",
    "images_train = train_data.drop(columns = ['label']).values\n",
    "images_train = torch.tensor(images_train, dtype = torch.float32)\n",
    "images_train = images_train.reshape(-1, 28, 28)\n",
    "images_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca7ed2",
   "metadata": {},
   "source": [
    "**Custom Dataset Class**\n",
    "\n",
    "In PyTorch, creating a custom `Dataset` class is a best practice for organizing data loading logic. It provides several benefits:\n",
    "\n",
    "1.  **Organization:** It keeps data loading, preprocessing, and augmentation logic in one place, making the code cleaner and more maintainable.\n",
    "2.  **Memory Efficiency:** Instead of loading the entire dataset into memory at once, you can load data lazily (on-demand) within the class.\n",
    "3.  **Standard Interface:** It allows your data to work seamlessly with PyTorch's `DataLoader`.\n",
    "\n",
    "The two essential methods provide specific functionality:\n",
    "\n",
    "*   **`__len__(self)`**: Returns the total number of items in the dataset. This allows the `DataLoader` to know how many samples are available and how many batches it can create.\n",
    "*   **`__getitem__(self, idx)`**: Allows the dataset to be indexed like a list (e.g., `dataset[0]`). It retrieves a single sample and its corresponding label at the given index, which is crucial for the `DataLoader` to fetch mini-batches during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a custom Dataset class\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        self.labels = torch.tensor(data.iloc[:, 0].to_numpy(), dtype = torch.long)\n",
    "        self.images = torch.tensor(data.iloc[:, 1:].to_numpy().reshape(-1, 28, 28), dtype = torch.float32)\n",
    "\n",
    "    # Implementing the __len__ method\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # Implementing the __getitem__ method\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the FashionDataset class to load Train and Test datasets\n",
    "\n",
    "train_dataset = FashionDataset('fashion-mnist_train.csv')\n",
    "test_dataset = FashionDataset('fashion-mnist_test.csv')\n",
    "\n",
    "print(f\"CSV Training set size: {len(train_dataset)}\")\n",
    "print(f\"CSV Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Train Images and Labels shapes\n",
    "print(\"Train Images shape:\", train_dataset.images.shape)\n",
    "print(\"Train Labels shape:\", train_dataset.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Test Images and Labels shapes\n",
    "print(\"Test Images shape:\", test_dataset.images.shape)\n",
    "print(\"Test Labels shape:\", test_dataset.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the first image and label using __getitem__ (indexing)\n",
    "first_image, first_label = train_dataset[1]\n",
    "\n",
    "# Visualizing the first image\n",
    "plt.imshow(first_image, cmap = 'gray')\n",
    "plt.title(f\"Label: {first_label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b65c7",
   "metadata": {},
   "source": [
    "**Data Loaders**\n",
    "\n",
    "A DataLoader wraps a dataset and provides:\n",
    "- **Batching:** Groups multiple samples together for efficient training\n",
    "- **Shuffling:** Randomizes the order of samples to improve learning\n",
    "- **Parallel loading:** Loads data in the background while the model trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,           # Shuffle the training data\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,          # Don't shuffle test data\n",
    ")\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b0e1e",
   "metadata": {},
   "source": [
    "## **3. Checking Class Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca768ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label for _, label in train_dataset]\n",
    "unique, counts = np.unique(labels, return_counts = True)\n",
    "print(\"Unique labels:\", unique)\n",
    "print(\"Counts:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95da6c",
   "metadata": {},
   "source": [
    "**Balanced Dataset:** Each class has exactly 6,000 samples in the training set, making this a perfectly balanced dataset. This is ideal for training as the model won't be biased toward any particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1add7b",
   "metadata": {},
   "source": [
    "## **4. Understanding Classification vs Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b2b67",
   "metadata": {},
   "source": [
    "In our previous notebook, we built a model to predict exam scores - a **regression** task. Now we're building a model to classify clothing items - a **classification** task. What's the difference?\n",
    "\n",
    "**Regression vs Classification:**\n",
    "\n",
    "| Aspect | Regression | Classification |\n",
    "|--------|-----------|---------------|\n",
    "| **Output Type** | Continuous numerical value | Discrete category/class |\n",
    "| **Examples** | Predicting exam scores (0-100), house prices, temperature | Identifying clothing type, spam detection, disease diagnosis |\n",
    "| **Previous Task** | Exam Score: 67.5, 89.2, 54.8, etc. | - |\n",
    "| **Current Task** | - | Clothing Type: T-shirt, Trouser, Dress, etc. |\n",
    "| **Output Range** | Any real number (e.g., -âˆž to +âˆž) | Fixed set of categories (e.g., 0-9 for our 10 classes) |\n",
    "| **Loss Function** | Mean Squared Error (MSE) | ? |\n",
    "| **Activation Function** | Identity (linear) | ? |\n",
    "| **Evaluation Metrics** | MSE | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54240054",
   "metadata": {},
   "source": [
    "## **5. Implementing the Neural Network Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3dccb9",
   "metadata": {},
   "source": [
    "Now let's implement our multi-layer neural network using PyTorch. We'll create a class that inherits from `nn.Module`, just like we did with the Perceptron, but this time with multiple layers.\n",
    "\n",
    "**Key Components:**\n",
    "- `nn.Linear`: Implements Weights and Biases to perform $y = xW^T + b$\n",
    "- `nn.ReLU`: ReLU activation function (does something to the Output $y)\n",
    "- `forward()`: This is the \"logic\" hub. It should take the output from nn.Linear and immediately pass it through nn.ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the neural network architecture\n",
    "        \"\"\"\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # Input layer to Hidden layer 1\n",
    "        # Input: 784 pixels (28x28), Output: 128 neurons\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        \n",
    "        # Hidden layer 1 to Hidden layer 2\n",
    "        # Input: 128 neurons, Output: 64 neurons\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Hidden layer 2 to Output layer\n",
    "        # Input: 64 neurons, Output: 10 classes\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        # ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass: define how data flows through the network\n",
    "        \n",
    "        Args:\n",
    "            x: Input images (batch_size, 1, 28, 28)\n",
    "        \n",
    "        Returns:\n",
    "            Output logits (batch_size, 10)\n",
    "        \"\"\"\n",
    "        # Flatten the image from (batch_size, 1, 28, 28) to (batch_size, 784)\n",
    "        x = x.reshape(-1, 28 * 28)\n",
    "        \n",
    "        # Layer 1: Linear transformation + ReLU activation\n",
    "        x = self.fc1(x)      # (batch_size, 784) -> (batch_size, 128)\n",
    "        x = self.relu(x)     # Apply ReLU activation\n",
    "        \n",
    "        # Layer 2: Linear transformation + ReLU activation\n",
    "        x = self.fc2(x)      # (batch_size, 128) -> (batch_size, 64)\n",
    "        x = self.relu(x)     # Apply ReLU activation\n",
    "        \n",
    "        # Output layer: Linear transformation (no activation here)\n",
    "        # Softmax will be applied automatically by the loss function\n",
    "        x = self.fc3(x)      # (batch_size, 64) -> (batch_size, 10)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of our model\n",
    "model = FashionMNISTNet().to(device)  # Move model to GPU if available\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af99697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb683014",
   "metadata": {},
   "source": [
    "**Understanding the Parameter Count:**\n",
    "\n",
    "Let's break down where all these parameters come from:\n",
    "\n",
    "1. **Layer 1 (fc1):** 784 â†’ 128\n",
    "   - Weights: 784 Ã— 128 = 100,352\n",
    "   - Biases: 128\n",
    "   - Total: 100,480 parameters\n",
    "\n",
    "2. **Layer 2 (fc2):** 128 â†’ 64\n",
    "   - Weights: 128 Ã— 64 = 8,192\n",
    "   - Biases: 64\n",
    "   - Total: 8,256 parameters\n",
    "\n",
    "3. **Layer 3 (fc3):** 64 â†’ 10\n",
    "   - Weights: 64 Ã— 10 = 640\n",
    "   - Biases: 10\n",
    "   - Total: 650 parameters\n",
    "\n",
    "**Grand Total:** 100,480 + 8,256 + 650 = **109,386 parameters**\n",
    "\n",
    "Each of these parameters will be learned during training to minimize our loss function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25edf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b74058",
   "metadata": {},
   "source": [
    "Now comes the exciting part - training our neural network! The training process is similar to what we did with the perceptron, but with some important differences:\n",
    "\n",
    "**Training Loop Components:**\n",
    "\n",
    "1. **Epochs:** Complete passes through the entire training dataset\n",
    "2. **Batches:** Process multiple images at once (faster and more stable than one at a time)\n",
    "3. **Forward Pass:** Feed data through the network to get predictions\n",
    "4. **Loss Calculation:** Measure how wrong the predictions are\n",
    "5. **Backward Pass:** Calculate gradients (how to adjust each parameter)\n",
    "6. **Parameter Update:** Use optimizer to adjust weights and biases\n",
    "\n",
    "**Why Train in Batches?**\n",
    "\n",
    "Instead of using all 60,000 images at once (too memory-intensive) or one image at a time (too slow and unstable), we use **mini-batches** of 64 images:\n",
    "\n",
    "- **Computational Efficiency:** GPUs are optimized for parallel processing\n",
    "- **Memory Management:** Fits in GPU/CPU memory\n",
    "- **Better Gradients:** Averaging over a batch gives more stable gradient estimates\n",
    "- **Faster Convergence:** Updates happen more frequently than full-batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Iterate through batches\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # Move data to device (GPU if available)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Forward pass: compute predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 2. Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 3. Backward pass: compute gradients\n",
    "        loss.backward()        # Compute new gradients\n",
    "        \n",
    "        # 4. Update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average loss and accuracy for this epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "            f\"Loss: {epoch_loss:.4f} | \"\n",
    "            f\"Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95263637",
   "metadata": {},
   "source": [
    "## **6. Evaluating on the Test Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5aa58",
   "metadata": {},
   "source": [
    "Training accuracy tells us how well the model performs on data it has seen. But the real test is: **Can it generalize to new, unseen data?**\n",
    "\n",
    "This is why we have a separate **test set** - 10,000 images the model has never seen during training.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "1. **Generalization:** The ability to perform well on new data\n",
    "2. **Overfitting:** When training accuracy is high but test accuracy is low (model memorized training data)\n",
    "3. **Underfitting:** When both training and test accuracy are low (model is too simple)\n",
    "4. **Good Fit:** When both training and test accuracy are high and similar\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*_7OPgojau8hkiPUiHoGK_w.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**What We're Measuring:**\n",
    "- **Accuracy:** Percentage of correct predictions\n",
    "- **Per-Class Performance:** How well the model performs on each clothing type\n",
    "- **Confusion Matrix:** Where the model makes mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397faed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Don't compute gradients during evaluation (saves memory and computation)\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device) # If GPU is available\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Overall accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Store for confusion matrix\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378afc1",
   "metadata": {},
   "source": [
    "## **7. Conclusion and Key Takeaways**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b22c75",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully built, trained, and evaluated a multi-layer neural network for image classification. Let's summarize what we've learned:\n",
    "\n",
    "**ðŸŽ¯ What We Accomplished:**\n",
    "\n",
    "1. âœ… Loaded and explored the Fashion MNIST dataset (70,000 images)\n",
    "2. âœ… Built a 3-layer neural network with 109,386 parameters\n",
    "3. âœ… Trained the model using Cross-Entropy Loss and Adam optimizer\n",
    "4. âœ… Achieved ~85-90% accuracy on unseen test data\n",
    "5. âœ… Analyzed performance using confusion matrices and visualizations\n",
    "\n",
    "**ðŸ”‘ Key Concepts Learned:**\n",
    "\n",
    "1. **Classification vs Regression:**\n",
    "   - Classification predicts discrete categories\n",
    "   - Requires different loss functions (Cross-Entropy) and activations (Softmax)\n",
    "\n",
    "2. **Multi-Layer Neural Networks:**\n",
    "   - Stack layers to learn hierarchical features\n",
    "   - Use activation functions (ReLU) for non-linearity\n",
    "   - More layers = more complex patterns can be learned\n",
    "\n",
    "3. **Training Process:**\n",
    "   - Forward pass â†’ Loss calculation â†’ Backward pass â†’ Parameter update\n",
    "   - Mini-batch training for efficiency\n",
    "   - Monitoring loss and accuracy to track learning\n",
    "\n",
    "4. **Evaluation:**\n",
    "   - Test set measures generalization ability\n",
    "   - Confusion matrix reveals where errors occur\n",
    "   - Per-class accuracy shows strengths and weaknesses\n",
    "\n",
    "**ðŸ’¡ Important Insights:**\n",
    "\n",
    "- **Simple items** (Trousers, Bags, Sneakers) are easier to classify\n",
    "- **Similar items** (T-shirt vs Shirt, Pullover vs Coat) get confused\n",
    "- **Architecture matters:** More layers and neurons generally improve performance\n",
    "- **Hyperparameters** (learning rate, batch size, epochs) significantly impact results\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŒŸ You've now mastered the fundamentals of neural networks! Keep exploring and building more complex models!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c223eef",
   "metadata": {},
   "source": [
    "## **8. Challenge Exercises (HomeWork)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1992cb",
   "metadata": {},
   "source": [
    "Ready to test your understanding? Try these challenges:\n",
    "\n",
    "**Challenge 1: Modify the Architecture**\n",
    "- Change the network to have 4 layers instead of 3\n",
    "- Try different neuron counts (e.g., 256 â†’ 128 â†’ 64 â†’ 10)\n",
    "- Compare the results with the original architecture\n",
    "\n",
    "**Challenge 2: Experiment with Hyperparameters**\n",
    "- Train for 20 epochs instead of 10\n",
    "- Try different learning rates (0.0001, 0.01, 0.1)\n",
    "- Change the batch size (32, 128, 256)\n",
    "\n",
    "**Challenge 3: Analyze Specific Classes**\n",
    "- Focus on the two classes with lowest accuracy\n",
    "- Visualize 20 misclassified examples from these classes\n",
    "- Can you spot patterns in why the model fails?\n",
    "\n",
    "**Challenge 4: Save and Load the Model**\n",
    "```python\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'fashion_mnist_model.pth')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = FashionMNISTNet().to(device)\n",
    "loaded_model.load_state_dict(torch.load('fashion_mnist_model.pth'))\n",
    "```\n",
    "\n",
    "**Challenge 5: Try Different Optimizers**\n",
    "- Replace Adam with SGD with momentum\n",
    "- Compare training curves and final accuracy\n",
    "- Which optimizer works better for this task?\n",
    "\n",
    "---\n",
    "\n",
    "Good luck, and happy coding! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
