{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Homework\n",
    "\n",
    "Welcome to your homework on **Neural Networks with PyTorch**!\n",
    "\n",
    "In this notebook, you will practice the concepts from today's lesson:\n",
    "- Data preprocessing (missing values, encoding, normalization)\n",
    "- Building a Perceptron model with `torch.nn`\n",
    "- Training loop (forward pass, loss, backward pass, optimizer)\n",
    "- Interpreting learned parameters\n",
    "\n",
    "**Instructions:**\n",
    "- Fill in the code cells marked with `# YOUR CODE HERE`\n",
    "- Do NOT change any other code\n",
    "- Make sure the CSV file `StudentPerformanceFactors.csv` is in the same folder\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 1: Conceptual Questions\n",
    "\n",
    "Answer the following questions by assigning the correct option letter (as a string) to each variable.\n",
    "\n",
    "**1a)** What type of machine learning is it when we train a model using data that includes both inputs and known outputs?\n",
    "- A: Unsupervised Learning\n",
    "- B: Supervised Learning\n",
    "- C: Reinforcement Learning\n",
    "- D: Transfer Learning\n",
    "\n",
    "**1b)** What is the difference between an **algorithm** and a **model**?\n",
    "- A: An algorithm is the trained result; a model is the procedure\n",
    "- B: An algorithm is a set of rules for learning; a model is the result after training with learned parameters\n",
    "- C: They are the same thing\n",
    "- D: A model is always a neural network; an algorithm is not\n",
    "\n",
    "**1c)** A Perceptron with an identity activation function is mathematically equivalent to:\n",
    "- A: Logistic Regression\n",
    "- B: K-Nearest Neighbors\n",
    "- C: Multiple Linear Regression\n",
    "- D: Decision Tree\n",
    "\n",
    "**1d)** Why do we normalize features before training a model?\n",
    "- A: To make the dataset smaller\n",
    "- B: To remove missing values\n",
    "- C: So that features with larger scales don't dominate those with smaller scales\n",
    "- D: To convert categorical data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "answer_1a = \"__\"  # Replace __ with A, B, C, or D\n",
    "answer_1b = \"__\"\n",
    "answer_1c = \"__\"\n",
    "answer_1d = \"__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2: Handling Missing Values\n",
    "\n",
    "The small dataset below has missing values. Your task is to:\n",
    "\n",
    "1. Find which columns have missing values\n",
    "2. Fill the missing values in `City` with the **mode** (most frequent value)\n",
    "3. Fill the missing values in `Rating` with the **mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset ---\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank'],\n",
    "    'City': ['London', 'London', None, 'Paris', 'London', None],\n",
    "    'Rating': [4.5, None, 3.8, 4.2, None, 3.5]\n",
    "})\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Fill missing values in 'City' with the mode (most frequent value)\n",
    "df['City'] = ...\n",
    "\n",
    "# Fill missing values in 'Rating' with the mean\n",
    "df['Rating'] = ...\n",
    "\n",
    "print(\"After:\")\n",
    "print(df)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 3: Encoding Categorical Data\n",
    "\n",
    "Given the dataset below:\n",
    "\n",
    "1. Apply **Label Encoding** to the binary column `Has_Car` (Yes -> 1, No -> 0)\n",
    "2. Apply **One-Hot Encoding** to the multi-class column `Department`\n",
    "\n",
    "**Reminder:**\n",
    "- Label Encoding is for binary (2 options) or ordinal data\n",
    "- One-Hot Encoding is for nominal (unranked) multi-class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset ---\n",
    "df_enc = pd.DataFrame({\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Has_Car': ['Yes', 'No', 'Yes', 'No', 'Yes'],\n",
    "    'Department': ['Sales', 'Engineering', 'Sales', 'HR', 'Engineering'],\n",
    "    'Salary': [50000, 70000, 52000, 60000, 75000]\n",
    "})\n",
    "\n",
    "print(\"Before encoding:\")\n",
    "print(df_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Label encode 'Has_Car' (Yes -> 1, No -> 0)\n",
    "df_enc['Has_Car'] = ...\n",
    "\n",
    "# Step 2: One-hot encode 'Department'\n",
    "df_enc = ...\n",
    "\n",
    "print(\"After encoding:\")\n",
    "print(df_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 4: Z-Score Normalization\n",
    "\n",
    "Implement the Z-score normalization function:\n",
    "\n",
    "$$X_{\\text{norm}} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Then apply it to the `Salary` column from the dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = np.array([50000, 70000, 52000, 60000, 75000], dtype=np.float64)\n",
    "print(f\"Original salaries: {salaries}\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Step 1: Compute the mean\n",
    "mu = ...\n",
    "\n",
    "# Step 2: Compute the standard deviation\n",
    "sigma = ...\n",
    "\n",
    "# Step 3: Apply z-score normalization\n",
    "salaries_norm = ...\n",
    "\n",
    "print(f\"Mean: {mu}\")\n",
    "print(f\"Std: {sigma:.2f}\")\n",
    "print(f\"Normalized salaries: {salaries_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 5: Encoding Questions\n",
    "\n",
    "For each column described below, decide whether you should use **Label Encoding** or **One-Hot Encoding**.\n",
    "\n",
    "**5a)** A column `Color` with values: `Red`, `Blue`, `Green`\n",
    "- A: Label Encoding\n",
    "- B: One-Hot Encoding\n",
    "\n",
    "**5b)** A column `Smoker` with values: `Yes`, `No`\n",
    "- A: Label Encoding\n",
    "- B: One-Hot Encoding\n",
    "\n",
    "**5c)** A column `Education` with values: `High School`, `Bachelor`, `Master`, `PhD` (you are certain of the ranking)\n",
    "- A: Label Encoding\n",
    "- B: One-Hot Encoding\n",
    "\n",
    "**5d)** A column `Country` with values: `UK`, `France`, `Germany`, `Italy`\n",
    "- A: Label Encoding\n",
    "- B: One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "answer_5a = \"__\"  # Replace __ with A or B\n",
    "answer_5b = \"__\"\n",
    "answer_5c = \"__\"\n",
    "answer_5d = \"__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 6: Build and Train a Perceptron\n",
    "\n",
    "Now let's put it all together! You will build a **Perceptron** model to predict a student's exam score using the `StudentPerformanceFactors.csv` dataset.\n",
    "\n",
    "The data preprocessing has been done for you. Your tasks are to:\n",
    "\n",
    "1. Define the Perceptron model class\n",
    "2. Create the loss function and optimizer\n",
    "3. Implement the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preprocessing (already done for you) ---\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('StudentPerformanceFactors.csv')\n",
    "\n",
    "# Fill missing values\n",
    "data['Teacher_Quality'] = data['Teacher_Quality'].fillna(data['Teacher_Quality'].mode()[0])\n",
    "data['Parental_Education_Level'] = data['Parental_Education_Level'].fillna(data['Parental_Education_Level'].mode()[0])\n",
    "data['Distance_from_Home'] = data['Distance_from_Home'].fillna(data['Distance_from_Home'].mode()[0])\n",
    "\n",
    "# Label encode binary columns\n",
    "binary_cols = [col for col in data.columns if data[col].dtype == 'object' and data[col].nunique() == 2]\n",
    "for col in binary_cols:\n",
    "    data[col] = data[col].map({data[col].unique()[0]: 0, data[col].unique()[1]: 1})\n",
    "\n",
    "# One-hot encode multi-class columns\n",
    "multi_cols = [col for col in data.columns if data[col].dtype == 'object' and data[col].nunique() > 2]\n",
    "data = pd.get_dummies(data, columns=multi_cols)\n",
    "\n",
    "# Normalize features\n",
    "for column in data.columns:\n",
    "    if column != 'Exam_Score':\n",
    "        mu = np.mean(data[column])\n",
    "        sigma = np.std(data[column])\n",
    "        data[column] = (data[column] - mu) / sigma\n",
    "\n",
    "# Split features and target\n",
    "x = data.drop('Exam_Score', axis=1)\n",
    "y = data['Exam_Score']\n",
    "\n",
    "# Convert to tensors\n",
    "x_tensor = torch.tensor(x.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "input_size = x_tensor.shape[1]\n",
    "print(f\"Input features: {input_size}\")\n",
    "print(f\"x_tensor shape: {x_tensor.shape}\")\n",
    "print(f\"y_tensor shape: {y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Perceptron Model\n",
    "\n",
    "Create a class called `Perceptron` that:\n",
    "- Inherits from `torch.nn.Module`\n",
    "- Has a single `torch.nn.Linear` layer with the correct input and output sizes\n",
    "- Has a `forward` method that passes the input through the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class Perceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(Perceptron, self).__init__()\n",
    "        # Create a linear layer: input_size -> 1\n",
    "        self.linear = ...  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass x through the linear layer and return the result\n",
    "        return ...\n",
    "\n",
    "# Create the model\n",
    "model = Perceptron(input_size)\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Loss Function and Optimizer\n",
    "\n",
    "- Use `torch.nn.MSELoss()` as the loss function\n",
    "- Use `torch.optim.SGD` as the optimizer with `learning_rate = 0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "criterion = ...  # MSE Loss\n",
    "learning_rate = 0.01\n",
    "optimizer = ...  # SGD optimizer with model parameters and learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the Model\n",
    "\n",
    "Implement the training loop for **1000 epochs**. For each epoch:\n",
    "1. Forward pass: get predictions from the model\n",
    "2. Compute the loss using the criterion\n",
    "3. Backward pass: call `loss.backward()`\n",
    "4. Update weights: call `optimizer.step()`\n",
    "5. Clear gradients: call `optimizer.zero_grad()`\n",
    "6. Print the loss every 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "num_epochs = 1000\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pass  # Replace with your implementation\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Final Loss: {loss_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 7: Interpret the Results\n",
    "\n",
    "After training, examine the model's learned weights and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This cell extracts and displays the model's learned parameters ---\n",
    "weights = model.linear.weight.data.numpy().flatten()\n",
    "bias = model.linear.bias.data.numpy()[0]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': x.columns,\n",
    "    'Weight': weights\n",
    "})\n",
    "feature_importance['Abs_Weight'] = feature_importance['Weight'].abs()\n",
    "feature_importance = feature_importance.sort_values('Abs_Weight', ascending=False)\n",
    "\n",
    "print(f\"Bias: {bias:.4f}\")\n",
    "print(f\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7a)** If a feature has a **positive** weight, what does that mean?\n",
    "- A: As the feature increases, the predicted exam score decreases\n",
    "- B: As the feature increases, the predicted exam score increases\n",
    "- C: The feature has no effect on the prediction\n",
    "- D: The feature should be removed\n",
    "\n",
    "**7b)** If a feature has a **negative** weight, what does that mean?\n",
    "- A: The feature is not important\n",
    "- B: As the feature increases, the predicted exam score increases\n",
    "- C: As the feature increases, the predicted exam score decreases\n",
    "- D: The model is broken\n",
    "\n",
    "**7c)** Which tells you how **important** a feature is to the model?\n",
    "- A: The sign (positive/negative) of the weight\n",
    "- B: The absolute value (magnitude) of the weight\n",
    "- C: The name of the feature\n",
    "- D: The order in which features appear in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "answer_7a = \"__\"  # Replace __ with A, B, C, or D\n",
    "answer_7b = \"__\"\n",
    "answer_7c = \"__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 8: Training Loop Components\n",
    "\n",
    "Put the training loop steps in the correct order by assigning numbers 1-5.\n",
    "\n",
    "- `optimizer.zero_grad()` - Clear previous gradients\n",
    "- `loss = criterion(predictions, y_tensor)` - Calculate loss\n",
    "- `predictions = model(x_tensor)` - Forward pass\n",
    "- `optimizer.step()` - Update weights\n",
    "- `loss.backward()` - Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Assign the correct order number (1-5) for each step\n",
    "step_forward_pass = ...       # predictions = model(x_tensor)\n",
    "step_calculate_loss = ...     # loss = criterion(predictions, y_tensor)\n",
    "step_backward_pass = ...      # loss.backward()\n",
    "step_update_weights = ...     # optimizer.step()\n",
    "step_zero_gradients = ...     # optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: Make a Prediction\n",
    "\n",
    "Using the trained model, predict the exam score for a new student. The data has already been preprocessed (normalized and encoded) for you.\n",
    "\n",
    "Remember: to make a prediction with a trained PyTorch model, you pass the input tensor through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new student's data (already preprocessed)\n",
    "# This represents a student who studies a lot, has high attendance, etc.\n",
    "new_student = torch.zeros(1, input_size)  # Start with zeros\n",
    "new_student[0, 0] = 1.5   # High hours studied (normalized)\n",
    "new_student[0, 1] = 1.5   # High attendance (normalized)\n",
    "new_student[0, 4] = 1.0   # High previous scores (normalized)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Use the model to predict this student's exam score\n",
    "# Hint: wrap the prediction in torch.no_grad() since we're not training\n",
    "with torch.no_grad():\n",
    "    predicted_score = ...\n",
    "\n",
    "print(f\"Predicted exam score: {predicted_score.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this homework you practiced:\n",
    "\n",
    "1. **Core concepts** of supervised learning, algorithms vs models, and perceptrons\n",
    "2. **Handling missing values** using mode and mean\n",
    "3. **Encoding categorical data** using label encoding and one-hot encoding\n",
    "4. **Z-score normalization** to standardize feature scales\n",
    "5. **Choosing the right encoding** for different types of data\n",
    "6. **Building a Perceptron** model using `torch.nn.Module`\n",
    "7. **Interpreting model weights** to understand feature importance\n",
    "8. **Understanding the training loop** step by step\n",
    "\n",
    "Great work! You now have the foundations for building neural networks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
