{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Homework - Answer Key\n",
    "\n",
    "Run the student's homework notebook first, then run these cells to check their answers.\n",
    "\n",
    "**Note:** This notebook expects all variables from the homework to already be defined (e.g. run both notebooks in the same kernel, or copy the student's code here before checking).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Conceptual Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "assert answer_1a == \"B\", \"Hint: Supervised Learning uses labeled data (inputs + known outputs).\"\n",
    "assert answer_1b == \"B\", \"Hint: An algorithm is the procedure; a model is the trained result with learned parameters.\"\n",
    "assert answer_1c == \"C\", \"Hint: A single linear layer with identity activation is y = w1*x1 + w2*x2 + ... + b.\"\n",
    "assert answer_1d == \"C\", \"Hint: Normalization ensures features contribute equally regardless of their original scale.\"\n",
    "print(\"All Q1 answers correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "assert df['City'].isnull().sum() == 0, \"City column still has missing values.\"\n",
    "assert df['Rating'].isnull().sum() == 0, \"Rating column still has missing values.\"\n",
    "assert (df['City'] == 'London').sum() >= 3, \"Hint: The mode of City is 'London' - missing values should be filled with 'London'.\"\n",
    "assert abs(df['Rating'].mean() - 4.0) < 0.01, \"Hint: The mean of Rating should be 4.0 after filling.\"\n",
    "print(\"Q2 correct! Missing values filled properly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "assert df_enc['Has_Car'].dtype in [np.int64, np.int32, int, np.int_], f\"Has_Car should be numeric, got {df_enc['Has_Car'].dtype}\"\n",
    "assert set(df_enc['Has_Car'].unique()) == {0, 1}, \"Has_Car should only contain 0 and 1.\"\n",
    "assert 'Department' not in df_enc.columns, \"Department column should be replaced by one-hot encoded columns.\"\n",
    "dept_cols = [col for col in df_enc.columns if 'Department' in col or 'Sales' in col or 'Engineering' in col or 'HR' in col]\n",
    "assert len(dept_cols) >= 2, \"One-hot encoding should create separate columns for each department.\"\n",
    "print(\"Q3 correct! Encoding applied properly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Z-Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "expected_mu = np.mean([50000, 70000, 52000, 60000, 75000])\n",
    "expected_sigma = np.std([50000, 70000, 52000, 60000, 75000])\n",
    "expected_norm = (np.array([50000, 70000, 52000, 60000, 75000]) - expected_mu) / expected_sigma\n",
    "\n",
    "assert abs(mu - expected_mu) < 1, f\"Mean should be {expected_mu}, got {mu}\"\n",
    "assert abs(sigma - expected_sigma) < 1, f\"Std should be {expected_sigma:.2f}, got {sigma:.2f}\"\n",
    "assert np.allclose(salaries_norm, expected_norm, atol=1e-4), f\"Normalized values are incorrect.\"\n",
    "assert abs(np.mean(salaries_norm)) < 1e-10, \"After z-score normalization, the mean should be approximately 0.\"\n",
    "print(f\"Q4 correct! Mean={mu}, Std={sigma:.2f}\")\n",
    "print(f\"Normalized: {salaries_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Encoding Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "assert answer_5a == \"B\", \"Hint: Colors have no natural order, so use One-Hot Encoding.\"\n",
    "assert answer_5b == \"A\", \"Hint: Binary (Yes/No) columns use Label Encoding (0 or 1).\"\n",
    "assert answer_5c == \"A\", \"Hint: Education has a clear ranking and you're certain of it, so Label Encoding works.\"\n",
    "assert answer_5d == \"B\", \"Hint: Countries have no natural order, so use One-Hot Encoding.\"\n",
    "print(\"All Q5 answers correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Build and Train a Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "# Check model architecture\n",
    "assert hasattr(model, 'linear'), \"Model should have a 'linear' attribute (nn.Linear layer).\"\n",
    "assert model.linear.in_features == input_size, f\"Linear layer should have {input_size} input features.\"\n",
    "assert model.linear.out_features == 1, \"Linear layer should have 1 output.\"\n",
    "\n",
    "# Check that training happened\n",
    "assert len(loss_history) == 1000, f\"Expected 1000 epochs, got {len(loss_history)}.\"\n",
    "assert loss_history[-1] < loss_history[0], \"Loss should decrease during training.\"\n",
    "assert loss_history[-1] < 10.0, f\"Final loss should be below 10, got {loss_history[-1]:.4f}.\"\n",
    "\n",
    "print(f\"Q6 correct!\")\n",
    "print(f\"  Model has {sum(p.numel() for p in model.parameters())} parameters.\")\n",
    "print(f\"  Initial loss: {loss_history[0]:.4f}\")\n",
    "print(f\"  Final loss: {loss_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Interpret the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "assert answer_7a == \"B\", \"Hint: Positive weight means the feature and prediction move in the same direction.\"\n",
    "assert answer_7b == \"C\", \"Hint: Negative weight means the feature and prediction move in opposite directions.\"\n",
    "assert answer_7c == \"B\", \"Hint: The absolute value (magnitude) tells you how strongly a feature affects the prediction.\"\n",
    "print(\"All Q7 answers correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Training Loop Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Checking your answers ---\n",
    "assert step_forward_pass == 1, \"Hint: The forward pass (getting predictions) is the first step.\"\n",
    "assert step_calculate_loss == 2, \"Hint: After getting predictions, we calculate the loss.\"\n",
    "assert step_backward_pass == 3, \"Hint: After calculating loss, we compute gradients with backward().\"\n",
    "assert step_update_weights == 4, \"Hint: After computing gradients, we update weights with optimizer.step().\"\n",
    "assert step_zero_gradients == 5, \"Hint: After updating weights, we clear gradients for the next iteration.\"\n",
    "print(\"Q8 correct! Training loop order is: forward -> loss -> backward -> step -> zero_grad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
