{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0lAI4wJsxyUI",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1762107289572,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "0lAI4wJsxyUI",
    "outputId": "46faec05-737f-4121-d4f1-ac1985f00332"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<script>\n",
    "const firstCell = document.querySelector('.cell.code_cell');\n",
    "if (firstCell) {\n",
    "  firstCell.querySelector('.input').style.pointerEvents = 'none';\n",
    "  firstCell.querySelector('.input').style.opacity = '0.5';\n",
    "}\n",
    "</script>\n",
    "\"\"\"))\n",
    "\n",
    "html = \"\"\"\n",
    "<div style=\"display:flex; flex-direction:column; align-items:center; text-align:center; gap:12px; padding:8px;\">\n",
    "  <h1 style=\"margin:0;\">üëã Welcome to <span style=\"color:#1E88E5;\">Algopath Coding Academy</span>!</h1>\n",
    "\n",
    "  <img src=\"https://raw.githubusercontent.com/sshariqali/mnist_pretrained_model/main/algopath_logo.jpg\"\n",
    "       alt=\"Algopath Coding Academy Logo\"\n",
    "       width=\"400\"\n",
    "       style=\"border-radius:15px; box-shadow:0 4px 12px rgba(0,0,0,0.2); max-width:100%; height:auto;\" />\n",
    "\n",
    "  <p style=\"font-size:16px; margin:0;\">\n",
    "    <em>Empowering young minds to think creatively, code intelligently, and build the future with AI.</em>\n",
    "  </p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f92fa",
   "metadata": {
    "id": "457f92fa"
   },
   "source": [
    "# PyTorch Tensors Tutorial\n",
    "\n",
    "\n",
    "**Table of Contents:**\n",
    "1. [Introduction to PyTorch](#1)\n",
    "2. [Creating Tensors](#2)\n",
    "3. [Tensor Attributes and Properties](#3)\n",
    "4. [Tensor Indexing Slicing and Filtering](#4)\n",
    "5. [Tensor Operations](#5)\n",
    "6. [Tensor Manipulation](#6)\n",
    "7. [GPU Interaction](#7)\n",
    "8. [NumPy vs PyTorch Comparison](#8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd53d1",
   "metadata": {
    "id": "23bd53d1"
   },
   "source": [
    "<a name='1'></a>\n",
    "## **1. Introduction to PyTorch Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8m3FnYCs4iDO",
   "metadata": {
    "id": "8m3FnYCs4iDO"
   },
   "source": [
    "### What is PyTorch?\n",
    "PyTorch is an open-source deep learning library developed by Facebook's AI Research lab. It provides:\n",
    "- Tensor computation with strong GPU acceleration\n",
    "- Automatic differentiation for building neural networks\n",
    "- A flexible and intuitive API for research and production\n",
    "\n",
    "### What is a Tensor?\n",
    "A **tensor** is the core data structure in PyTorch. Think of it as:\n",
    "- Similar to a NumPy `ndarray` but with additional capabilities\n",
    "- Can run on GPUs for accelerated computing\n",
    "- Supports automatic differentiation (autograd) for neural network training\n",
    "- A multi-dimensional array that can represent scalars, vectors, matrices, and higher-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df007a87",
   "metadata": {
    "id": "df007a87"
   },
   "source": [
    "### Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb692616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10634,
     "status": "ok",
     "timestamp": 1762202366615,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "eb692616",
    "outputId": "c79502e5-e38e-4d29-bd3d-ee1233ca0abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a611a",
   "metadata": {
    "id": "d54a611a"
   },
   "source": [
    "### Setting up your Device\n",
    "Check if CUDA (GPU) is available and set the device accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de0b3891",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1762202394435,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "de0b3891",
    "outputId": "21c3bad7-ee1c-45cd-c44c-7335390c87a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "GPU not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c184a2",
   "metadata": {
    "id": "67c184a2"
   },
   "source": [
    "---\n",
    "<a name='2'></a>\n",
    "## **2. Creating Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DscBqY7M4llk",
   "metadata": {
    "id": "DscBqY7M4llk"
   },
   "source": [
    "### From Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d016abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 12, 25,  5, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.tensor() - from Python lists or tuples\n",
    "tensor_1d = torch.tensor([9, 12, 25, 5, 10])\n",
    "tensor_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a180ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 12, 25],\n",
       "        [ 5, 10, 16]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D tensor from nested list\n",
    "tensor_2d = torch.tensor([[9, 12, 25], [5, 10, 16]])\n",
    "tensor_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c299076",
   "metadata": {
    "id": "3c299076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 15, 20, 25])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.from_numpy() - from NumPy array\n",
    "np_array = np.array([12, 15, 20, 25])\n",
    "tensor_from_numpy = torch.from_numpy(np_array)\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3b29a",
   "metadata": {
    "id": "fcb3b29a"
   },
   "source": [
    "### Creating New Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f3a607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros()\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88fc78d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones()\n",
    "ones_tensor = torch.ones(3,4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de709c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0664, 0.1018, 0.5533],\n",
       "        [0.7426, 0.2093, 0.7567],\n",
       "        [0.7145, 0.8365, 0.5752]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rand() - uniform distribution [0, 1)\n",
    "# random values between 0 and 1. Uniform distribution means all values are equally likely.\n",
    "rand_uniform = torch.rand(3, 3)\n",
    "rand_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb35bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange() - sequence of values\n",
    "arange_tensor = torch.arange(0, 10, 2)\n",
    "arange_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5daebc",
   "metadata": {
    "id": "dd5daebc"
   },
   "source": [
    "---\n",
    "<a name='3'></a>\n",
    "## **3. Tensor Attributes and Properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cef5fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6774, 0.1257, 0.0521],\n",
       "        [0.7637, 0.2455, 0.7043]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "sample_tensor = torch.rand(2, 3)\n",
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d92a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type\n",
    "sample_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58a1948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "sample_tensor.shape # sample_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff85faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check which device the tensor is on\n",
    "print(sample_tensor.device)\n",
    "\n",
    "# Move tensor to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    sample_tensor = sample_tensor.to('cuda')\n",
    "    print(sample_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46848b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of dimensions\n",
    "sample_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70b2c874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of elements\n",
    "sample_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71e79efa",
   "metadata": {
    "id": "71e79efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer tensor dtype: torch.int64\n",
      "Float tensor dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with specific dtypes\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype = torch.long)\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype = torch.float32)\n",
    "print(f\"Integer tensor dtype: {int_tensor.dtype}\")\n",
    "print(f\"Float tensor dtype: {float_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d156fe",
   "metadata": {
    "id": "b8d156fe"
   },
   "source": [
    "---\n",
    "<a name='4'></a>\n",
    "## **4. Tensor Indexing, Slicing, and Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7079ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9331, 0.6773, 0.4257, 0.3674, 0.4492, 0.2314],\n",
       "        [0.4501, 0.4761, 0.1579, 0.5700, 0.2652, 0.7457],\n",
       "        [0.0918, 0.8349, 0.4894, 0.7036, 0.5727, 0.9568],\n",
       "        [0.8287, 0.4557, 0.0399, 0.1880, 0.2801, 0.4225]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor for indexing\n",
    "tensor = torch.rand(4,6)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70d591c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9331)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard indexing\n",
    "tensor[0, 0] # Access element at row 0, column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a31da7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9331, 0.6773, 0.4257, 0.3674, 0.4492, 0.2314])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing rows and columns\n",
    "tensor[0] # First row\n",
    "# tensor[:, 1] # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4f1d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9331, 0.6773, 0.4257, 0.3674, 0.4492, 0.2314],\n",
       "        [0.4501, 0.4761, 0.1579, 0.5700, 0.2652, 0.7457]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing\n",
    "tensor[0:2] # First 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c642274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1579, 0.5700],\n",
       "        [0.4894, 0.7036]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1:3, 2:4] # Rows 1-3, Columns 2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20cf4cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean mask (elements > 10):\n",
      "tensor([[ True,  True, False, False, False, False],\n",
      "        [False, False, False,  True, False,  True],\n",
      "        [False,  True, False,  True,  True,  True],\n",
      "        [ True, False, False, False, False, False]])\n",
      "\n",
      "Filtered values (> 10):\n",
      "tensor([0.9331, 0.6773, 0.5700, 0.7457, 0.8349, 0.7036, 0.5727, 0.9568, 0.8287])\n"
     ]
    }
   ],
   "source": [
    "# Boolean/Masked indexing\n",
    "mask = tensor > 0.5\n",
    "print(\"Boolean mask (elements > 0.5):\") # \n",
    "print(mask) # boolean mask retains the original tensor's shape\n",
    "print(\"\\nFiltered values (> 0.5):\")\n",
    "print(tensor[mask]) # filtered values are a 1D array of only the elements that meet the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d03b2828",
   "metadata": {
    "id": "d03b2828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9331, 0.6773, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5700, 0.0000, 0.7457],\n",
       "        [0.0000, 0.8349, 0.0000, 0.7036, 0.5727, 0.9568],\n",
       "        [0.8287, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.where() - conditional selection\n",
    "result = torch.where(tensor > 0.5, tensor, torch.tensor(0)) # replace values <= 0.5 with 0\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e3e8a",
   "metadata": {
    "id": "0b1e3e8a"
   },
   "source": [
    "---\n",
    "<a name='5'></a>\n",
    "## **5. Tensor Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3wIYTj8B4pAQ",
   "metadata": {
    "id": "3wIYTj8B4pAQ"
   },
   "source": [
    "### Element-wise Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9ed3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      " tensor([[0.6581, 0.5738],\n",
      "        [0.1634, 0.5728],\n",
      "        [0.1141, 0.6779]])\n",
      "Tensor b:\n",
      " tensor([[0.4400, 0.3766],\n",
      "        [0.5407, 0.9020],\n",
      "        [0.2807, 0.2133]])\n"
     ]
    }
   ],
   "source": [
    "# Create sample tensors\n",
    "a = torch.rand((3,2))\n",
    "b = torch.rand((3,2))\n",
    "\n",
    "print(\"Tensor a:\\n\", a)\n",
    "print(\"Tensor b:\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c1fa7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0981, 0.9504],\n",
       "        [0.7041, 1.4748],\n",
       "        [0.3948, 0.8912]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "a + b # or torch.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33760ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2181,  0.1973],\n",
       "        [-0.3773, -0.3292],\n",
       "        [-0.1666,  0.4645]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "a - b # or torch.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a4b7e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2896, 0.2161],\n",
       "        [0.0883, 0.5167],\n",
       "        [0.0320, 0.1446]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication (element-wise)\n",
    "a * b # or torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2b62117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4957, 1.5239],\n",
       "        [0.3022, 0.6350],\n",
       "        [0.4064, 3.1772]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "a / b # or torch.div(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35217b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4331, 0.3293],\n",
       "        [0.0267, 0.3281],\n",
       "        [0.0130, 0.4595]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power\n",
    "a ** 2 # or torch.pow(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8f38562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6581, 2.5738],\n",
       "        [2.1634, 2.5728],\n",
       "        [2.1141, 2.6779]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar operations\n",
    "scalar = 2.0\n",
    "a + scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df9b58",
   "metadata": {
    "id": "99df9b58"
   },
   "source": [
    "### Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53acf471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1:\n",
      " tensor([[10,  6],\n",
      "        [25, 13]])\n",
      "Matrix 2:\n",
      " tensor([[19, 45],\n",
      "        [16,  2]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "mat1 = torch.tensor([[10, 6], [25, 13]])\n",
    "mat2 = torch.tensor([[19, 45], [16, 2]])\n",
    "\n",
    "print(\"Matrix 1:\\n\", mat1)\n",
    "print(\"Matrix 2:\\n\", mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7def25e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 286,  462],\n",
       "        [ 683, 1151]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using torch.matmul()\n",
    "result1 = torch.matmul(mat1, mat2)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7429ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 286,  462],\n",
       "        [ 683, 1151]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using @ operator\n",
    "result2 = mat1 @ mat2\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f64540ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 25],\n",
       "        [ 6, 13]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose\n",
    "mat1.transpose(0, 1)  # Swap dimensions 0 and 1 \n",
    "# torch.transpose(mat, 0, 1)  # Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "585dc133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 25],\n",
       "        [ 6, 13]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.T # Shortcut for transpose for 2D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8bdfb",
   "metadata": {
    "id": "c8b8bdfb"
   },
   "source": [
    "### Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7aea80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  6., 25.],\n",
       "        [13., 19., 45.],\n",
       "        [16.,  2., 11.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor = torch.tensor([[10, 6, 25],\n",
    "                       [13, 19, 45],\n",
    "                       [16, 2, 11]], dtype=torch.float)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b41a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41., 77., 29.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "torch.sum(tensor)\n",
    "torch.sum(tensor, dim = 0) # Sum along columns\n",
    "torch.sum(tensor, dim = 1) # Sum along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd1100f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13.,  9., 27.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean\n",
    "torch.mean(tensor)\n",
    "torch.mean(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36da456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.0167, 17.0098,  7.0946])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard deviation\n",
    "torch.std(tensor, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07d3570d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max and Min\n",
    "torch.max(tensor) # along dimension can be specified as well by torch.max(tensor, dim=0)\n",
    "torch.min(tensor) # along dimension can be specified as well by torch.min(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f187a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argmax (index of maximum value)\n",
    "torch.argmax(tensor)\n",
    "torch.argmax(tensor, dim=0)\n",
    "torch.argmax(tensor, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6aa4e",
   "metadata": {
    "id": "b5c6aa4e"
   },
   "source": [
    "### Broadcasting\n",
    "Broadcasting allows operations between tensors of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38bf7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[10,  6, 25],\n",
      "        [13, 19, 45]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "Tensor b:\n",
      "tensor([16, 12, 11])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting examples\n",
    "a = torch.tensor([[10, 6, 25],\n",
    "                  [13, 19, 45]])\n",
    "b = torch.tensor([16, 12, 11])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8df8161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Broadcasted addition (a + b):\n",
      "tensor([[26, 18, 36],\n",
      "        [29, 31, 56]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting: b is automatically expanded to match a's shape\n",
    "result = a + b\n",
    "print(\"\\nBroadcasted addition (a + b):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71802da",
   "metadata": {
    "id": "c71802da"
   },
   "source": [
    "---\n",
    "<a name='6'></a>\n",
    "## **6. Tensor Manipulation (Reshaping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vYcGjw7n4rbe",
   "metadata": {
    "id": "vYcGjw7n4rbe"
   },
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4021721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor = torch.arange(11, 23)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1a895b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d9678c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14],\n",
       "        [15, 16, 17, 18],\n",
       "        [19, 20, 21, 22]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping to (3, 4)\n",
    "reshaped_tensor = torch.reshape(tensor, (3, 4))\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8e01026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7353275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14],\n",
       "        [15, 16, 17, 18],\n",
       "        [19, 20, 21, 22]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .view() - returns a view\n",
    "viewed = tensor.view(3, 4)\n",
    "viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4c5314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744d8a8",
   "metadata": {},
   "source": [
    "Difference between .view() and .reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a40016cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 7],\n",
       "        [1, 3],\n",
       "        [6, 8]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5,7],[1,3],[6,8]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ecf003b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 1, 6],\n",
       "        [7, 3, 8]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.transpose(0, 1)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "120be6e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "x_t.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1fa69a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 1],\n",
       "        [6, 7],\n",
       "        [3, 8]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2947a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14],\n",
       "        [15, 16, 17, 18],\n",
       "        [19, 20, 21, 22]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using -1 to infer dimension\n",
    "auto_reshape = tensor.view(3, -1)\n",
    "auto_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b728a",
   "metadata": {
    "id": "014b728a"
   },
   "source": [
    "### Changing Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72c5c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6979, 0.7816, 0.6311, 0.4191]],\n",
       "\n",
       "         [[0.6843, 0.9599, 0.9263, 0.4475]],\n",
       "\n",
       "         [[0.3459, 0.3946, 0.7296, 0.3074]]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() - remove dimensions of size 1\n",
    "tensor_4d = torch.rand(1, 3, 1, 4)\n",
    "tensor_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd20f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0c07056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6979, 0.7816, 0.6311, 0.4191],\n",
       "        [0.6843, 0.9599, 0.9263, 0.4475],\n",
       "        [0.3459, 0.3946, 0.7296, 0.3074]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed = torch.squeeze(tensor_4d)\n",
    "squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb032e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c267346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze specific dimension\n",
    "squeezed_dim = torch.squeeze(tensor_4d, dim = 0)\n",
    "squeezed_dim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d688ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1\n",
    "unsqueezed_0 = torch.unsqueeze(squeezed_dim, dim = 0)\n",
    "unsqueezed_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3400c5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 4])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1\n",
    "unsqueezed_0 = torch.unsqueeze(squeezed_dim, dim = 1)\n",
    "unsqueezed_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f653c44",
   "metadata": {
    "id": "2f653c44"
   },
   "source": [
    "### Combining Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb27b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[10,  6],\n",
      "        [25, 13]])\n",
      "\n",
      "Tensor b:\n",
      "tensor([[ 9, 45],\n",
      "        [17, 26]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[10, 6], [25, 13]])\n",
    "b = torch.tensor([[9, 45], [17, 26]])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fcdceb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6],\n",
       "        [25, 13],\n",
       "        [ 9, 45],\n",
       "        [17, 26]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along dimension 0 (rows)\n",
    "cat_dim0 = torch.cat([a, b], dim=0)\n",
    "cat_dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60252584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6,  9, 45],\n",
       "        [25, 13, 17, 26]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along dimension 1 (columns)\n",
    "cat_dim1 = torch.cat([a, b], dim=1)\n",
    "cat_dim1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf25e7",
   "metadata": {
    "id": "95bf25e7"
   },
   "source": [
    "### Splitting Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db44d42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4658, 0.1350, 0.5459, 0.8956],\n",
       "        [0.1447, 0.4234, 0.4259, 0.0410],\n",
       "        [0.6710, 0.6812, 0.5658, 0.6286]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor to split\n",
    "tensor = torch.rand(3, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f1c4ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "706258cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4658, 0.1350, 0.5459, 0.8956],\n",
       "         [0.1447, 0.4234, 0.4259, 0.0410]]),\n",
       " tensor([[0.6710, 0.6812, 0.5658, 0.6286]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.split() - split into chunks of a given size\n",
    "splits = torch.split(tensor, 2, dim=0)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "caf7c01d",
   "metadata": {
    "id": "caf7c01d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4658, 0.1350],\n",
       "         [0.1447, 0.4234],\n",
       "         [0.6710, 0.6812]]),\n",
       " tensor([[0.5459, 0.8956],\n",
       "         [0.4259, 0.0410],\n",
       "         [0.5658, 0.6286]]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.chunk() - split into a specific number of chunks\n",
    "chunks = torch.chunk(tensor, 2, dim=1)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b10c4",
   "metadata": {
    "id": "f94b10c4"
   },
   "source": [
    "---\n",
    "<a name='7'></a>\n",
    "## **7. NumPy & GPU Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a68a3",
   "metadata": {
    "id": "c54a68a3"
   },
   "source": [
    "### Moving Tensors Between CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f815fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CPU tensor\n",
    "cpu_tensor = torch.tensor([26.0, 12.0, 31.0, 42.0])\n",
    "print(\"CPU Tensor:\", cpu_tensor)\n",
    "print(\"Device:\", cpu_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GPU tensor (if CUDA is available)\n",
    "gpu_tensor = torch.tensor([26.0, 12.0, 31.0, 42.0], device = 'cuda')\n",
    "print(\"GPU Tensor:\", gpu_tensor)\n",
    "print(\"Device:\", gpu_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3UPIkt254ukG",
   "metadata": {
    "id": "3UPIkt254ukG"
   },
   "source": [
    "### NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Tensor to NumPy (only works on CPU tensors)\n",
    "\n",
    "np_from_tensor = cpu_tensor.numpy()\n",
    "print(\"NumPy from tensor:\", np_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85008f93",
   "metadata": {
    "id": "85008f93"
   },
   "source": [
    "---\n",
    "<a name='8'></a>\n",
    "## **8. Benefits of PyTorch over NumPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42486fd3",
   "metadata": {
    "id": "42486fd3"
   },
   "source": [
    "### Why PyTorch for Machine Learning? Key Benefits\n",
    "\n",
    "PyTorch offers several advantages over NumPy for machine learning tasks:\n",
    "\n",
    "#### 1. **GPU Acceleration**\n",
    "- PyTorch tensors can seamlessly move between CPU and GPU\n",
    "- Massive speedup for large-scale computations (10-100x faster)\n",
    "- Essential for training deep neural networks\n",
    "\n",
    "#### 2. **Automatic Differentiation (Autograd)**\n",
    "- Automatically computes gradients for backpropagation\n",
    "- Critical for training neural networks\n",
    "- No need to manually derive and implement gradient calculations\n",
    "\n",
    "#### 3. **Built for Deep Learning**\n",
    "- Rich ecosystem of neural network layers, optimizers, and loss functions\n",
    "- Easy model building with `torch.nn` module\n",
    "- Pre-trained models and transfer learning support\n",
    "\n",
    "#### 4. **Strong Community and Ecosystem**\n",
    "- Extensive libraries (torchvision, torchaudio, etc.)\n",
    "- Active research community\n",
    "- Excellent documentation and tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc4d4c",
   "metadata": {
    "id": "eebc4d4c"
   },
   "source": [
    "### Demonstration: GPU Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d772902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71618ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large matrix multiplication comparison\n",
    "size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy (CPU only)\n",
    "np_a = np.random.randn(size, size)\n",
    "np_b = np.random.randn(size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch CPU\n",
    "torch_a_cpu = torch.randn(size, size)\n",
    "torch_b_cpu = torch.randn(size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch GPU\n",
    "torch_a_gpu = torch.randn(size, size).to('cuda')\n",
    "torch_b_gpu = torch.randn(size, size).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "np_result = np.dot(np_a, np_b)\n",
    "np_time = time.time() - start\n",
    "\n",
    "print(f\"NumPy (CPU) time: {np_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea249ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "torch_result_cpu = torch_a_cpu @ torch_b_cpu\n",
    "torch_cpu_time = time.time() - start\n",
    "\n",
    "print(f\"PyTorch (CPU) time: {torch_cpu_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "torch_result_gpu = torch_a_gpu @ torch_b_gpu\n",
    "torch_gpu_time = time.time() - start\n",
    "\n",
    "print(f\"PyTorch (GPU) time: {torch_gpu_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa7898",
   "metadata": {
    "id": "c4fa7898"
   },
   "outputs": [],
   "source": [
    "# # PyTorch GPU (if available)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch_a_gpu = torch.randn(size, size).to(device)\n",
    "#     torch_b_gpu = torch.randn(size, size).to(device)\n",
    "\n",
    "#     # Warm up GPU\n",
    "#     _ = torch.matmul(torch_a_gpu, torch_b_gpu)\n",
    "#     torch.cuda.synchronize()\n",
    "\n",
    "#     start = time.time()\n",
    "#     torch_result_gpu = torch.matmul(torch_a_gpu, torch_b_gpu)\n",
    "#     torch.cuda.synchronize()\n",
    "#     torch_gpu_time = time.time() - start\n",
    "\n",
    "#     print(f\"PyTorch (GPU) time: {torch_gpu_time:.4f} seconds\")\n",
    "#     print(f\"\\nüöÄ GPU Speedup: {torch_cpu_time / torch_gpu_time:.2f}x faster than CPU\")\n",
    "# else:\n",
    "#     print(\"\\n‚ö†Ô∏è GPU not available for speed comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a190a45",
   "metadata": {
    "id": "5a190a45"
   },
   "source": [
    "### When to Use What?\n",
    "\n",
    "**Use NumPy when:**\n",
    "- Doing general numerical computations\n",
    "- Working with small to medium datasets\n",
    "- Not training neural networks\n",
    "- CPU processing is sufficient\n",
    "\n",
    "**Use PyTorch when:**\n",
    "- Building and training neural networks\n",
    "- Need GPU acceleration\n",
    "- Require automatic differentiation\n",
    "- Working on deep learning projects\n",
    "- Need production deployment of ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accf664",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='9'></a>\n",
    "## **9. Reading Material**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a2afc",
   "metadata": {},
   "source": [
    "### torch.rand() vs torch.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdefa5",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://i-blog.csdnimg.cn/direct/e34944beb690439b8505f2bba367b7cc.png\" width=\"700\"/>\n",
    "  <p><i>Uniform Distribution vs Normal Distribution</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55aadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.rand() - uniform distribution [0, 1)\n",
    "# random values between 0 and 1. Uniform distribution means all values are equally likely.\n",
    "rand_uniform = torch.rand(3, 3)\n",
    "rand_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn() - standard normal distribution (mean=0, std=1)\n",
    "# random values from a normal distribution with mean 0 and standard deviation 1. \n",
    "# 68.3 % probability that values are between -1 and 1\n",
    "# 95.4 % probability that values are between -2 and 2\n",
    "# range is theoretically from -infinity to +infinity.\n",
    "\n",
    "rand_normal = torch.randn(3, 3)\n",
    "rand_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285e60f",
   "metadata": {},
   "source": [
    "### In-place Operations\n",
    "Operations ending with `_` modify the tensor in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place addition\n",
    "a.add_(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place multiplication\n",
    "a.subtract_(3)\n",
    "a\n",
    "\n",
    "# Note: In-place operations save memory but modify the original tensor\n",
    "# Regular operations create new tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230da4e",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ded15cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[10,  6],\n",
      "        [25, 13]])\n",
      "\n",
      "Tensor b:\n",
      "tensor([[ 9, 45],\n",
      "        [17, 26]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[10, 6], [25, 13]])\n",
    "b = torch.tensor([[9, 45], [17, 26]])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba04839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.stack() - stack along a new dimension\n",
    "stacked_dim0 = torch.stack([a, b], dim = 0) # 0 means row wise stacking and 1 means column wise stacking\n",
    "stacked_dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a700ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_dim0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e228d",
   "metadata": {
    "id": "cf3e228d"
   },
   "source": [
    "### Reordering Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a3da9b",
   "metadata": {},
   "source": [
    "| Operation         | Resulting Tensor                | Logic/Explanation                                      |\n",
    "|-------------------|---------------------------------|--------------------------------------------------------|\n",
    "| **Original**      | <pre>[[1, 2, 3],<br> [4, 5, 6]]</pre> <br>Shape: (2, 3) | Starting tensor                                        |\n",
    "| `reshape(3, 2)`   | <pre>[[1, 2],<br> [3, 4],<br> [5, 6]]</pre> | Fills the new shape sequentially: 1, 2, then 3, 4, etc.|\n",
    "| `permute(1, 0)`   | <pre>[[1, 4],<br> [2, 5],<br> [3, 6]]</pre> | Swaps axes: Row 1 becomes Column 1, etc.               |\n",
    "\n",
    "**Key Difference:**\n",
    "- `reshape` changes the shape by reordering the elements in memory sequentially.\n",
    "- `permute` changes the order of axes (dimensions) without changing the order of elements in memory.\n",
    "- `permute` serves a similar purpose to `transpose`, but while `transpose` swaps exactly two dimensions, `permute` can rearrange all dimensions in any order you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7c584d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9962, 0.2111, 0.3090],\n",
       "        [0.3452, 0.8704, 0.6638]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(2,3)\n",
    "print(tensor.shape)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "546a9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9962, 0.3452],\n",
       "        [0.2111, 0.8704],\n",
       "        [0.3090, 0.6638]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permute dimensions works by reordering the dimensions of a tensor to a specified order.\n",
    "permuted = tensor.permute(1, 0)\n",
    "print(permuted.shape)\n",
    "permuted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928eb10c",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='10'></a>\n",
    "## **10. Practice Exercises**\n",
    "\n",
    "Test your understanding of PyTorch tensors with these hands-on exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba02ecf",
   "metadata": {},
   "source": [
    "### Exercise 1: Creating Tensors\n",
    "Create a 4x5 tensor filled with random values from a normal distribution (mean=0, std=1). Then convert it to a tensor with dtype `torch.float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9156b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dec374",
   "metadata": {},
   "source": [
    "### Exercise 2: Challenge - Normalize a Tensor\n",
    "Create a tensor of shape (5, 6) with random values from a uniform distribution. Normalize it so that each column has mean 0 and standard deviation 1. (Hint: Use broadcasting and reduction operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c6a529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91611ac",
   "metadata": {},
   "source": [
    "### Exercise 3: NumPy Integration\n",
    "Create a NumPy array with shape (4, 4) containing random integers between 1 and 100. Convert it to a PyTorch tensor, compute the sum of each row, then convert the result back to a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7c325532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f8a42",
   "metadata": {},
   "source": [
    "### Exercise 4: Combining Tensors\n",
    "Create three tensors of shape (2, 3). Stack them along a new dimension (dim=0), then concatenate them along dimension 1 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6ea0b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd9fb6",
   "metadata": {},
   "source": [
    "### Exercise 5: Reshaping\n",
    "Create a 1D tensor with values from 0 to 23. Reshape it to (2, 3, 4). Then use `permute` to swap the first and last dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "353cc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9303a2",
   "metadata": {},
   "source": [
    "### Exercise 6: Broadcasting\n",
    "Create a tensor A of shape (3, 4) and a tensor B of shape (4,). Add them together using broadcasting, then verify the shape of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4c6041b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2eaa06",
   "metadata": {},
   "source": [
    "### Exercise 7: Reduction Operations\n",
    "Create a 5x5 tensor with random values. Calculate the mean of each row and the standard deviation of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "63736400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8f9fc",
   "metadata": {},
   "source": [
    "### Exercise 8: Matrix Operations\n",
    "Create two matrices A (3x4) and B (4x5) with random values. Compute their matrix product and find the maximum value in the resulting matrix along with its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f7429e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7704f",
   "metadata": {},
   "source": [
    "### Exercise 9: Boolean Masking\n",
    "Create a tensor with values from 1 to 20. Use boolean masking to extract only the values that are divisible by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed428dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b05937",
   "metadata": {},
   "source": [
    "### Exercise 10: Tensor Indexing\n",
    "Create a tensor of shape (6, 8) with random values. Extract the middle 2x4 submatrix (rows 2-3, columns 2-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc60ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb46cf",
   "metadata": {
    "id": "b2cb46cf"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you've learned:\n",
    "\n",
    "1. ‚úÖ What PyTorch is and why it's essential for deep learning\n",
    "2. ‚úÖ How to create tensors in various ways\n",
    "3. ‚úÖ Tensor attributes and properties\n",
    "4. ‚úÖ Indexing, slicing, and filtering tensors\n",
    "5. ‚úÖ Essential tensor operations (arithmetic, matrix ops, reductions)\n",
    "6. ‚úÖ Tensor manipulation (reshaping, combining, splitting)\n",
    "7. ‚úÖ NumPy integration and GPU acceleration\n",
    "8. ‚úÖ Key differences between NumPy and PyTorch\n",
    "9. ‚úÖ Why PyTorch is superior for machine learning\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore PyTorch's autograd in depth\n",
    "- Learn about `torch.nn` for building neural networks\n",
    "- Practice with real datasets using `torch.utils.data`\n",
    "- Implement your first neural network!\n",
    "\n",
    "**Happy Learning! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "23bd53d1",
    "67c184a2",
    "dd5daebc",
    "b8d156fe",
    "0b1e3e8a",
    "c71802da",
    "f94b10c4",
    "85008f93"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
