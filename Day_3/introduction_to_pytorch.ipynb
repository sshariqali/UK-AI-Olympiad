{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0lAI4wJsxyUI",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1762107289572,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "0lAI4wJsxyUI",
    "outputId": "46faec05-737f-4121-d4f1-ac1985f00332"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "const firstCell = document.querySelector('.cell.code_cell');\n",
       "if (firstCell) {\n",
       "  firstCell.querySelector('.input').style.pointerEvents = 'none';\n",
       "  firstCell.querySelector('.input').style.opacity = '0.5';\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display:flex; flex-direction:column; align-items:center; text-align:center; gap:12px; padding:8px;\">\n",
       "  <h1 style=\"margin:0;\">ðŸ‘‹ Welcome to <span style=\"color:#1E88E5;\">Algopath Coding Academy</span>!</h1>\n",
       "\n",
       "  <img src=\"https://raw.githubusercontent.com/sshariqali/mnist_pretrained_model/main/algopath_logo.jpg\"\n",
       "       alt=\"Algopath Coding Academy Logo\"\n",
       "       width=\"400\"\n",
       "       style=\"border-radius:15px; box-shadow:0 4px 12px rgba(0,0,0,0.2); max-width:100%; height:auto;\" />\n",
       "\n",
       "  <p style=\"font-size:16px; margin:0;\">\n",
       "    <em>Empowering young minds to think creatively, code intelligently, and build the future with AI.</em>\n",
       "  </p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<script>\n",
    "const firstCell = document.querySelector('.cell.code_cell');\n",
    "if (firstCell) {\n",
    "  firstCell.querySelector('.input').style.pointerEvents = 'none';\n",
    "  firstCell.querySelector('.input').style.opacity = '0.5';\n",
    "}\n",
    "</script>\n",
    "\"\"\"))\n",
    "\n",
    "html = \"\"\"\n",
    "<div style=\"display:flex; flex-direction:column; align-items:center; text-align:center; gap:12px; padding:8px;\">\n",
    "  <h1 style=\"margin:0;\">ðŸ‘‹ Welcome to <span style=\"color:#1E88E5;\">Algopath Coding Academy</span>!</h1>\n",
    "\n",
    "  <img src=\"https://raw.githubusercontent.com/sshariqali/mnist_pretrained_model/main/algopath_logo.jpg\"\n",
    "       alt=\"Algopath Coding Academy Logo\"\n",
    "       width=\"400\"\n",
    "       style=\"border-radius:15px; box-shadow:0 4px 12px rgba(0,0,0,0.2); max-width:100%; height:auto;\" />\n",
    "\n",
    "  <p style=\"font-size:16px; margin:0;\">\n",
    "    <em>Empowering young minds to think creatively, code intelligently, and build the future with AI.</em>\n",
    "  </p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f92fa",
   "metadata": {
    "id": "457f92fa"
   },
   "source": [
    "# PyTorch Tensors Tutorial\n",
    "\n",
    "\n",
    "**Table of Contents:**\n",
    "1. [Introduction to PyTorch](#1)\n",
    "2. [Creating Tensors](#2)\n",
    "3. [Tensor Attributes and Properties](#3)\n",
    "4. [Tensor Indexing Slicing and Filtering](#4)\n",
    "5. [Tensor Operations](#5)\n",
    "6. [Tensor Manipulation](#6)\n",
    "7. [GPU Interaction](#7)\n",
    "8. [NumPy vs PyTorch Comparison](#8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd53d1",
   "metadata": {
    "id": "23bd53d1"
   },
   "source": [
    "<a name='1'></a>\n",
    "## **1. Introduction to PyTorch Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8m3FnYCs4iDO",
   "metadata": {
    "id": "8m3FnYCs4iDO"
   },
   "source": [
    "### What is PyTorch?\n",
    "PyTorch is an open-source deep learning library developed by Facebook's AI Research lab. It provides:\n",
    "- Tensor computation with strong GPU acceleration\n",
    "- Automatic differentiation for building neural networks\n",
    "- A flexible and intuitive API for research and production\n",
    "\n",
    "### What is a Tensor?\n",
    "A **tensor** is the core data structure in PyTorch. Think of it as:\n",
    "- Similar to a NumPy `ndarray` but with additional capabilities\n",
    "- Can run on GPUs for accelerated computing\n",
    "- Supports automatic differentiation (autograd) for neural network training\n",
    "- A multi-dimensional array that can represent scalars, vectors, matrices, and higher-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df007a87",
   "metadata": {
    "id": "df007a87"
   },
   "source": [
    "### Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb692616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10634,
     "status": "ok",
     "timestamp": 1762202366615,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "eb692616",
    "outputId": "c79502e5-e38e-4d29-bd3d-ee1233ca0abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a611a",
   "metadata": {
    "id": "d54a611a"
   },
   "source": [
    "### Setting up your Device\n",
    "Check if CUDA (GPU) is available and set the device accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0b3891",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1762202394435,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "de0b3891",
    "outputId": "21c3bad7-ee1c-45cd-c44c-7335390c87a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "GPU not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c184a2",
   "metadata": {
    "id": "67c184a2"
   },
   "source": [
    "---\n",
    "<a name='2'></a>\n",
    "## **2. Creating Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DscBqY7M4llk",
   "metadata": {
    "id": "DscBqY7M4llk"
   },
   "source": [
    "### From Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d016abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.tensor() - from Python lists or tuples\n",
    "tensor_1d = torch.tensor([1, 2, 3, 4, 5])\n",
    "tensor_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a180ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D tensor from nested list\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c299076",
   "metadata": {
    "id": "3c299076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.from_numpy() - from NumPy array (shares memory!)\n",
    "np_array = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "tensor_from_numpy = torch.from_numpy(np_array)\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3b29a",
   "metadata": {
    "id": "fcb3b29a"
   },
   "source": [
    "### Creating New Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3a607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros()\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88fc78d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones()\n",
    "ones_tensor = torch.ones(3,4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de709c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4664, 0.7369, 0.1835],\n",
       "        [0.0862, 0.5104, 0.5799],\n",
       "        [0.4217, 0.7657, 0.9702]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rand() - uniform distribution [0, 1)\n",
    "# random values between 0 and 1. Uniform distribution means all values are equally likely.\n",
    "rand_uniform = torch.rand(3, 3)\n",
    "rand_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9922b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3455, -0.2079, -0.3835],\n",
       "        [-1.4898, -0.1833, -0.1595],\n",
       "        [-0.1620,  0.7861, -0.4565]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randn() - standard normal distribution (mean=0, std=1)\n",
    "# random values from a normal distribution with mean 0 and standard deviation 1. range is theoretically from -infinity to +infinity.\n",
    "rand_normal = torch.randn(3, 3)\n",
    "rand_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb35bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange() - sequence of values\n",
    "arange_tensor = torch.arange(0, 10, 2)\n",
    "arange_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b2d691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.linspace() - linearly spaced values\n",
    "linspace_tensor = torch.linspace(0, 1, 5)\n",
    "linspace_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f402251",
   "metadata": {
    "id": "6f402251"
   },
   "source": [
    "### Creating Tensors Based on Other Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5757c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1664, 0.4794, 0.7029],\n",
       "        [0.7985, 0.4445, 0.1382]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a reference tensor\n",
    "reference_tensor = torch.rand(2, 3)\n",
    "reference_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e577ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros_like()\n",
    "zeros_like = torch.zeros_like(reference_tensor)\n",
    "zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d46bd624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones_like()\n",
    "ones_like = torch.ones_like(reference_tensor)\n",
    "ones_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132adc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6724, 0.6249, 0.4836],\n",
       "        [0.8151, 0.1190, 0.2250]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rand_like()\n",
    "rand_like = torch.rand_like(reference_tensor)\n",
    "rand_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5daebc",
   "metadata": {
    "id": "dd5daebc"
   },
   "source": [
    "---\n",
    "<a name='3'></a>\n",
    "## **3. Tensor Attributes and Properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cef5fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0762, -2.4215],\n",
       "        [-0.2484,  2.1531]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "sample_tensor = torch.randn(2, 2)\n",
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d92a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type\n",
    "sample_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a1948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "sample_tensor.shape # sample_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85faf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "sample_tensor.device\n",
    "\n",
    "# Move tensor to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    sample_tensor = sample_tensor.to('cuda')\n",
    "    sample_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46848b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of dimensions\n",
    "sample_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b2c874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of elements\n",
    "sample_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e79efa",
   "metadata": {
    "id": "71e79efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer tensor dtype: torch.int64\n",
      "Float tensor dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with specific dtypes\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype = torch.long)\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype = torch.float32)\n",
    "print(f\"Integer tensor dtype: {int_tensor.dtype}\")\n",
    "print(f\"Float tensor dtype: {float_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d156fe",
   "metadata": {
    "id": "b8d156fe"
   },
   "source": [
    "---\n",
    "<a name='4'></a>\n",
    "## **4. Tensor Indexing, Slicing, and Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7079ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor for indexing\n",
    "tensor = torch.arange(24).reshape(4, 6)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70d591c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard indexing\n",
    "tensor[0, 0] # Access element at row 0, column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a31da7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing rows and columns\n",
    "tensor[0] # First row\n",
    "# tensor[:, 1] # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4f1d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing\n",
    "tensor[0:2] # First 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c642274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  9],\n",
       "        [14, 15]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1:3, 2:4] # Rows 1-3, Columns 2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f127b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[::2] # Every other row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20cf4cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean mask (elements > 10):\n",
      "tensor([[False, False, False, False, False, False],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "\n",
      "Filtered values (> 10):\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])\n"
     ]
    }
   ],
   "source": [
    "# Boolean/Masked indexing\n",
    "mask = tensor > 10\n",
    "print(\"Boolean mask (elements > 10):\") # \n",
    "print(mask) # boolean mask retains the original tensor's shape\n",
    "print(\"\\nFiltered values (> 10):\")\n",
    "print(tensor[mask]) # filtered values are a 1D array of only the elements that meet the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d03b2828",
   "metadata": {
    "id": "d03b2828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.where() - conditional selection\n",
    "result = torch.where(tensor > 10, tensor, torch.tensor(0)) # replace values <= 10 with 0\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e3e8a",
   "metadata": {
    "id": "0b1e3e8a"
   },
   "source": [
    "---\n",
    "<a name='5'></a>\n",
    "## **5. Tensor Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3wIYTj8B4pAQ",
   "metadata": {
    "id": "3wIYTj8B4pAQ"
   },
   "source": [
    "### Element-wise Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9ed3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tensor([1., 2., 3.])\n",
      "Tensor b: tensor([4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Create sample tensors\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"Tensor a:\", a)\n",
    "print(\"Tensor b:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fa7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "a + b # or torch.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33760ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtraction\n",
    "a - b # or torch.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplication (element-wise)\n",
    "a * b # or torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b62117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.4000, 0.5000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "a / b # or torch.div(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35217b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power\n",
    "a ** 2 # or torch.pow(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8f38562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar operations\n",
    "scalar = 2.0\n",
    "a + scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ed4af",
   "metadata": {
    "id": "a40ed4af"
   },
   "source": [
    "### In-place Operations\n",
    "Operations ending with `_` modify the tensor in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "344a3bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place operations (methods ending with _)\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4b52e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 7., 8.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place addition\n",
    "x.add_(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed7b9c1b",
   "metadata": {
    "id": "ed7b9c1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14., 16.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place multiplication\n",
    "x.mul_(2)\n",
    "x\n",
    "\n",
    "# Note: In-place operations save memory but modify the original tensor\n",
    "# Regular operations create new tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df9b58",
   "metadata": {
    "id": "99df9b58"
   },
   "source": [
    "### Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53acf471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Matrix 2:\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "mat1 = torch.tensor([[1, 2], [3, 4]])\n",
    "mat2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Matrix 1:\\n\", mat1)\n",
    "print(\"Matrix 2:\\n\", mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7def25e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using torch.matmul()\n",
    "result1 = torch.matmul(mat1, mat2)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7429ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using @ operator\n",
    "result2 = mat1 @ mat2\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f64540ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose\n",
    "mat1.transpose(0, 1)  # Swap dimensions 0 and 1 \n",
    "# torch.transpose(mat, 0, 1)  # Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "585dc133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.T # Shortcut for transpose for 2D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8bdfb",
   "metadata": {
    "id": "c8b8bdfb"
   },
   "source": [
    "### Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7aea80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                       [4.0, 5.0, 6.0],\n",
    "                       [7.0, 8.0, 9.0]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b41a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6., 15., 24.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "torch.sum(tensor)\n",
    "torch.sum(tensor, dim = 0) # Sum along columns\n",
    "torch.sum(tensor, dim = 1) # Sum along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1100f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "torch.mean(tensor)\n",
    "torch.mean(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "torch.std(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max and Min\n",
    "torch.max(tensor) # along dimension can be specified as well by torch.max(tensor, dim=0)\n",
    "torch.min(tensor) # along dimension can be specified as well by torch.min(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f187a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argmax (index of maximum value)\n",
    "torch.argmax(tensor)\n",
    "torch.argmax(tensor, dim=0)\n",
    "torch.argmax(tensor, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6aa4e",
   "metadata": {
    "id": "b5c6aa4e"
   },
   "source": [
    "### Broadcasting\n",
    "Broadcasting allows operations between tensors of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87871d74",
   "metadata": {
    "id": "87871d74"
   },
   "outputs": [],
   "source": [
    "# Broadcasting examples\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "b = torch.tensor([10, 20, 30])\n",
    "\n",
    "print(\"Tensor a (2x3):\")\n",
    "print(a)\n",
    "print(\"\\nTensor b (3,):\")\n",
    "print(b)\n",
    "\n",
    "# Broadcasting: b is automatically expanded to match a's shape\n",
    "result = a + b\n",
    "print(\"\\nBroadcasted addition (a + b):\")\n",
    "print(result)\n",
    "\n",
    "# Broadcasting with column vector\n",
    "c = torch.tensor([[100], [200]])\n",
    "print(\"\\nTensor c (2x1):\")\n",
    "print(c)\n",
    "\n",
    "result2 = a + c\n",
    "print(\"\\nBroadcasted addition (a + c):\")\n",
    "print(result2)\n",
    "\n",
    "# Scalar broadcasting\n",
    "result3 = a * 10\n",
    "print(\"\\nScalar broadcasting (a * 10):\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71802da",
   "metadata": {
    "id": "c71802da"
   },
   "source": [
    "---\n",
    "<a name='6'></a>\n",
    "## **6. Tensor Manipulation (Reshaping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vYcGjw7n4rbe",
   "metadata": {
    "id": "vYcGjw7n4rbe"
   },
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4021721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor = torch.arange(12)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a895b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9678c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.reshape() - can return a copy or a view\n",
    "reshaped1 = torch.reshape(tensor, (3, 4))\n",
    "reshaped1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e01026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7353275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .view() - returns a view (must be contiguous)\n",
    "viewed = tensor.view(4, 3)\n",
    "viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c5314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4ab52",
   "metadata": {},
   "source": [
    "**Difference Between `.view()` and `.reshape()` (Explained Simply)**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.sstatic.net/ee7Hj.png\" width=\"500\"/>\n",
    "  <p><i>Tensor and its underlying storage</i></p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.sstatic.net/26Q9g.png\" width=\"500\"/>\n",
    "  <p><i>The right-hand tensor (shape (3,2)) can be computed from the left-hand one with t2 = t1.view(3,2)</i></p>\n",
    "</div>\n",
    "\n",
    "**What is `.view()`?**\n",
    "- `.view()` changes the shape of a tensor **without copying the data**.\n",
    "- It only works if the tensor's data is stored in a **contiguous block** in memory (all elements are lined up in order).\n",
    "- If the tensor is **not contiguous** (for example, after a transpose), `.view()` will give an error.\n",
    "\n",
    "**What is `.reshape()`?**\n",
    "- `.reshape()` also changes the shape of a tensor.\n",
    "- If possible, it returns a **view** (no copy, just like `.view()`).\n",
    "- If the tensor is **not contiguous**, `.reshape()` will **make a copy** of the data so it can still give you the new shape.\n",
    "- So, `.reshape()` is more flexible and works in more situations.\n",
    "\n",
    "**What does \"contiguous\" mean?**\n",
    "- **Contiguous**: All the elements of the tensor are stored in memory one after another, in the order you see them.\n",
    "- **Non-contiguous**: The elements are not stored in order (for example, after you transpose a tensor, the way data is stored in memory changes).\n",
    "\n",
    "**When to use `.view()`?**\n",
    "- Use `.view()` when you are sure your tensor is **contiguous** (hasn't been transposed or sliced in a way that changes memory order).\n",
    "- It's a bit faster because it never copies data.\n",
    "\n",
    "**When to use `.reshape()`?**\n",
    "- Use `.reshape()` if you are **not sure** if your tensor is contiguous.\n",
    "- It will work in more cases, but might copy data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79582e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Is x contiguous? True\n",
      "\n",
      "Transposed x:\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "Is transposed contiguous? False\n",
      "\n",
      "Attempting xt.view(6)...\n",
      "Error: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "Making xt contiguous and then viewing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 1, 4, 2, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "print(f\"Original x:\\n{x}\")\n",
    "print(f\"Is x contiguous? {x.is_contiguous()}\") # True\n",
    "\n",
    "# 2. Transpose the tensor\n",
    "# Memory still looks like: [0, 1, 2, 3, 4, 5]\n",
    "# But the \"instructions\" say to read it vertically.\n",
    "xt = x.transpose(0, 1)\n",
    "print(f\"\\nTransposed x:\\n{xt}\")\n",
    "print(f\"Is transposed contiguous? {xt.is_contiguous()}\") # False\n",
    "\n",
    "# 3. Try to use .view()\n",
    "try:\n",
    "    print(\"\\nAttempting xt.view(6)...\")\n",
    "    xt.view(6)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# 4. Make it contiguous and then use .view()\n",
    "print(\"\\nMaking xt contiguous and then viewing...\")\n",
    "xt_contiguous = xt.contiguous()\n",
    "xt_contiguous.view(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2947a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using -1 to infer dimension\n",
    "auto_reshape = tensor.view(3, -1)\n",
    "auto_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b728a",
   "metadata": {
    "id": "014b728a"
   },
   "source": [
    "### Changing Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c5c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2423, -1.6811,  0.0700, -1.1526]],\n",
       "\n",
       "         [[-0.3222,  0.5486,  1.5061, -0.8805]],\n",
       "\n",
       "         [[ 0.1760,  0.7252, -0.1779, -0.3199]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() - remove dimensions of size 1\n",
    "tensor_4d = torch.randn(1, 3, 1, 4)\n",
    "tensor_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd20f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c07056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2423, -1.6811,  0.0700, -1.1526],\n",
       "        [-0.3222,  0.5486,  1.5061, -0.8805],\n",
       "        [ 0.1760,  0.7252, -0.1779, -0.3199]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed = torch.squeeze(tensor_4d)\n",
    "squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb032e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c267346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze specific dimension\n",
    "squeezed_dim = torch.squeeze(tensor_4d, dim = 0)\n",
    "squeezed_dim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d688ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1\n",
    "unsqueezed_0 = torch.unsqueeze(squeezed_dim, dim = 0)\n",
    "unsqueezed_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3400c5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1\n",
    "unsqueezed_0 = torch.unsqueeze(squeezed_dim, dim = 1)\n",
    "unsqueezed_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f653c44",
   "metadata": {
    "id": "2f653c44"
   },
   "source": [
    "### Combining Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb27b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Tensor b:\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat() - concatenate along an existing dimension\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcdceb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along dimension 0 (rows)\n",
    "cat_dim0 = torch.cat([a, b], dim=0)\n",
    "cat_dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60252584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along dimension 1 (columns)\n",
    "cat_dim1 = torch.cat([a, b], dim=1)\n",
    "cat_dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe227431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [5, 6]],\n",
       "\n",
       "        [[3, 4],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.stack() - stack along a new dimension\n",
    "stacked_dim0 = torch.stack([a, b], dim = 1) # 0 means row wise stacking and 1 means column wise stacking\n",
    "stacked_dim0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf25e7",
   "metadata": {
    "id": "95bf25e7"
   },
   "source": [
    "### Splitting Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db44d42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor to split\n",
    "tensor = torch.arange(12).reshape(3, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1c4ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "706258cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3],\n",
       "         [4, 5, 6, 7]]),\n",
       " tensor([[ 8,  9, 10, 11]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.split() - split into chunks of a given size\n",
    "splits = torch.split(tensor, 2, dim=0)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caf7c01d",
   "metadata": {
    "id": "caf7c01d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [4, 5],\n",
       "         [8, 9]]),\n",
       " tensor([[ 2,  3],\n",
       "         [ 6,  7],\n",
       "         [10, 11]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.chunk() - split into a specific number of chunks\n",
    "chunks = torch.chunk(tensor, 2, dim=1)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e228d",
   "metadata": {
    "id": "cf3e228d"
   },
   "source": [
    "### Reordering Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea242e1b",
   "metadata": {},
   "source": [
    "| Operation         | Resulting Tensor                | Logic/Explanation                                      |\n",
    "|-------------------|---------------------------------|--------------------------------------------------------|\n",
    "| **Original**      | <pre>[[1, 2, 3],<br> [4, 5, 6]]</pre> <br>Shape: (2, 3) | Starting tensor                                        |\n",
    "| `reshape(3, 2)`   | <pre>[[1, 2],<br> [3, 4],<br> [5, 6]]</pre> | Fills the new shape sequentially: 1, 2, then 3, 4, etc.|\n",
    "| `permute(1, 0)`   | <pre>[[1, 4],<br> [2, 5],<br> [3, 6]]</pre> | Swaps axes: Row 1 becomes Column 1, etc.               |\n",
    "\n",
    "**Key Difference:**\n",
    "- `reshape` changes the shape by reordering the elements in memory sequentially.\n",
    "- `permute` changes the order of axes (dimensions) without changing the order of elements in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ff7dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(2,3)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db640ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4844,  0.0816, -0.4064],\n",
       "        [ 1.4538, -0.8095, -0.0257]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84028c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permute dimensions works by reordering the dimensions of a tensor to a specified order.\n",
    "permuted = tensor.permute(1, 0)\n",
    "permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f717354e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4844,  1.4538],\n",
       "        [ 0.0816, -0.8095],\n",
       "        [-0.4064, -0.0257]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c40e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped = tensor.reshape(3, 2)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afd05d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4844,  0.0816],\n",
       "        [-0.4064,  1.4538],\n",
       "        [-0.8095, -0.0257]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b10c4",
   "metadata": {
    "id": "f94b10c4"
   },
   "source": [
    "---\n",
    "<a name='7'></a>\n",
    "## **7. NumPy & GPU Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3UPIkt254ukG",
   "metadata": {
    "id": "3UPIkt254ukG"
   },
   "source": [
    "### NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916393d",
   "metadata": {
    "id": "0916393d"
   },
   "outputs": [],
   "source": [
    "# CPU Tensors and NumPy arrays share memory\n",
    "np_array = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(\"Original NumPy array:\", np_array)\n",
    "\n",
    "# Convert NumPy to Tensor (shares memory)\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "print(\"Tensor from NumPy:\", tensor_from_np)\n",
    "\n",
    "# Modify the tensor\n",
    "tensor_from_np[0] = 100\n",
    "print(\"\\nAfter modifying tensor:\")\n",
    "print(\"Tensor:\", tensor_from_np)\n",
    "print(\"NumPy array (also changed!):\", np_array)\n",
    "\n",
    "# Convert Tensor to NumPy (only works on CPU tensors)\n",
    "torch_tensor = torch.tensor([10.0, 20.0, 30.0, 40.0])\n",
    "np_from_tensor = torch_tensor.numpy()\n",
    "print(\"\\nTensor:\", torch_tensor)\n",
    "print(\"NumPy from tensor:\", np_from_tensor)\n",
    "\n",
    "# Modify NumPy array\n",
    "np_from_tensor[0] = 999\n",
    "print(\"\\nAfter modifying NumPy array:\")\n",
    "print(\"NumPy array:\", np_from_tensor)\n",
    "print(\"Tensor (also changed!):\", torch_tensor)\n",
    "\n",
    "print(\"\\nâš ï¸ Note: CPU Tensors and NumPy arrays share the same memory location!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a68a3",
   "metadata": {
    "id": "c54a68a3"
   },
   "source": [
    "### Moving Tensors Between CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e29655",
   "metadata": {
    "id": "c3e29655"
   },
   "outputs": [],
   "source": [
    "# Create a CPU tensor\n",
    "cpu_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "print(\"CPU Tensor:\", cpu_tensor)\n",
    "print(\"Device:\", cpu_tensor.device)\n",
    "\n",
    "# Move to GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    # Method 1: Using .to(device)\n",
    "    gpu_tensor = cpu_tensor.to(device)\n",
    "    print(\"\\nGPU Tensor (using .to()):\", gpu_tensor)\n",
    "    print(\"Device:\", gpu_tensor.device)\n",
    "\n",
    "    # Method 2: Using .cuda()\n",
    "    gpu_tensor2 = cpu_tensor.cuda()\n",
    "    print(\"\\nGPU Tensor (using .cuda()):\", gpu_tensor2)\n",
    "    print(\"Device:\", gpu_tensor2.device)\n",
    "\n",
    "    # Move back to CPU\n",
    "    back_to_cpu = gpu_tensor.cpu()\n",
    "    print(\"\\nBack to CPU:\", back_to_cpu)\n",
    "    print(\"Device:\", back_to_cpu.device)\n",
    "\n",
    "    # Convert GPU tensor to NumPy (requires moving to CPU first)\n",
    "    # gpu_tensor.numpy()  # This would raise an error!\n",
    "    np_array = gpu_tensor.cpu().numpy()\n",
    "    print(\"\\nNumPy array from GPU tensor:\", np_array)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ CUDA not available. Tensor remains on CPU.\")\n",
    "    print(\"To use GPU features, ensure you have:\")\n",
    "    print(\"1. A CUDA-capable GPU\")\n",
    "    print(\"2. CUDA toolkit installed\")\n",
    "    print(\"3. PyTorch with CUDA support installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85008f93",
   "metadata": {
    "id": "85008f93"
   },
   "source": [
    "---\n",
    "<a name='8'></a>\n",
    "## **8. NumPy vs PyTorch: Comparison and Benefits**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k7vZyjFz409f",
   "metadata": {
    "id": "k7vZyjFz409f"
   },
   "source": [
    "### Key Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5723f",
   "metadata": {
    "id": "35d5723f"
   },
   "outputs": [],
   "source": [
    "# Similar operations in NumPy and PyTorch\n",
    "print(\"=\" * 60)\n",
    "print(\"NUMPY vs PYTORCH - Similar Syntax\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Creating arrays/tensors\n",
    "np_arr = np.array([1, 2, 3, 4, 5])\n",
    "torch_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"\\nNumPy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", torch_tensor)\n",
    "\n",
    "# Zeros\n",
    "np_zeros = np.zeros((3, 3))\n",
    "torch_zeros = torch.zeros(3, 3)\n",
    "print(\"\\nNumPy zeros:\\n\", np_zeros)\n",
    "print(\"PyTorch zeros:\\n\", torch_zeros)\n",
    "\n",
    "# Random values\n",
    "np_rand = np.random.randn(2, 3)\n",
    "torch_rand = torch.randn(2, 3)\n",
    "print(\"\\nNumPy random:\\n\", np_rand)\n",
    "print(\"PyTorch random:\\n\", torch_rand)\n",
    "\n",
    "# Reshaping\n",
    "np_reshaped = np_arr.reshape(5, 1)\n",
    "torch_reshaped = torch_tensor.reshape(5, 1)\n",
    "print(\"\\nNumPy reshaped:\\n\", np_reshaped)\n",
    "print(\"PyTorch reshaped:\\n\", torch_reshaped)\n",
    "\n",
    "# Mathematical operations\n",
    "print(\"\\nNumPy mean:\", np_arr.mean())\n",
    "print(\"PyTorch mean:\", torch_tensor.float().mean())\n",
    "\n",
    "print(\"\\nNumPy sum:\", np_arr.sum())\n",
    "print(\"PyTorch sum:\", torch_tensor.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42486fd3",
   "metadata": {
    "id": "42486fd3"
   },
   "source": [
    "### Why PyTorch for Machine Learning? Key Benefits\n",
    "\n",
    "PyTorch offers several advantages over NumPy for machine learning tasks:\n",
    "\n",
    "#### 1. **GPU Acceleration**\n",
    "- PyTorch tensors can seamlessly move between CPU and GPU\n",
    "- Massive speedup for large-scale computations (10-100x faster)\n",
    "- Essential for training deep neural networks\n",
    "\n",
    "#### 2. **Automatic Differentiation (Autograd)**\n",
    "- Automatically computes gradients for backpropagation\n",
    "- Critical for training neural networks\n",
    "- No need to manually derive and implement gradient calculations\n",
    "\n",
    "#### 3. **Built for Deep Learning**\n",
    "- Rich ecosystem of neural network layers, optimizers, and loss functions\n",
    "- Easy model building with `torch.nn` module\n",
    "- Pre-trained models and transfer learning support\n",
    "\n",
    "#### 4. **Dynamic Computation Graphs**\n",
    "- Graphs are built on-the-fly, allowing for flexible architectures\n",
    "- Easier debugging compared to static graphs\n",
    "- Supports variable-length inputs and conditional logic\n",
    "\n",
    "#### 5. **Production Ready**\n",
    "- TorchScript for model deployment\n",
    "- ONNX support for interoperability\n",
    "- Mobile deployment with PyTorch Mobile\n",
    "\n",
    "#### 6. **Strong Community and Ecosystem**\n",
    "- Extensive libraries (torchvision, torchaudio, etc.)\n",
    "- Active research community\n",
    "- Excellent documentation and tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc4d4c",
   "metadata": {
    "id": "eebc4d4c"
   },
   "source": [
    "### Demonstration: GPU Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa7898",
   "metadata": {
    "id": "c4fa7898"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Large matrix multiplication comparison\n",
    "size = 5000\n",
    "\n",
    "# NumPy (CPU only)\n",
    "np_a = np.random.randn(size, size)\n",
    "np_b = np.random.randn(size, size)\n",
    "\n",
    "start = time.time()\n",
    "np_result = np.dot(np_a, np_b)\n",
    "np_time = time.time() - start\n",
    "\n",
    "print(f\"NumPy (CPU) time: {np_time:.4f} seconds\")\n",
    "\n",
    "# PyTorch CPU\n",
    "torch_a_cpu = torch.randn(size, size)\n",
    "torch_b_cpu = torch.randn(size, size)\n",
    "\n",
    "start = time.time()\n",
    "torch_result_cpu = torch.matmul(torch_a_cpu, torch_b_cpu)\n",
    "torch_cpu_time = time.time() - start\n",
    "\n",
    "print(f\"PyTorch (CPU) time: {torch_cpu_time:.4f} seconds\")\n",
    "\n",
    "# PyTorch GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    torch_a_gpu = torch.randn(size, size).to(device)\n",
    "    torch_b_gpu = torch.randn(size, size).to(device)\n",
    "\n",
    "    # Warm up GPU\n",
    "    _ = torch.matmul(torch_a_gpu, torch_b_gpu)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "    torch_result_gpu = torch.matmul(torch_a_gpu, torch_b_gpu)\n",
    "    torch.cuda.synchronize()\n",
    "    torch_gpu_time = time.time() - start\n",
    "\n",
    "    print(f\"PyTorch (GPU) time: {torch_gpu_time:.4f} seconds\")\n",
    "    print(f\"\\nðŸš€ GPU Speedup: {torch_cpu_time / torch_gpu_time:.2f}x faster than CPU\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ GPU not available for speed comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd5d9e",
   "metadata": {
    "id": "eadd5d9e"
   },
   "source": [
    "### Demonstration: Automatic Differentiation (Autograd)\n",
    "This is PyTorch's killer feature for machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b663998",
   "metadata": {
    "id": "8b663998"
   },
   "outputs": [],
   "source": [
    "# Automatic differentiation example\n",
    "# Enable gradient tracking with requires_grad=True\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Define a computation\n",
    "z = x**2 + y**3\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = {y.item()}\")\n",
    "print(f\"z = xÂ² + yÂ³ = {z.item()}\")\n",
    "\n",
    "# Compute gradients automatically\n",
    "z.backward()\n",
    "\n",
    "# Access gradients\n",
    "print(f\"\\nâˆ‚z/âˆ‚x = 2x = {x.grad.item()}\")  # Should be 2*x = 4\n",
    "print(f\"âˆ‚z/âˆ‚y = 3yÂ² = {y.grad.item()}\")  # Should be 3*yÂ² = 27\n",
    "\n",
    "print(\"\\nâœ¨ PyTorch automatically computed these gradients!\")\n",
    "print(\"This is essential for training neural networks with backpropagation.\")\n",
    "\n",
    "# NumPy cannot do this - you'd have to compute gradients manually\n",
    "print(\"\\nâš ï¸ NumPy doesn't have automatic differentiation.\")\n",
    "print(\"You would need to manually derive and implement gradient calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a190a45",
   "metadata": {
    "id": "5a190a45"
   },
   "source": [
    "### Summary Comparison Table\n",
    "\n",
    "| Feature | NumPy | PyTorch |\n",
    "|---------|-------|---------|\n",
    "| **Data Structure** | ndarray | Tensor |\n",
    "| **GPU Support** | âŒ No | âœ… Yes |\n",
    "| **Automatic Differentiation** | âŒ No | âœ… Yes (Autograd) |\n",
    "| **Deep Learning** | âŒ Not built for it | âœ… Purpose-built |\n",
    "| **Speed (CPU)** | Very fast | Very fast |\n",
    "| **Speed (GPU)** | N/A | 10-100x faster |\n",
    "| **Use Case** | General numerical computing | Machine Learning & DL |\n",
    "| **Syntax** | Similar | Similar to NumPy |\n",
    "| **Ecosystem** | SciPy, scikit-learn | torchvision, torchaudio |\n",
    "| **Learning Curve** | Moderate | Easy if you know NumPy |\n",
    "\n",
    "### When to Use What?\n",
    "\n",
    "**Use NumPy when:**\n",
    "- Doing general numerical computations\n",
    "- Working with small to medium datasets\n",
    "- Not training neural networks\n",
    "- CPU processing is sufficient\n",
    "\n",
    "**Use PyTorch when:**\n",
    "- Building and training neural networks\n",
    "- Need GPU acceleration\n",
    "- Require automatic differentiation\n",
    "- Working on deep learning projects\n",
    "- Need production deployment of ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb46cf",
   "metadata": {
    "id": "b2cb46cf"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you've learned:\n",
    "\n",
    "1. âœ… What PyTorch is and why it's essential for deep learning\n",
    "2. âœ… How to create tensors in various ways\n",
    "3. âœ… Tensor attributes and properties\n",
    "4. âœ… Indexing, slicing, and filtering tensors\n",
    "5. âœ… Essential tensor operations (arithmetic, matrix ops, reductions)\n",
    "6. âœ… Tensor manipulation (reshaping, combining, splitting)\n",
    "7. âœ… NumPy integration and GPU acceleration\n",
    "8. âœ… Key differences between NumPy and PyTorch\n",
    "9. âœ… Why PyTorch is superior for machine learning\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore PyTorch's autograd in depth\n",
    "- Learn about `torch.nn` for building neural networks\n",
    "- Practice with real datasets using `torch.utils.data`\n",
    "- Implement your first neural network!\n",
    "\n",
    "**Happy Learning! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "23bd53d1",
    "67c184a2",
    "dd5daebc",
    "b8d156fe",
    "0b1e3e8a",
    "c71802da",
    "f94b10c4",
    "85008f93"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
