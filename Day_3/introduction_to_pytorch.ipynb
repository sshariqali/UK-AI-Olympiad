{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0lAI4wJsxyUI",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1762107289572,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "0lAI4wJsxyUI",
    "outputId": "46faec05-737f-4121-d4f1-ac1985f00332"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "const firstCell = document.querySelector('.cell.code_cell');\n",
       "if (firstCell) {\n",
       "  firstCell.querySelector('.input').style.pointerEvents = 'none';\n",
       "  firstCell.querySelector('.input').style.opacity = '0.5';\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display:flex; flex-direction:column; align-items:center; text-align:center; gap:12px; padding:8px;\">\n",
       "  <h1 style=\"margin:0;\">ðŸ‘‹ Welcome to <span style=\"color:#1E88E5;\">Algopath Coding Academy</span>!</h1>\n",
       "\n",
       "  <img src=\"https://raw.githubusercontent.com/sshariqali/mnist_pretrained_model/main/algopath_logo.jpg\"\n",
       "       alt=\"Algopath Coding Academy Logo\"\n",
       "       width=\"400\"\n",
       "       style=\"border-radius:15px; box-shadow:0 4px 12px rgba(0,0,0,0.2); max-width:100%; height:auto;\" />\n",
       "\n",
       "  <p style=\"font-size:16px; margin:0;\">\n",
       "    <em>Empowering young minds to think creatively, code intelligently, and build the future with AI.</em>\n",
       "  </p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<script>\n",
    "const firstCell = document.querySelector('.cell.code_cell');\n",
    "if (firstCell) {\n",
    "  firstCell.querySelector('.input').style.pointerEvents = 'none';\n",
    "  firstCell.querySelector('.input').style.opacity = '0.5';\n",
    "}\n",
    "</script>\n",
    "\"\"\"))\n",
    "\n",
    "html = \"\"\"\n",
    "<div style=\"display:flex; flex-direction:column; align-items:center; text-align:center; gap:12px; padding:8px;\">\n",
    "  <h1 style=\"margin:0;\">ðŸ‘‹ Welcome to <span style=\"color:#1E88E5;\">Algopath Coding Academy</span>!</h1>\n",
    "\n",
    "  <img src=\"https://raw.githubusercontent.com/sshariqali/mnist_pretrained_model/main/algopath_logo.jpg\"\n",
    "       alt=\"Algopath Coding Academy Logo\"\n",
    "       width=\"400\"\n",
    "       style=\"border-radius:15px; box-shadow:0 4px 12px rgba(0,0,0,0.2); max-width:100%; height:auto;\" />\n",
    "\n",
    "  <p style=\"font-size:16px; margin:0;\">\n",
    "    <em>Empowering young minds to think creatively, code intelligently, and build the future with AI.</em>\n",
    "  </p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f92fa",
   "metadata": {
    "id": "457f92fa"
   },
   "source": [
    "# PyTorch Tensors Tutorial\n",
    "\n",
    "\n",
    "**Table of Contents:**\n",
    "1. [Introduction to PyTorch](#1)\n",
    "2. [Creating Tensors](#2)\n",
    "3. [Tensor Attributes and Properties](#3)\n",
    "4. [Tensor Indexing Slicing and Filtering](#4)\n",
    "5. [Tensor Operations](#5)\n",
    "6. [Tensor Manipulation](#6)\n",
    "7. [GPU Interaction](#7)\n",
    "8. [NumPy vs PyTorch Comparison](#8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd53d1",
   "metadata": {
    "id": "23bd53d1"
   },
   "source": [
    "<a name='1'></a>\n",
    "## **1. Introduction to PyTorch Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8m3FnYCs4iDO",
   "metadata": {
    "id": "8m3FnYCs4iDO"
   },
   "source": [
    "### What is PyTorch?\n",
    "PyTorch is an open-source deep learning library developed by Facebook's AI Research lab. It provides:\n",
    "- Tensor computation with strong GPU acceleration\n",
    "- Automatic differentiation for building neural networks\n",
    "- A flexible and intuitive API for research and production\n",
    "\n",
    "### What is a Tensor?\n",
    "A **tensor** is the core data structure in PyTorch. Think of it as:\n",
    "- Similar to a NumPy `ndarray` but with additional capabilities\n",
    "- Can run on GPUs for accelerated computing\n",
    "- Supports automatic differentiation (autograd) for neural network training\n",
    "- A multi-dimensional array that can represent scalars, vectors, matrices, and higher-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df007a87",
   "metadata": {
    "id": "df007a87"
   },
   "source": [
    "### Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb692616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10634,
     "status": "ok",
     "timestamp": 1762202366615,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "eb692616",
    "outputId": "c79502e5-e38e-4d29-bd3d-ee1233ca0abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a611a",
   "metadata": {
    "id": "d54a611a"
   },
   "source": [
    "### Setting up your Device\n",
    "Check if CUDA (GPU) is available and set the device accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0b3891",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1762202394435,
     "user": {
      "displayName": "Shariq Ali",
      "userId": "00441094809974358112"
     },
     "user_tz": 0
    },
    "id": "de0b3891",
    "outputId": "21c3bad7-ee1c-45cd-c44c-7335390c87a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "GPU not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c184a2",
   "metadata": {
    "id": "67c184a2"
   },
   "source": [
    "---\n",
    "<a name='2'></a>\n",
    "## **2. Creating Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DscBqY7M4llk",
   "metadata": {
    "id": "DscBqY7M4llk"
   },
   "source": [
    "### From Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d016abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 11, 25,  5, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.tensor() - from Python lists or tuples\n",
    "tensor_1d = torch.tensor([9, 12, 25, 5, 10])\n",
    "tensor_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 11, 25],\n",
       "        [ 5, 10, 16]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D tensor from nested list\n",
    "tensor_2d = torch.tensor([[9, 12, 25], [5, 10, 16]])\n",
    "tensor_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c299076",
   "metadata": {
    "id": "3c299076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 15, 20, 25])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.from_numpy() - from NumPy array (shares memory!)\n",
    "np_array = np.array([12, 15, 20, 25])\n",
    "tensor_from_numpy = torch.from_numpy(np_array)\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3b29a",
   "metadata": {
    "id": "fcb3b29a"
   },
   "source": [
    "### Creating New Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3a607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros()\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88fc78d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones()\n",
    "ones_tensor = torch.ones(3,4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de709c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4664, 0.7369, 0.1835],\n",
       "        [0.0862, 0.5104, 0.5799],\n",
       "        [0.4217, 0.7657, 0.9702]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rand() - uniform distribution [0, 1)\n",
    "# random values between 0 and 1. Uniform distribution means all values are equally likely.\n",
    "rand_uniform = torch.rand(3, 3)\n",
    "rand_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb35bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange() - sequence of values\n",
    "arange_tensor = torch.arange(0, 10, 2)\n",
    "arange_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b2d691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.linspace() - linearly spaced values\n",
    "linspace_tensor = torch.linspace(0, 1, 5)\n",
    "linspace_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5daebc",
   "metadata": {
    "id": "dd5daebc"
   },
   "source": [
    "---\n",
    "<a name='3'></a>\n",
    "## **3. Tensor Attributes and Properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cef5fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0762, -2.4215],\n",
       "        [-0.2484,  2.1531]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "sample_tensor = torch.randn(2, 2)\n",
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d92a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type\n",
    "sample_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a1948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "sample_tensor.shape # sample_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85faf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which device the tensor is on\n",
    "print(sample_tensor.device)\n",
    "\n",
    "# Move tensor to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    sample_tensor = sample_tensor.to('cuda')\n",
    "    print(sample_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46848b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of dimensions\n",
    "sample_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b2c874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of elements\n",
    "sample_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e79efa",
   "metadata": {
    "id": "71e79efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer tensor dtype: torch.int64\n",
      "Float tensor dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with specific dtypes\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype = torch.long)\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype = torch.float32)\n",
    "print(f\"Integer tensor dtype: {int_tensor.dtype}\")\n",
    "print(f\"Float tensor dtype: {float_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d156fe",
   "metadata": {
    "id": "b8d156fe"
   },
   "source": [
    "---\n",
    "<a name='4'></a>\n",
    "## **4. Tensor Indexing, Slicing, and Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7079ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9053, 0.4043, 0.8561, 0.9175, 0.5014, 0.3896],\n",
       "        [0.7273, 0.0145, 0.2873, 0.4997, 0.3504, 0.0737],\n",
       "        [0.4426, 0.2325, 0.9622, 0.5124, 0.3272, 0.6838],\n",
       "        [0.7561, 0.8080, 0.8834, 0.0447, 0.2182, 0.7886]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor for indexing\n",
    "tensor = torch.rand(4,6)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70d591c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard indexing\n",
    "tensor[0, 0] # Access element at row 0, column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a31da7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing rows and columns\n",
    "tensor[0] # First row\n",
    "# tensor[:, 1] # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4f1d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing\n",
    "tensor[0:2] # First 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c642274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  9],\n",
       "        [14, 15]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1:3, 2:4] # Rows 1-3, Columns 2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f127b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[::2] # Every other row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20cf4cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean mask (elements > 10):\n",
      "tensor([[False, False, False, False, False, False],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True]])\n",
      "\n",
      "Filtered values (> 10):\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])\n"
     ]
    }
   ],
   "source": [
    "# Boolean/Masked indexing\n",
    "mask = tensor > 10\n",
    "print(\"Boolean mask (elements > 10):\") # \n",
    "print(mask) # boolean mask retains the original tensor's shape\n",
    "print(\"\\nFiltered values (> 10):\")\n",
    "print(tensor[mask]) # filtered values are a 1D array of only the elements that meet the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d03b2828",
   "metadata": {
    "id": "d03b2828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.where() - conditional selection\n",
    "result = torch.where(tensor > 10, tensor, torch.tensor(0)) # replace values <= 10 with 0\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e3e8a",
   "metadata": {
    "id": "0b1e3e8a"
   },
   "source": [
    "---\n",
    "<a name='5'></a>\n",
    "## **5. Tensor Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3wIYTj8B4pAQ",
   "metadata": {
    "id": "3wIYTj8B4pAQ"
   },
   "source": [
    "### Element-wise Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ed3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      " tensor([[0.0917, 0.6345, 0.2946],\n",
      "        [0.9469, 0.7935, 0.1982],\n",
      "        [0.5007, 0.8374, 0.3373]])\n",
      "Tensor b:\n",
      " tensor([[0.8797, 0.4347, 0.7658],\n",
      "        [0.9362, 0.6688, 0.9601],\n",
      "        [0.4063, 0.5270, 0.3932]])\n"
     ]
    }
   ],
   "source": [
    "# Create sample tensors\n",
    "a = torch.rand((3,3))\n",
    "b = torch.rand((3,3))\n",
    "\n",
    "print(\"Tensor a:\\n\", a)\n",
    "print(\"Tensor b:\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1fa7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9714, 1.0692, 1.0604],\n",
       "        [1.8831, 1.4624, 1.1583],\n",
       "        [0.9070, 1.3644, 0.7305]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "a + b # or torch.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33760ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7880,  0.1997, -0.4711],\n",
       "        [ 0.0107,  0.1247, -0.7618],\n",
       "        [ 0.0944,  0.3104, -0.0558]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "a - b # or torch.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a4b7e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0807, 0.2758, 0.2256],\n",
       "        [0.8865, 0.5307, 0.1903],\n",
       "        [0.2034, 0.4413, 0.1326]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication (element-wise)\n",
    "a * b # or torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2b62117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1042, 1.4595, 0.3847],\n",
       "        [1.0114, 1.1865, 0.2065],\n",
       "        [1.2324, 1.5890, 0.8580]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "a / b # or torch.div(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35217b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0084, 0.4026, 0.0868],\n",
       "        [0.8966, 0.6297, 0.0393],\n",
       "        [0.2507, 0.7012, 0.1138]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power\n",
    "a ** 2 # or torch.pow(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8f38562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0917, 2.6345, 2.2946],\n",
       "        [2.9469, 2.7935, 2.1982],\n",
       "        [2.5007, 2.8374, 2.3373]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar operations\n",
    "scalar = 2.0\n",
    "a + scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ed4af",
   "metadata": {
    "id": "a40ed4af"
   },
   "source": [
    "### In-place Operations\n",
    "Operations ending with `_` modify the tensor in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4b52e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0917, 5.6345, 5.2946],\n",
       "        [5.9469, 5.7935, 5.1982],\n",
       "        [5.5007, 5.8374, 5.3373]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place addition\n",
    "a.add_(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed7b9c1b",
   "metadata": {
    "id": "ed7b9c1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0917, 0.6345, 0.2946],\n",
       "        [0.9469, 0.7935, 0.1982],\n",
       "        [0.5007, 0.8374, 0.3373]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place multiplication\n",
    "a.subtract_(3)\n",
    "a\n",
    "\n",
    "# Note: In-place operations save memory but modify the original tensor\n",
    "# Regular operations create new tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df9b58",
   "metadata": {
    "id": "99df9b58"
   },
   "source": [
    "### Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53acf471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1:\n",
      " tensor([[10,  6],\n",
      "        [25, 13]])\n",
      "Matrix 2:\n",
      " tensor([[19, 45],\n",
      "        [16,  2]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "mat1 = torch.tensor([[10, 6], [25, 13]])\n",
    "mat2 = torch.tensor([[19, 45], [16, 2]])\n",
    "\n",
    "print(\"Matrix 1:\\n\", mat1)\n",
    "print(\"Matrix 2:\\n\", mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7def25e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 286,  462],\n",
       "        [ 683, 1151]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using torch.matmul()\n",
    "result1 = torch.matmul(mat1, mat2)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7429ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 286,  462],\n",
       "        [ 683, 1151]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using @ operator\n",
    "result2 = mat1 @ mat2\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f64540ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 25],\n",
       "        [ 6, 13]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose\n",
    "mat1.transpose(0, 1)  # Swap dimensions 0 and 1 \n",
    "# torch.transpose(mat, 0, 1)  # Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "585dc133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 25],\n",
       "        [ 6, 13]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.T # Shortcut for transpose for 2D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8bdfb",
   "metadata": {
    "id": "c8b8bdfb"
   },
   "source": [
    "### Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7aea80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  6., 25.],\n",
       "        [13., 19., 45.],\n",
       "        [16.,  2., 11.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor = torch.tensor([[10, 6, 25],\n",
    "                       [13, 19, 45],\n",
    "                       [16, 2, 11]], dtype=torch.float)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b41a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41., 77., 29.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "torch.sum(tensor)\n",
    "torch.sum(tensor, dim = 0) # Sum along columns\n",
    "torch.sum(tensor, dim = 1) # Sum along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd1100f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13.,  9., 27.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean\n",
    "torch.mean(tensor)\n",
    "torch.mean(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36da456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.0167, 17.0098,  7.0946])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard deviation\n",
    "torch.std(tensor, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max and Min\n",
    "torch.max(tensor) # along dimension can be specified as well by torch.max(tensor, dim=0)\n",
    "torch.min(tensor) # along dimension can be specified as well by torch.min(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f187a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argmax (index of maximum value)\n",
    "torch.argmax(tensor)\n",
    "torch.argmax(tensor, dim=0)\n",
    "torch.argmax(tensor, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6aa4e",
   "metadata": {
    "id": "b5c6aa4e"
   },
   "source": [
    "### Broadcasting\n",
    "Broadcasting allows operations between tensors of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38bf7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[10,  6, 25],\n",
      "        [13, 19, 45]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "Tensor b:\n",
      "tensor([16, 12, 11])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting examples\n",
    "a = torch.tensor([[10, 6, 25],\n",
    "                  [13, 19, 45]])\n",
    "b = torch.tensor([16, 12, 11])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8df8161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Broadcasted addition (a + b):\n",
      "tensor([[26, 18, 36],\n",
      "        [29, 31, 56]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting: b is automatically expanded to match a's shape\n",
    "result = a + b\n",
    "print(\"\\nBroadcasted addition (a + b):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71802da",
   "metadata": {
    "id": "c71802da"
   },
   "source": [
    "---\n",
    "<a name='6'></a>\n",
    "## **6. Tensor Manipulation (Reshaping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vYcGjw7n4rbe",
   "metadata": {
    "id": "vYcGjw7n4rbe"
   },
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4021721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor = torch.arange(11, 23)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1a895b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9678c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14],\n",
       "        [15, 16, 17, 18],\n",
       "        [19, 20, 21, 22]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping to (3, 4)\n",
    "reshaped_tensor = torch.reshape(tensor, (3, 4))\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8e01026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7353275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14],\n",
       "        [15, 16, 17, 18],\n",
       "        [19, 20, 21, 22]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .view() - returns a view (must be contiguous)\n",
    "viewed = tensor.view(3, 4)\n",
    "viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4c5314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4ab52",
   "metadata": {},
   "source": [
    "**Difference Between `.view()` and `.reshape()` (Explained Simply)**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.sstatic.net/ee7Hj.png\" width=\"500\"/>\n",
    "  <p><i>Tensor and its underlying storage</i></p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.sstatic.net/26Q9g.png\" width=\"500\"/>\n",
    "  <p><i>The right-hand tensor (shape (3,2)) can be computed from the left-hand one with t2 = t1.view(3,2)</i></p>\n",
    "</div>\n",
    "\n",
    "A View is like a different \"lens\" looking at the same data. It doesn't create new data in your RAM or GPU memory; it just changes the metadata (shape and strides) about how to read that data.\n",
    "\n",
    "**What is `.view()`?**\n",
    "- `.view()` changes the shape of a tensor **without copying the data**.\n",
    "- It only works if the tensor's data is stored in a **contiguous block** in memory (all elements are lined up in order).\n",
    "- If the tensor is **not contiguous** (for example, after a transpose), `.view()` will give an error.\n",
    "\n",
    "**What is `.reshape()`?**\n",
    "- `.reshape()` also changes the shape of a tensor.\n",
    "- If possible, it returns a **view** (no copy, just like `.view()`).\n",
    "- If the tensor is **not contiguous**, `.reshape()` will **make a copy** of the data so it can still give you the new shape.\n",
    "- So, `.reshape()` is more flexible and works in more situations.\n",
    "\n",
    "**What does \"contiguous\" mean?**\n",
    "- **Contiguous**: All the elements of the tensor are stored in memory one after another, in the order you see them.\n",
    "- **Non-contiguous**: The elements are not stored in order (for example, after you transpose a tensor, the way data is stored in memory changes).\n",
    "\n",
    "**When to use `.view()`?**\n",
    "- Use `.view()` when you are sure your tensor is **contiguous** (hasn't been transposed or sliced in a way that changes memory order).\n",
    "- It's a bit faster because it never copies data.\n",
    "\n",
    "**When to use `.reshape()`?**\n",
    "- Use `.reshape()` if you are **not sure** if your tensor is contiguous.\n",
    "- It will work in more cases, but might copy data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79582e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Is x contiguous? True\n",
      "\n",
      "Transposed x:\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "Is transposed contiguous? False\n",
      "\n",
      "Attempting xt.view(6)...\n",
      "Error: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "Making xt contiguous and then viewing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 1, 4, 2, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "print(f\"Original x:\\n{x}\")\n",
    "print(f\"Is x contiguous? {x.is_contiguous()}\") # True\n",
    "\n",
    "# 2. Transpose the tensor\n",
    "# Memory still looks like: [0, 1, 2, 3, 4, 5]\n",
    "# But the \"instructions\" say to read it vertically.\n",
    "xt = x.transpose(0, 1)\n",
    "print(f\"\\nTransposed x:\\n{xt}\")\n",
    "print(f\"Is transposed contiguous? {xt.is_contiguous()}\") # False\n",
    "\n",
    "# 3. Try to use .view()\n",
    "try:\n",
    "    print(\"\\nAttempting xt.view(6)...\")\n",
    "    xt.view(6)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# 4. Make it contiguous and then use .view()\n",
    "print(\"\\nMaking xt contiguous and then viewing...\")\n",
    "xt_contiguous = xt.contiguous()\n",
    "xt_contiguous.view(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2947a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using -1 to infer dimension\n",
    "auto_reshape = tensor.view(3, -1)\n",
    "auto_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b728a",
   "metadata": {
    "id": "014b728a"
   },
   "source": [
    "### Changing Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c5c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2423, -1.6811,  0.0700, -1.1526]],\n",
       "\n",
       "         [[-0.3222,  0.5486,  1.5061, -0.8805]],\n",
       "\n",
       "         [[ 0.1760,  0.7252, -0.1779, -0.3199]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() - remove dimensions of size 1\n",
    "tensor_4d = torch.randn(1, 3, 1, 4)\n",
    "tensor_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd20f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c07056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2423, -1.6811,  0.0700, -1.1526],\n",
       "        [-0.3222,  0.5486,  1.5061, -0.8805],\n",
       "        [ 0.1760,  0.7252, -0.1779, -0.3199]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed = torch.squeeze(tensor_4d)\n",
    "squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb032e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c267346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze specific dimension\n",
    "squeezed_dim = torch.squeeze(tensor_4d, dim = 0)\n",
    "squeezed_dim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d688ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1\n",
    "unsqueezed_0 = torch.unsqueeze(squeezed_dim, dim = 0)\n",
    "unsqueezed_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3400c5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1\n",
    "unsqueezed_0 = torch.unsqueeze(squeezed_dim, dim = 1)\n",
    "unsqueezed_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f653c44",
   "metadata": {
    "id": "2f653c44"
   },
   "source": [
    "### Combining Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[10,  6],\n",
      "        [25, 13]])\n",
      "\n",
      "Tensor b:\n",
      "tensor([[ 9, 45],\n",
      "        [17, 26]])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat() - concatenate along an existing dimension\n",
    "a = torch.tensor([[10, 6], [25, 13]])\n",
    "b = torch.tensor([[9, 45], [17, 26]])\n",
    "\n",
    "print(\"Tensor a:\")\n",
    "print(a)\n",
    "print(\"\\nTensor b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcdceb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6],\n",
       "        [25, 13],\n",
       "        [ 9, 45],\n",
       "        [17, 26]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along dimension 0 (rows)\n",
    "cat_dim0 = torch.cat([a, b], dim=0)\n",
    "cat_dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60252584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6,  9, 45],\n",
       "        [25, 13, 17, 26]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along dimension 1 (columns)\n",
    "cat_dim1 = torch.cat([a, b], dim=1)\n",
    "cat_dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe227431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10,  6],\n",
       "         [25, 13]],\n",
       "\n",
       "        [[ 9, 45],\n",
       "         [17, 26]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.stack() - stack along a new dimension\n",
    "stacked_dim0 = torch.stack([a, b], dim = 0) # 0 means row wise stacking and 1 means column wise stacking\n",
    "stacked_dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67dabef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_dim0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf25e7",
   "metadata": {
    "id": "95bf25e7"
   },
   "source": [
    "### Splitting Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db44d42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor to split\n",
    "tensor = torch.arange(12).reshape(3, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1c4ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "706258cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3],\n",
       "         [4, 5, 6, 7]]),\n",
       " tensor([[ 8,  9, 10, 11]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.split() - split into chunks of a given size\n",
    "splits = torch.split(tensor, 2, dim=0)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caf7c01d",
   "metadata": {
    "id": "caf7c01d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [4, 5],\n",
       "         [8, 9]]),\n",
       " tensor([[ 2,  3],\n",
       "         [ 6,  7],\n",
       "         [10, 11]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.chunk() - split into a specific number of chunks\n",
    "chunks = torch.chunk(tensor, 2, dim=1)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e228d",
   "metadata": {
    "id": "cf3e228d"
   },
   "source": [
    "### Reordering Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea242e1b",
   "metadata": {},
   "source": [
    "| Operation         | Resulting Tensor                | Logic/Explanation                                      |\n",
    "|-------------------|---------------------------------|--------------------------------------------------------|\n",
    "| **Original**      | <pre>[[1, 2, 3],<br> [4, 5, 6]]</pre> <br>Shape: (2, 3) | Starting tensor                                        |\n",
    "| `reshape(3, 2)`   | <pre>[[1, 2],<br> [3, 4],<br> [5, 6]]</pre> | Fills the new shape sequentially: 1, 2, then 3, 4, etc.|\n",
    "| `permute(1, 0)`   | <pre>[[1, 4],<br> [2, 5],<br> [3, 6]]</pre> | Swaps axes: Row 1 becomes Column 1, etc.               |\n",
    "\n",
    "**Key Difference:**\n",
    "- `reshape` changes the shape by reordering the elements in memory sequentially.\n",
    "- `permute` changes the order of axes (dimensions) without changing the order of elements in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ff7dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(2,3)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db640ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3119, 0.5794, 0.5553],\n",
       "        [0.8826, 0.4619, 0.9928]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84028c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permute dimensions works by reordering the dimensions of a tensor to a specified order.\n",
    "permuted = tensor.permute(1, 0)\n",
    "permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f717354e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3119, 0.8826],\n",
       "        [0.5794, 0.4619],\n",
       "        [0.5553, 0.9928]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80c40e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped = tensor.reshape(3, 2)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afd05d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3119, 0.5794],\n",
       "        [0.5553, 0.8826],\n",
       "        [0.4619, 0.9928]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b10c4",
   "metadata": {
    "id": "f94b10c4"
   },
   "source": [
    "---\n",
    "<a name='7'></a>\n",
    "## **7. NumPy & GPU Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a68a3",
   "metadata": {
    "id": "c54a68a3"
   },
   "source": [
    "### Moving Tensors Between CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f815fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Tensor: tensor([1., 2., 3., 4.])\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a CPU tensor\n",
    "cpu_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "print(\"CPU Tensor:\", cpu_tensor)\n",
    "print(\"Device:\", cpu_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bf91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tensor: tensor([1., 2., 3., 4.], device='cuda:0')\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create a GPU tensor (if CUDA is available)\n",
    "gpu_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0], device = 'cuda')\n",
    "print(\"GPU Tensor:\", gpu_tensor)\n",
    "print(\"Device:\", gpu_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3UPIkt254ukG",
   "metadata": {
    "id": "3UPIkt254ukG"
   },
   "source": [
    "### NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor: tensor([10., 20., 30., 40.])\n",
      "NumPy from tensor: [10. 20. 30. 40.]\n"
     ]
    }
   ],
   "source": [
    "# Convert Tensor to NumPy (only works on CPU tensors)\n",
    "\n",
    "np_from_tensor = cpu_tensor.numpy()\n",
    "print(\"NumPy from tensor:\", np_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85008f93",
   "metadata": {
    "id": "85008f93"
   },
   "source": [
    "---\n",
    "<a name='8'></a>\n",
    "## **8. Benefits of PyTorch over NumPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42486fd3",
   "metadata": {
    "id": "42486fd3"
   },
   "source": [
    "### Why PyTorch for Machine Learning? Key Benefits\n",
    "\n",
    "PyTorch offers several advantages over NumPy for machine learning tasks:\n",
    "\n",
    "#### 1. **GPU Acceleration**\n",
    "- PyTorch tensors can seamlessly move between CPU and GPU\n",
    "- Massive speedup for large-scale computations (10-100x faster)\n",
    "- Essential for training deep neural networks\n",
    "\n",
    "#### 2. **Automatic Differentiation (Autograd)**\n",
    "- Automatically computes gradients for backpropagation\n",
    "- Critical for training neural networks\n",
    "- No need to manually derive and implement gradient calculations\n",
    "\n",
    "#### 3. **Built for Deep Learning**\n",
    "- Rich ecosystem of neural network layers, optimizers, and loss functions\n",
    "- Easy model building with `torch.nn` module\n",
    "- Pre-trained models and transfer learning support\n",
    "\n",
    "#### 4. **Strong Community and Ecosystem**\n",
    "- Extensive libraries (torchvision, torchaudio, etc.)\n",
    "- Active research community\n",
    "- Excellent documentation and tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc4d4c",
   "metadata": {
    "id": "eebc4d4c"
   },
   "source": [
    "### Demonstration: GPU Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d772902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71618ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large matrix multiplication comparison\n",
    "size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af14d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy (CPU only)\n",
    "np_a = np.random.randn(size, size)\n",
    "np_b = np.random.randn(size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de0f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch CPU\n",
    "torch_a_cpu = torch.randn(size, size)\n",
    "torch_b_cpu = torch.randn(size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c21c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch GPU\n",
    "torch_a_gpu = torch.randn(size, size).to('cuda')\n",
    "torch_b_gpu = torch.randn(size, size).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83b5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy (CPU) time: 4.6320 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "np_result = np.dot(np_a, np_b)\n",
    "np_time = time.time() - start\n",
    "\n",
    "print(f\"NumPy (CPU) time: {np_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea249ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch (CPU) time: 2.1483 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "torch_result_cpu = torch_a_cpu @ torch_b_cpu\n",
    "torch_cpu_time = time.time() - start\n",
    "\n",
    "print(f\"PyTorch (CPU) time: {torch_cpu_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082c5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch (GPU) time: 0.1555 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "torch_result_gpu = torch_a_gpu @ torch_b_gpu\n",
    "torch_gpu_time = time.time() - start\n",
    "\n",
    "print(f\"PyTorch (GPU) time: {torch_gpu_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa7898",
   "metadata": {
    "id": "c4fa7898"
   },
   "outputs": [],
   "source": [
    "# # PyTorch GPU (if available)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch_a_gpu = torch.randn(size, size).to(device)\n",
    "#     torch_b_gpu = torch.randn(size, size).to(device)\n",
    "\n",
    "#     # Warm up GPU\n",
    "#     _ = torch.matmul(torch_a_gpu, torch_b_gpu)\n",
    "#     torch.cuda.synchronize()\n",
    "\n",
    "#     start = time.time()\n",
    "#     torch_result_gpu = torch.matmul(torch_a_gpu, torch_b_gpu)\n",
    "#     torch.cuda.synchronize()\n",
    "#     torch_gpu_time = time.time() - start\n",
    "\n",
    "#     print(f\"PyTorch (GPU) time: {torch_gpu_time:.4f} seconds\")\n",
    "#     print(f\"\\nðŸš€ GPU Speedup: {torch_cpu_time / torch_gpu_time:.2f}x faster than CPU\")\n",
    "# else:\n",
    "#     print(\"\\nâš ï¸ GPU not available for speed comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a190a45",
   "metadata": {
    "id": "5a190a45"
   },
   "source": [
    "### When to Use What?\n",
    "\n",
    "**Use NumPy when:**\n",
    "- Doing general numerical computations\n",
    "- Working with small to medium datasets\n",
    "- Not training neural networks\n",
    "- CPU processing is sufficient\n",
    "\n",
    "**Use PyTorch when:**\n",
    "- Building and training neural networks\n",
    "- Need GPU acceleration\n",
    "- Require automatic differentiation\n",
    "- Working on deep learning projects\n",
    "- Need production deployment of ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accf664",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='9'></a>\n",
    "## **9. Reading Material**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a2afc",
   "metadata": {},
   "source": [
    "### **torch.rand() vs torch.randn()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdefa5",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://i-blog.csdnimg.cn/direct/e34944beb690439b8505f2bba367b7cc.png\" width=\"700\"/>\n",
    "  <p><i>Uniform Distribution vs Normal Distribution</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55aadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.rand() - uniform distribution [0, 1)\n",
    "# random values between 0 and 1. Uniform distribution means all values are equally likely.\n",
    "rand_uniform = torch.rand(3, 3)\n",
    "rand_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn() - standard normal distribution (mean=0, std=1)\n",
    "# random values from a normal distribution with mean 0 and standard deviation 1. \n",
    "# 68.3 % probability that values are between -1 and 1\n",
    "# 95.4 % probability that values are between -2 and 2\n",
    "# range is theoretically from -infinity to +infinity.\n",
    "\n",
    "rand_normal = torch.randn(3, 3)\n",
    "rand_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb46cf",
   "metadata": {
    "id": "b2cb46cf"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you've learned:\n",
    "\n",
    "1. âœ… What PyTorch is and why it's essential for deep learning\n",
    "2. âœ… How to create tensors in various ways\n",
    "3. âœ… Tensor attributes and properties\n",
    "4. âœ… Indexing, slicing, and filtering tensors\n",
    "5. âœ… Essential tensor operations (arithmetic, matrix ops, reductions)\n",
    "6. âœ… Tensor manipulation (reshaping, combining, splitting)\n",
    "7. âœ… NumPy integration and GPU acceleration\n",
    "8. âœ… Key differences between NumPy and PyTorch\n",
    "9. âœ… Why PyTorch is superior for machine learning\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore PyTorch's autograd in depth\n",
    "- Learn about `torch.nn` for building neural networks\n",
    "- Practice with real datasets using `torch.utils.data`\n",
    "- Implement your first neural network!\n",
    "\n",
    "**Happy Learning! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "23bd53d1",
    "67c184a2",
    "dd5daebc",
    "b8d156fe",
    "0b1e3e8a",
    "c71802da",
    "f94b10c4",
    "85008f93"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
