{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86bbbdd5",
   "metadata": {},
   "source": [
    "### **1. Recap: Where We Left Off**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71cd3c",
   "metadata": {},
   "source": [
    "On **Day 7**, we built the **core attention mechanism** â€“ the fundamental building block of Transformers:\n",
    "\n",
    "| What We Built | What It Does |\n",
    "|--------------|-------------|\n",
    "| **Scaled Dot-Product Attention** | Computes weighted sums based on relevance |\n",
    "| **Multi-Head Attention** | Multiple attention heads for diverse patterns |\n",
    "| **Padding Mask** | Ignores padding tokens |\n",
    "| **Causal Mask** | Prevents seeing future tokens |\n",
    "\n",
    "**Today's Mission:** Take these building blocks and assemble them into complete **Encoder** and **Decoder** layers â€“ the two engines that power the Transformer!\n",
    "\n",
    "Let's dive in! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0f0d9",
   "metadata": {},
   "source": [
    "### **2. The Big Picture: What Are Encoders and Decoders?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e181670e",
   "metadata": {},
   "source": [
    "Before we dive into the code, let's understand the **purpose** and **roles** of Encoders and Decoders in the Transformer architecture.\n",
    "\n",
    "#### **The Translation Analogy ğŸŒ**\n",
    "\n",
    "Imagine you're a professional translator converting English to French:\n",
    "\n",
    "```\n",
    "English: \"The cat sat on the mat\"\n",
    "         â†“\n",
    "    [Understanding Phase - ENCODER]\n",
    "         â†“\n",
    "    Deep understanding of the meaning\n",
    "         â†“\n",
    "    [Generation Phase - DECODER]\n",
    "         â†“\n",
    "French: \"Le chat s'est assis sur le tapis\"\n",
    "```\n",
    "\n",
    "**Two Distinct Phases:**\n",
    "\n",
    "1. **Encoder (Understanding)**: Read and deeply understand the input\n",
    "   - \"What is the subject? The cat.\"\n",
    "   - \"What action? Sitting.\"\n",
    "   - \"Where? On the mat.\"\n",
    "   - Result: Rich representation of meaning\n",
    "\n",
    "2. **Decoder (Generation)**: Generate the output word by word\n",
    "   - Look at the understanding (from Encoder)\n",
    "   - Look at what you've already written\n",
    "   - Decide what word comes next\n",
    "\n",
    "**Key Insight:** The Encoder and Decoder work **together** but have **different jobs**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426df797",
   "metadata": {},
   "source": [
    "#### **Visual Representation**\n",
    "\n",
    "Here's how data flows through the complete Transformer:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*BHzGVskWGS_3jEcYYi6miQ.png\" width=\"700\"/>\n",
    "  <p><i>The Encoder processes the input, the Decoder generates the output</i></p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "| Component | Input | Output | Purpose |\n",
    "|-----------|-------|--------|--------|\n",
    "| **Encoder** | Source sequence (e.g., English) | Rich contextual representations | Understand the input deeply |\n",
    "| **Decoder** | Target sequence (e.g., French) + Encoder output | Next token predictions | Generate output sequence |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa277955",
   "metadata": {},
   "source": [
    "### **3. Why Do We Need Both? The Sequence-to-Sequence Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c01083",
   "metadata": {},
   "source": [
    "#### **The Challenge: Variable Length Input â†’ Variable Length Output**\n",
    "\n",
    "Many real-world tasks involve converting one sequence into another, where the lengths may differ:\n",
    "\n",
    "| Task | Input | Output |\n",
    "|------|-------|--------|\n",
    "| **Machine Translation** | \"How are you?\" (3 words) | \"Comment allez-vous?\" (3 words, but could differ) |\n",
    "| **Summarization** | 500-word article | 50-word summary |\n",
    "| **Question Answering** | \"What is the capital of France?\" | \"Paris\" |\n",
    "| **Code Generation** | \"Write a function to sort a list\" | 10 lines of Python code |\n",
    "| **Speech Recognition** | 5 seconds of audio | \"Hello, world\" |\n",
    "\n",
    "**The Problem:** We can't just use a single neural network layer because:\n",
    "- Input and output have **different lengths**\n",
    "- We need to **first understand** the full input before generating output\n",
    "- We need to **generate output sequentially** (word by word)\n",
    "\n",
    "**The Solution:** Encoder-Decoder architecture!\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20250529130320642115/Seq2Seq-Model.webp\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28f844",
   "metadata": {},
   "source": [
    "### **4. The Encoder: Understanding the Input**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412201c",
   "metadata": {},
   "source": [
    "#### **4.1 What Does the Encoder Do?**\n",
    "\n",
    "The Encoder's job is to **deeply understand the input sequence** and create rich representations that capture:\n",
    "\n",
    "- ğŸ“ **Word meanings** (semantic information)\n",
    "- ğŸ”— **Relationships** between words (syntactic information)\n",
    "- ğŸ¯ **Context** for each word (disambiguation)\n",
    "\n",
    "**Example: Understanding \"bank\"**\n",
    "\n",
    "The word \"bank\" can mean:\n",
    "- ğŸ¦ Financial institution: \"I deposited money in the bank\"\n",
    "- ğŸŒŠ River side: \"The boat floated near the bank\"\n",
    "\n",
    "The Encoder uses **self-attention** to look at surrounding words and disambiguate:\n",
    "\n",
    "```\n",
    "\"I deposited money in the bank\"\n",
    "                        â†‘\n",
    "                   \"bank\" attends to \"deposited\" and \"money\"\n",
    "                        â†’ Meaning: Financial institution! ğŸ¦\n",
    "\n",
    "\"The boat floated near the bank\"\n",
    "                          â†‘\n",
    "                     \"bank\" attends to \"boat\" and \"floated\"\n",
    "                          â†’ Meaning: River side! ğŸŒŠ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2425e5",
   "metadata": {},
   "source": [
    "#### **4.2 The Encoder Layer Architecture**\n",
    "\n",
    "Each Encoder Layer consists of **two sublayers**:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://www.researchgate.net/publication/334288604/figure/fig1/AS:778232232148992@1562556431066/The-Transformer-encoder-structure.ppm\" width=\"300\"/>\n",
    "  <p><i>A single Encoder Layer</i></p>\n",
    "</div>\n",
    "\n",
    "**Sublayer 1: Multi-Head Self-Attention**\n",
    "- Every word looks at every other word in the input\n",
    "- Creates contextualized representations\n",
    "- This is the attention mechanism we built on Day 7!\n",
    "\n",
    "**Sublayer 2: Position-wise Feed-Forward Network**\n",
    "- A simple two-layer neural network applied to each position independently\n",
    "- Adds non-linear transformation power\n",
    "- Same weights shared across all positions\n",
    "\n",
    "**The Secret Sauce: Add & Norm**\n",
    "\n",
    "Each sublayer is wrapped with:\n",
    "1. **Residual Connection** (Add): `output = sublayer(x) + x`\n",
    "2. **Layer Normalization** (Norm): Stabilizes training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa8728",
   "metadata": {},
   "source": [
    "#### **4.3 The Encoder Stack**\n",
    "\n",
    "The original Transformer uses **N = 6 identical Encoder layers** stacked on top of each other:\n",
    "\n",
    "```\n",
    "Input Embeddings + Positional Encoding\n",
    "               â†“\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚ Encoder Layer 1 â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â†“\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚ Encoder Layer 2 â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â†“\n",
    "              ...\n",
    "               â†“\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚ Encoder Layer 6 â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â†“\n",
    "      Encoder Output (sent to Decoder)\n",
    "```\n",
    "\n",
    "**Why Multiple Layers?**\n",
    "\n",
    "Each layer builds more **abstract representations**:\n",
    "- Layer 1: Surface-level patterns (word similarity)\n",
    "- Layer 2-3: Syntactic patterns (grammar, phrases)\n",
    "- Layer 4-5: Semantic patterns (meaning, context)\n",
    "- Layer 6: High-level understanding (intent, sentiment)\n",
    "\n",
    "**Analogy:** Like reading a text multiple times â€“ each pass reveals deeper understanding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f324c",
   "metadata": {},
   "source": [
    "### **5. The Decoder: Generating the Output**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf8a19",
   "metadata": {},
   "source": [
    "#### **5.1 What Does the Decoder Do?**\n",
    "\n",
    "The Decoder's job is to **generate the output sequence one token at a time**, using:\n",
    "\n",
    "1. ğŸ“– The **understanding from the Encoder** (what does the input mean?)\n",
    "2. âœï¸ The **tokens generated so far** (what have I already written?)\n",
    "\n",
    "**Example: Translating Step by Step**\n",
    "\n",
    "```\n",
    "English Input: \"The cat sat on the mat\"\n",
    "                    â†“ [Encoder]\n",
    "              Encoder Output (rich representation)\n",
    "                    â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚   DECODER   â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Step 1: Input \"<START>\"           â†’ Output: \"Le\"\n",
    "Step 2: Input \"<START> Le\"        â†’ Output: \"chat\"\n",
    "Step 3: Input \"<START> Le chat\"   â†’ Output: \"s'est\"\n",
    "Step 4: ...continue until \"<END>\"\n",
    "```\n",
    "\n",
    "**Key Point:** The Decoder is **autoregressive** â€“ it uses its own previous outputs as inputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a5f2b",
   "metadata": {},
   "source": [
    "#### **5.2 The Decoder Layer Architecture**\n",
    "\n",
    "Each Decoder Layer is more complex â€“ it has **three sublayers**:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://res.cloudinary.com/edlitera/image/upload/c_fill,f_auto/v1680629118/blog/gz5ccspg3yvq4eo6xhrr\" width=\"300\"/>\n",
    "  <p><i>A single Decoder Layer</i></p>\n",
    "</div>\n",
    "\n",
    "**Sublayer 1: Masked Multi-Head Self-Attention**\n",
    "- Output tokens attend to **previous output tokens only**\n",
    "- Uses a **causal mask** to prevent seeing future tokens\n",
    "- Remember: We can't cheat by looking at future words!\n",
    "\n",
    "**Sublayer 2: Multi-Head Cross-Attention** â­ NEW!\n",
    "- Output tokens attend to **all input tokens** (Encoder output)\n",
    "- **Query** comes from Decoder (what am I generating?)\n",
    "- **Key & Value** come from Encoder (what's in the input?)\n",
    "- This is how the Decoder \"looks at\" the source!\n",
    "\n",
    "**Sublayer 3: Position-wise Feed-Forward Network**\n",
    "- Same as in the Encoder\n",
    "- Adds non-linear transformation power\n",
    "\n",
    "Each sublayer has Add & Norm (residual + layer normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cef49d",
   "metadata": {},
   "source": [
    "#### **5.3 Cross-Attention: The Bridge Between Encoder and Decoder**\n",
    "\n",
    "Cross-attention is the **critical connection** that lets the Decoder access the Encoder's understanding:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://vaclavkosar.com/images/visual-representation-cross-attention-2.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "```python\n",
    "# In Decoder's Cross-Attention:\n",
    "Query = decoder_output @ W_q    # \"What am I looking for?\" (from Decoder)\n",
    "Key   = encoder_output @ W_k    # \"What's available?\" (from Encoder)\n",
    "Value = encoder_output @ W_v    # \"What information?\" (from Encoder)\n",
    "\n",
    "# Q from Decoder, K & V from Encoder!\n",
    "cross_attention = Attention(Query, Key, Value)\n",
    "```\n",
    "\n",
    "**Intuition:**\n",
    "\n",
    "When generating the French word \"chat\" (cat):\n",
    "- Query: \"I'm about to generate a word â€“ what should it be?\"\n",
    "- Keys: \"Here are all the English words: The, cat, sat, on, the, mat\"\n",
    "- Values: \"Here's what each English word means\"\n",
    "- Result: High attention to \"cat\" â†’ Generate \"chat\"!\n",
    "\n",
    "| Generating | Attends Most To | Why |\n",
    "|------------|----------------|-----|\n",
    "| \"Le\" (The) | \"The\" | Article alignment |\n",
    "| \"chat\" (cat) | \"cat\" | Noun translation |\n",
    "| \"s'est assis\" (sat) | \"sat\" | Verb translation |\n",
    "| \"sur\" (on) | \"on\" | Preposition alignment |\n",
    "| \"le tapis\" (the mat) | \"the mat\" | Phrase translation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912eb6e",
   "metadata": {},
   "source": [
    "### **6. Putting It All Together: The Complete Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db2651",
   "metadata": {},
   "source": [
    "Let's trace how data flows through the entire Transformer for a translation task:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/sshariqali/mnist_pretrained_model/blob/main/Gemini_Generated_Image_fq0l3nfq0l3nfq0l.png?raw=true\" width=\"700\"/>\n",
    "  <p><i>Encoder Decoder Working</i></p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "                    ENCODER               DECODER\n",
    "                    \n",
    "                 \"The cat sat\"           \"Le chat\"\n",
    "                       â†“                     â†“\n",
    "                  [Embedding]           [Embedding]\n",
    "                       â†“                     â†“\n",
    "             [Positional Encoding]  [Positional Encoding]\n",
    "                       â†“                     â†“\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ Self-Attention  â”‚  â”‚  Masked Self-Attention  â”‚\n",
    "              â”‚ (Bidirectional) â”‚  â”‚ (Causal/Unidirectional) â”‚\n",
    "              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â†“                     â†“\n",
    "                  [Add & Norm]          [Add & Norm]\n",
    "                       â†“                     â†“\n",
    "                       â†“          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Cross-Attention     â”‚\n",
    "                       â”‚          â”‚(Decoder Q, Encoder K,V)â”‚\n",
    "                       â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â”‚                     â†“\n",
    "                       â”‚                [Add & Norm]\n",
    "                       â†“                     â†“\n",
    "                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                 â”‚Feed-Forwardâ”‚        â”‚Feed-Forwardâ”‚\n",
    "                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                       â†“                     â†“\n",
    "                  [Add & Norm]          [Add & Norm]\n",
    "                       â†“                     â†“\n",
    "                 Encoder Output      [Linear + Softmax]\n",
    "                    (memory)                 â†“\n",
    "                                    Next Token Prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f58478",
   "metadata": {},
   "source": [
    "### **7. Summary: What We Learned Today**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f96d7",
   "metadata": {},
   "source": [
    "Congratulations! You now understand the architecture of Transformers at a conceptual level! ğŸ‰\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "âœ… **Encoder**: Processes input and creates rich contextual representations\n",
    "- Uses bidirectional self-attention (sees all words)\n",
    "- Two sublayers: Self-Attention + Feed-Forward\n",
    "\n",
    "âœ… **Decoder**: Generates output sequence autoregressively\n",
    "- Uses masked self-attention (sees only past)\n",
    "- Uses cross-attention to look at encoder output\n",
    "- Three sublayers: Masked Self-Attention + Cross-Attention + Feed-Forward\n",
    "\n",
    "âœ… **Supporting Components**:\n",
    "- **Positional Encoding**: Adds word order information\n",
    "- **Feed-Forward Network**: Adds non-linear transformation\n",
    "- **Layer Normalization**: Stabilizes training\n",
    "- **Residual Connections**: Enables deep networks\n",
    "\n",
    "---\n",
    "\n",
    "**What's Next?**\n",
    "\n",
    "In **Part 2**, we'll implement the **Encoder Layer** from scratch in PyTorch!\n",
    "\n",
    "In **Part 3**, we'll implement the **Decoder Layer** with cross-attention!\n",
    "\n",
    "Get ready to build! ğŸ”§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4cb924",
   "metadata": {},
   "source": [
    "### **8. Quick Quiz: Test Your Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd036d4",
   "metadata": {},
   "source": [
    "Before moving on, let's test your understanding!\n",
    "\n",
    "**Question 1:** Why does the Decoder use masked self-attention while the Encoder doesn't?\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer</summary>\n",
    "\n",
    "The Decoder generates output **autoregressively** (one token at a time). During training, we must prevent it from \"cheating\" by seeing future tokens it shouldn't know yet. The Encoder, on the other hand, is just understanding the input â€“ it should see the entire input at once.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Question 2:** In cross-attention, where do Query, Key, and Value come from?\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer</summary>\n",
    "\n",
    "- **Query**: From the Decoder (\"What am I looking for?\")\n",
    "- **Key & Value**: From the Encoder output (\"What's in the source?\")\n",
    "\n",
    "This allows the Decoder to \"look at\" the source sequence while generating the target.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Question 3:** Why do we need positional encodings?\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer</summary>\n",
    "\n",
    "Self-attention is **permutation invariant** â€“ it treats \"The cat sat\" the same as \"sat cat The\". Positional encodings inject information about word order so the model knows which word comes first, second, etc.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Question 4:** What is the purpose of residual connections (the \"Add\" in \"Add & Norm\")?\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer</summary>\n",
    "\n",
    "Residual connections provide a \"gradient highway\" that allows gradients to flow freely during backpropagation. This enables training of very deep networks (6+ layers) without vanishing gradients.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Question 5:** Would you use an Encoder-only, Decoder-only, or Encoder-Decoder model for machine translation?\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer</summary>\n",
    "\n",
    "**Encoder-Decoder** model! Translation requires understanding the source language (Encoder) AND generating the target language (Decoder). Examples: Original Transformer, T5, mBART.\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
